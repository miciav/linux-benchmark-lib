[project]
name = "linux-benchmark-lib"
version = "0.23.0"
description = "A robust and configurable Python library for benchmarking Linux computational node performance"
readme = "README.md"
requires-python = ">=3.12"
authors = [
    { name = "Your Name", email = "your.email@example.com" }
]
dependencies = [
    "psutil>=7.0.0",
    "pandas>=2.0.0",
    "numpy>=1.24.0",
    "jc>=1.25.0",
    "rich>=13.7.0",
    "typer>=0.12.5",
    "PyYAML>=6.0",
    "InquirerPy>=0.3.4"
]

[project.optional-dependencies]
controller = [
    "ansible-runner>=2.4.0",
    "ansible-core>=2.15.0",
    "matplotlib>=3.7.0",
    "seaborn>=0.12.0",
    "influxdb-client>=1.36.0",
]

[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
include = ["lb_runner*", "lb_controller*", "lb_ui*"]
exclude = ["reports*", "data_exports*", "benchmark_results*", "tests*"]

[tool.setuptools.package-data]
lb_runner = [
    "plugins/**/*",
]
lb_controller = [
    "ansible/**/*",
]

[project.scripts]
lb = "lb_ui.cli:main"
lb-ui = "lb_ui.cli:main"

[project.entry-points."linux_benchmark.collectors"]
psutil = "lb_runner.plugin_system.builtin:PSUTIL_COLLECTOR"
cli = "lb_runner.plugin_system.builtin:CLI_COLLECTOR"

[project.entry-points."linux_benchmark.workloads"]
stress_ng = "lb_runner.plugins.stress_ng.plugin:PLUGIN"
fio = "lb_runner.plugins.fio.plugin:PLUGIN"
dd = "lb_runner.plugins.dd.plugin:PLUGIN"
hpl = "lb_runner.plugins.hpl.plugin:PLUGIN"

[tool.uv]
package = true

[tool.black]
line-length = 88
target-version = ['py312']
include = '\.pyi?$'
exclude = '''
/(
    \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | _build
  | buck-out
  | build
  | dist
)/
'''

[tool.pytest.ini_options]
minversion = "7.0"
addopts = "-ra -q --strict-markers"
testpaths = ["tests"]
markers = [
    "integration: marks tests as integration tests (deselect with '-m \"not integration\"')",
    "docker: integration tests that build/run plugin Docker images",
    "multipass: integration tests that validate plugin multipass/ansible assets",
    "unit: test isolati e veloci (senza I/O o side effects)",
    "e2e: test end-to-end completi (es. con VM reali)",
    "cli: test dell'interfaccia a riga di comando",
    "plugins: test specifici per i plugin di workload",
    "slow: test che richiedono > 1 secondo",
    "slowest: test molto lenti (minuti) come provisioning VM",
]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"

[tool.mypy]
python_version = "3.12"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true

[tool.pydocstyle]
inherit = false
ignore = "D100,D104,D203,D213"
match-dir = "(?!tests).*"

[dependency-groups]
dev = [
    "pytest>=7.3.0",
    "pytest-cov>=4.0.0",
    "pytest-mock>=3.10.0",
    "psutil>=7.0.0",
    "black>=23.0.0",
    "flake8>=6.0.0",
    "pydocstyle>=6.3.0",
    "mypy>=1.0.0",
    "pre-commit>=3.2.0",
    "ansible-runner>=2.4.0",
]
