- name: Select workload runner mode
  debug:
    msg: >-
      Workload runner mode={{ workload_runner_mode | default('execute') }}
      tests={{ workload_runner_tests | default([]) }}
      output={{ workload_runner_output_dir | default('/tmp') }}

- name: Define workload runner workdir
  set_fact:
    workload_runner_workdir: "{{ workload_runner_workdir | default('/tmp/linux-benchmark-lib') }}"

- name: Choose Python interpreter for workload runner venv
  ansible.builtin.shell: |
    set -e
    if command -v python3.12 >/dev/null 2>&1; then
      command -v python3.12
    else
      command -v python3
    fi
  register: workload_runner_python_bin
  changed_when: false
  when: workload_runner_mode == "execute"

- name: Create workload runner workdir
  file:
    path: "{{ workload_runner_workdir }}"
    state: directory
    mode: "0755"

- name: Create virtual environment for workload runner
  ansible.builtin.command:
    cmd: "{{ (workload_runner_python_bin.stdout or 'python3') }} -m venv {{ workload_runner_workdir }}/.venv"
    creates: "{{ workload_runner_workdir }}/.venv/bin/python"
  when:
    - workload_runner_mode == "execute"
    - workload_runner_install_deps | default(false)

- name: Synchronize project to remote host
  ansible.builtin.copy:
    src: "{{ playbook_dir }}/../../{{ item }}"
    dest: "{{ workload_runner_workdir }}/{{ item }}"
    mode: preserve
  loop:
    - benchmark_config.py
    - local_runner.py
    - data_handler.py
    - reporter.py
    - ui
    - services
    - plugins
    - metric_collectors
    - workload_generators
    - pyproject.toml
    - uv.lock
  when: workload_runner_mode == "execute"

- name: Ensure workload output directory exists
  file:
    path: "{{ workload_runner_output_dir | default('/tmp') }}"
    state: directory
    mode: "0755"

- name: Check if Top500 workload is requested
  set_fact:
    workload_runner_top500_enabled: "{{ 'top500' in (workload_runner_tests | default([])) }}"
  when: workload_runner_mode == "execute"

- name: Prepare benchmark configuration for this host
  set_fact:
    workload_runner_config_rendered: >-
      {{
        (workload_runner_config | default({}))
        | combine({
            'output_dir': workload_runner_output_dir | default('/tmp'),
            'report_dir': (workload_runner_output_dir | default('/tmp')) ~ '/reports',
            'data_export_dir': (workload_runner_output_dir | default('/tmp')) ~ '/exports',
          }, recursive=True)
      }}

- name: Write benchmark configuration file
  copy:
    dest: "{{ workload_runner_workdir }}/benchmark_config.generated.json"
    content: "{{ workload_runner_config_rendered | to_nice_json }}"

- name: Upgrade pip inside workload runner venv
  ansible.builtin.command:
    cmd: "{{ workload_runner_workdir }}/.venv/bin/pip install --upgrade pip"
    chdir: "{{ workload_runner_workdir }}"
  when:
    - workload_runner_mode == "execute"
    - workload_runner_install_deps | default(false)

- name: Install Ansible for Top500 workload
  ansible.builtin.command:
    cmd: "{{ workload_runner_workdir }}/.venv/bin/pip install ansible"
    chdir: "{{ workload_runner_workdir }}"
  when:
    - workload_runner_mode == "execute"
    - workload_runner_install_deps | default(false)
    - workload_runner_top500_enabled | default(false)

- name: Install project in editable mode (explicit)
  ansible.builtin.command:
    cmd: "{{ workload_runner_workdir }}/.venv/bin/pip install -e ."
    chdir: "{{ workload_runner_workdir }}"
  when:
    - workload_runner_mode == "execute"
    - workload_runner_install_deps | default(false)

- name: Run benchmark via local runner
  ansible.builtin.shell: |
    {{ workload_runner_workdir }}/.venv/bin/python - <<'PY'
    from pathlib import Path
    import sys
    import logging

    # Configure logging
    output_dir = Path("{{ workload_runner_output_dir | default('/tmp') }}")
    log_file = output_dir / "runner.log"
    
    # Ensure output directory exists (it should, but to be safe)
    output_dir.mkdir(parents=True, exist_ok=True)

    handlers = [
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(log_file)
    ]

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=handlers
    )

    # __file__ is not defined in stdin scripts; use cwd provided by Ansible
    workdir = Path.cwd().resolve()
    sys.path.insert(0, str(workdir))
    sys.path.insert(0, str(workdir / "metric_collectors"))
    sys.path.insert(0, str(workdir / "workload_generators"))
    sys.path.insert(0, str(workdir / "plugins"))
    sys.path.insert(0, str(workdir / "ui"))
    sys.path.insert(0, str(workdir / "services"))
    from benchmark_config import BenchmarkConfig
    from local_runner import LocalRunner
    from plugins.builtin import builtin_plugins
    from plugins.registry import PluginRegistry

    config_path = Path("benchmark_config.generated.json")
    with config_path.open() as fh:
        cfg = BenchmarkConfig.from_json(fh.read())

    registry = PluginRegistry(builtin_plugins())
    runner = LocalRunner(cfg, registry=registry)
    test_name = "{{ item }}"
    print(f"Running benchmark: {test_name}", flush=True)
    
    print(f"\n>>> Starting {test_name}", flush=True)
    runner.run_benchmark(test_name)
    print(f"<<< Finished {test_name}\n", flush=True)
    PY
  args:
    chdir: "{{ workload_runner_workdir }}"
  environment:
    PYTHONPATH: >-
      {{ workload_runner_workdir }}:{{ workload_runner_workdir }}/plugins:{{ lookup('env', 'PYTHONPATH') | default('') }}
    PYTHONUNBUFFERED: "1"
    PATH: >-
      {{ workload_runner_workdir }}/.venv/bin:{{ ansible_env.PATH | default('/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin') }}
  loop: "{{ workload_runner_tests | default([]) }}"
  loop_control:
    label: "{{ item }}"
  when:
    - workload_runner_mode == "execute"
