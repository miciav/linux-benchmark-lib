{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>Benchmark orchestration for Linux nodes</p> Linux Benchmark Library <p>       Run repeatable workloads, collect multi-level metrics, and generate reports with       a clean CLI and stable Python APIs.     </p> Get started API reference Quick run <pre>lb config init -i\nlb plugin list --enable stress_ng\nlb run --remote --run-id demo-run</pre> <p>Provisioned runs are available in dev mode: <code>--docker</code> or <code>--multipass</code>.</p>"},{"location":"#why-this-exists","title":"Why this exists","text":"Repeatable workloads <p>Standardize load patterns and run them across hosts or provisioned targets.</p> Layered architecture <p>Runner, controller, app, and UI are cleanly separated to keep coupling low.</p> Actionable artifacts <p>Raw metrics, journals, reports, and exports are organized per run and host.</p> Extensible plugins <p>Add new workloads via entry points and a user plugin directory.</p>"},{"location":"#core-layers","title":"Core layers","text":"Layer Responsibility <code>lb_runner</code> Execute workloads and collect metrics on a node. <code>lb_controller</code> Orchestrate remote runs via Ansible and manage state. <code>lb_app</code> Stable API for CLIs/UIs and integrations. <code>lb_ui</code> CLI/TUI implementation. <code>lb_analytics</code> Reporting and post-processing. <code>lb_provisioner</code> Docker/Multipass helpers for the CLI."},{"location":"#where-to-go-next","title":"Where to go next","text":"<ul> <li>Read the Quickstart for CLI and Python examples.</li> <li>Use the CLI reference for all commands.</li> <li>Browse the API reference for stable modules.</li> <li>Check Diagrams for architecture visuals and release artifacts.</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>The codebase exposes a few stable, documented surfaces. Use these modules instead of reaching into private internals.</p> <ul> <li>Runner: local execution, plugin registry, and configuration models.</li> <li>Controller: orchestration, Ansible execution, journals.</li> <li>App &amp; UI: Application client plus UI wiring helpers.</li> <li>Provisioning: helpers to clean up provisioned nodes safely.</li> <li>Analytics: post-processing of stored runs.</li> </ul> <p>Use the navigation to open each section, or jump directly:</p> <ul> <li>Runner</li> <li>Controller</li> <li>App &amp; UI</li> <li>Provisioning</li> <li>Analytics</li> </ul>"},{"location":"cli/","title":"CLI Reference","text":"<p>Note: the user-facing CLI lives in <code>lb_ui</code> (invoke via <code>lb</code> or <code>python -m lb_ui.cli</code>). Runner/controller packages do not expose separate entrypoints.</p>"},{"location":"cli/#setup","title":"Setup","text":"<ul> <li>Install in a venv: <code>uv venv &amp;&amp; uv pip install -e \".[ui,controller]\"</code></li> <li>Make <code>lb</code> globally available (optional): <code>uv tool install -e \".[ui,controller]\"</code></li> <li>Enable shell completion: <code>lb --install-completion</code> (bash/zsh/fish)</li> </ul>"},{"location":"cli/#global-flags","title":"Global flags","text":"<ul> <li><code>--headless</code> forces headless output (useful in CI or pipes).</li> </ul>"},{"location":"cli/#config-resolution","title":"Config resolution","text":"<p>Order used by commands that need a config:</p> <ol> <li><code>-c/--config</code> flag</li> <li>Saved default at <code>~/.config/lb/config_path</code> (set via <code>lb config set-default</code> or <code>lb config init</code>)</li> <li><code>./benchmark_config.json</code> if present</li> <li>Built-in defaults</li> </ol>"},{"location":"cli/#top-level-commands","title":"Top-level commands","text":"<ul> <li><code>lb run [WORKLOAD ...] [-c FILE] [--run-id ID] [--resume [latest|ID]] [--remote/--no-remote] [--repetitions N] [--intensity LEVEL] [--setup/--no-setup] [--stop-file PATH] [--debug]</code>   Run workloads remotely via Ansible. Local execution is not supported by the CLI.</li> <li><code>lb run ... --docker [--docker-engine docker|podman] [--nodes N]</code>   Dev-only: provision containers and run via Ansible (requires <code>.lb_dev_cli</code> or <code>LB_ENABLE_TEST_CLI=1</code>).</li> <li><code>lb run ... --multipass [--nodes N]</code>   Dev-only: provision Multipass VMs and run via Ansible (requires <code>.lb_dev_cli</code> or <code>LB_ENABLE_TEST_CLI=1</code>).</li> <li><code>lb runs list [--root PATH] [-c FILE]</code> / <code>lb runs show RUN_ID [--root PATH] [-c FILE]</code>   Inspect stored runs under <code>benchmark_results/</code>.</li> <li><code>lb analyze [RUN_ID] [--root PATH] [--workload NAME] [--host NAME]</code>   Run analytics on an existing run (currently <code>aggregate</code>).</li> <li><code>lb plugin ...</code> / <code>lb plugins ...</code>   Inspect and manage workload plugins.</li> <li><code>lb config ...</code>   Create and manage benchmark configuration files.</li> <li><code>lb doctor ...</code>   Run prerequisite checks.</li> <li><code>lb test multipass ...</code> (dev-only)   Helper to run integration tests.</li> </ul>"},{"location":"cli/#plugin-management-lb-plugin","title":"Plugin management (<code>lb plugin ...</code>)","text":"<ul> <li><code>lb plugin list|ls [--select] [--enable NAME | --disable NAME] [-c FILE] [--set-default]</code></li> <li><code>lb plugin select [-c FILE] [--set-default]</code></li> <li><code>lb plugin install PATH|URL [--manifest FILE] [--force]</code></li> <li><code>lb plugin uninstall NAME [--purge-config/--keep-config] [-c FILE]</code></li> </ul>"},{"location":"cli/#config-management-lb-config","title":"Config management (<code>lb config ...</code>)","text":"<ul> <li><code>lb config init [-i] [--path FILE] [--set-default/--no-set-default]</code></li> <li><code>lb config set-repetitions N [-c FILE] [--set-default/--no-set-default]</code></li> <li><code>lb config set-default FILE</code> / <code>lb config unset-default</code> / <code>lb config show-default</code></li> <li><code>lb config edit [-p FILE]</code></li> <li><code>lb config workloads [-c FILE]</code></li> <li><code>lb config enable-workload NAME [-c FILE] [--set-default]</code></li> <li><code>lb config disable-workload NAME [-c FILE] [--set-default]</code></li> <li><code>lb config select-workloads [-c FILE] [--set-default]</code></li> </ul>"},{"location":"cli/#doctor-checks-lb-doctor","title":"Doctor checks (<code>lb doctor ...</code>)","text":"<ul> <li><code>lb doctor controller</code> - Python deps + Ansible requirements</li> <li><code>lb doctor local</code> - local workload tools (stress-ng, fio, sysstat)</li> <li><code>lb doctor multipass</code> - Multipass availability</li> <li><code>lb doctor all</code> - run all checks</li> </ul>"},{"location":"cli/#test-helpers-lb-test-dev-installs-only","title":"Test helpers (<code>lb test ...</code>, dev installs only)","text":"<ul> <li>Available when <code>.lb_dev_cli</code> exists in the project root or <code>LB_ENABLE_TEST_CLI=1</code> is set.</li> <li><code>lb test multipass [-o DIR] [--vm-count {1,2}] [--multi-workloads] [-- EXTRA_PYTEST_ARGS...]</code></li> </ul>"},{"location":"cli/#environment-variables","title":"Environment variables","text":"<ul> <li><code>LB_ENABLE_TEST_CLI=1</code> enables <code>lb test</code> and provisioning flags in the CLI.</li> <li><code>LB_USER_PLUGIN_DIR</code> overrides the user plugin install directory.</li> <li><code>LB_STOP_FILE</code> sets a stop sentinel path if <code>--stop-file</code> is omitted.</li> <li><code>LB_TEST_RESULTS_DIR</code>, <code>LB_MULTIPASS_VM_COUNT</code> customize test helpers.</li> </ul>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configuration","title":"Configuration","text":"<p>All knobs are defined in <code>BenchmarkConfig</code> (import from <code>lb_runner.api</code>).</p> <pre><code>from pathlib import Path\nfrom lb_runner.api import (\n    BenchmarkConfig,\n    RemoteExecutionConfig,\n    RemoteHostConfig,\n    WorkloadConfig,\n)\n\nconfig = BenchmarkConfig(\n    repetitions=3,\n    test_duration_seconds=120,\n    metrics_interval_seconds=1.0,\n    remote_hosts=[\n        RemoteHostConfig(\n            name=\"node1\",\n            address=\"192.168.1.10\",\n            user=\"ubuntu\",\n        )\n    ],\n    remote_execution=RemoteExecutionConfig(enabled=True),\n    workloads={\n        \"stress_ng\": WorkloadConfig(\n            plugin=\"stress_ng\",\n            enabled=True,\n            options={\"cpu_workers\": 4, \"vm_workers\": 2, \"vm_bytes\": \"2G\"},\n        )\n    },\n)\n\nconfig.save(Path(\"benchmark_config.json\"))\nconfig = BenchmarkConfig.load(Path(\"benchmark_config.json\"))\n</code></pre>"},{"location":"configuration/#notes","title":"Notes","text":"<ul> <li><code>workloads</code> is the primary map of workload names to configuration.</li> <li><code>plugin_settings</code> can hold typed Pydantic configs for plugins; it is optional.</li> <li><code>output_dir</code>, <code>report_dir</code>, and <code>data_export_dir</code> control where artifacts are written.</li> <li><code>remote_execution.enabled</code> controls whether the controller uses Ansible to run workloads.</li> <li><code>remote_execution.upgrade_pip</code> toggles the pip upgrade step during global setup.</li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":""},{"location":"contributing/#development-setup","title":"Development setup","text":"<pre><code>uv venv\nuv pip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/#tests","title":"Tests","text":"<ul> <li>Run all tests: <code>uv run pytest tests/</code></li> <li>Containerized tests (Docker): <code>./run_tests.sh</code></li> <li>Quick smoke run: <code>uv run python example.py</code></li> </ul>"},{"location":"contributing/#documentation","title":"Documentation","text":"<ul> <li>Install docs dependencies: <code>uv pip install -e \".[docs,controller]\"</code></li> <li>Run the site locally: <code>uv run mkdocs serve</code></li> </ul>"},{"location":"contributing/#style-and-quality","title":"Style and quality","text":"<ul> <li>Format: <code>uv run black .</code></li> <li>Lint: <code>uv run flake8</code></li> <li>Type check: <code>uv run mypy lb_runner lb_controller lb_app lb_ui</code></li> </ul>"},{"location":"contributing/#pr-checklist","title":"PR checklist","text":"<ul> <li>Keep commits focused and present tense.</li> <li>Note any required privileges (perf/eBPF, stress-ng, Docker, Multipass).</li> <li>Include validation steps and relevant logs/screenshots.</li> </ul>"},{"location":"ctrl_c_design/","title":"Ctrl+C, Stop Coordination, and Teardown Authority","text":""},{"location":"ctrl_c_design/#thread-and-component-model","title":"Thread and Component Model","text":"<ul> <li>UI/main thread drives the dashboard and installs a <code>SigintDoublePressHandler</code> through <code>lb_app.services.run_service.RunService</code>. It never exits on the first Ctrl+C while the controller thread is active; instead it posts notifications to a queue that the main loop drains.</li> <li>Controller worker thread (<code>ControllerRunner</code>) owns orchestration and transitions a shared <code>ControllerStateMachine</code>.</li> <li>AnsibleRunnerExecutor executes playbooks in subprocesses and exposes <code>interrupt()</code> + <code>is_running</code> for safe cancellation.</li> <li>lb_runner emits progress/stop events; the controller consumes them for stop confirmation.</li> <li>lb_provisioner is invoked from the CLI (<code>lb_ui</code>); cleanup is gated by controller state (<code>cleanup_allowed</code>).</li> </ul>"},{"location":"ctrl_c_design/#state-machine-phase-aware-and-monotonic","title":"State Machine (phase-aware and monotonic)","text":"<p>States: <code>INIT -&gt; RUNNING_GLOBAL_SETUP -&gt; RUNNING_WORKLOADS -&gt; RUNNING_GLOBAL_TEARDOWN -&gt; FINISHED</code></p> <p>Stop path: <code>... -&gt; STOP_ARMED -&gt; STOPPING_INTERRUPT_SETUP | STOPPING_WAIT_RUNNERS -&gt; STOPPING_TEARDOWN -&gt; ABORTED</code></p> <p>Failure path: any state -&gt; <code>STOP_FAILED</code> (stop protocol timeout) or <code>FAILED</code> (unexpected error)</p> <p>Rules:</p> <ul> <li>Transitions are validated and thread-safe.</li> <li>Cleanup is allowed only in <code>FINISHED</code> or <code>ABORTED</code>.</li> <li>Stop arming is idempotent; terminal states are immutable.</li> </ul>"},{"location":"ctrl_c_design/#ctrlc-semantics","title":"Ctrl+C Semantics","text":"<ul> <li>1st Ctrl+C: warn in the UI log area: \\\"Press Ctrl+C again to stop the execution\\\". No stop is requested.</li> <li>2nd Ctrl+C: enqueue a stop request; <code>ControllerRunner.arm_stop</code> transitions to <code>STOP_ARMED</code> and raises the shared <code>StopToken</code>.</li> <li>Further Ctrl+C while stopping are ignored until the controller finishes; process exit is not triggered by the UI.</li> </ul>"},{"location":"ctrl_c_design/#phase-aware-stop-handling","title":"Phase-aware Stop Handling","text":"<ul> <li>GLOBAL_SETUP: <code>stop_token</code> triggers <code>STOPPING_INTERRUPT_SETUP</code>; the running playbook is interrupted via <code>AnsibleRunnerExecutor.interrupt</code>. Controller proceeds to <code>STOPPING_TEARDOWN</code> before finishing in <code>ABORTED</code>.</li> <li>WORKLOAD_RUN: <code>STOPPING_WAIT_RUNNERS</code> kicks off the distributed stop protocol. Runners must confirm via events keyed by <code>run_id</code>; on success the controller enters <code>STOPPING_TEARDOWN</code>, else <code>STOP_FAILED</code>.</li> <li>GLOBAL_TEARDOWN: stop arms <code>STOPPING_INTERRUPT_TEARDOWN</code> and interrupts the teardown playbook; outcome is <code>ABORTED</code> or <code>STOP_FAILED</code>.</li> </ul>"},{"location":"ctrl_c_design/#ansiblerunner-interrupt-semantics","title":"AnsibleRunner Interrupt Semantics","text":"<ul> <li>Single execution path through <code>AnsibleRunnerExecutor.run_playbook</code>.</li> <li>Cancellable calls honor <code>StopToken</code> and a local interrupt flag; <code>interrupt()</code> is idempotent and terminates the subprocess when present.</li> <li><code>is_running</code> exposes whether a playbook is in-flight for diagnostics and stop decisions.</li> </ul>"},{"location":"ctrl_c_design/#provisioning-lifecycle-integration","title":"Provisioning Lifecycle Integration","text":"<ul> <li><code>RunExecutionSummary.cleanup_allowed</code> reflects <code>ControllerStateMachine.allows_cleanup</code>.</li> <li><code>lb_ui</code> only destroys provisioned nodes when <code>cleanup_allowed</code> is <code>True</code>; otherwise nodes are preserved for inspection.</li> </ul>"},{"location":"ctrl_c_stop_flow/","title":"Ctrl+C Isolation, State Machine, and Stop Flow","text":""},{"location":"ctrl_c_stop_flow/#why-ansible-was-getting-killed","title":"Why Ansible Was Getting Killed","text":"<ul> <li>Previously <code>ansible-playbook</code> was spawned in the same process group as the UI, so the first Ctrl+C delivered SIGINT directly to the child process, aborting setup and marking the controller as failed.</li> <li>Consequence: the dashboard exited immediately, setup stopped mid-flight, and the controller could not drive a coordinated stop/teardown.</li> </ul>"},{"location":"ctrl_c_stop_flow/#what-changed-isolation","title":"What Changed (Isolation)","text":"<ul> <li>Ansible subprocesses now run in their own session (<code>start_new_session=True</code>). A Ctrl+C in the UI no longer auto-terminates Ansible; the controller remains in charge.</li> <li><code>AnsibleRunnerExecutor.interrupt()</code> is idempotent and clears active process metadata; <code>is_running</code> reports in-flight state for diagnostics.</li> <li><code>lb_app.services.run_service.RunService</code> installs a double Ctrl+C handler:</li> <li>1st Ctrl+C: logs a warning (\\\"Press Ctrl+C again to stop the execution\\\"), no stop is issued.</li> <li>2nd Ctrl+C: arms a stop via the controller's <code>StopToken</code>/state machine; the UI stays alive.</li> <li>Further Ctrl+C while stopping are ignored; termination remains controller-driven.</li> </ul>"},{"location":"ctrl_c_stop_flow/#controller-state-machine-phase-aware","title":"Controller State Machine (Phase-Aware)","text":"<ul> <li>States: <code>INIT -&gt; RUNNING_GLOBAL_SETUP -&gt; RUNNING_WORKLOADS -&gt; RUNNING_GLOBAL_TEARDOWN -&gt; FINISHED</code></li> <li>Stop path: <code>... -&gt; STOP_ARMED -&gt; STOPPING_INTERRUPT_SETUP | STOPPING_WAIT_RUNNERS -&gt; STOPPING_TEARDOWN | STOPPING_INTERRUPT_TEARDOWN -&gt; ABORTED</code></li> <li>Failure path: any state can go to <code>FAILED</code> (unexpected error) or <code>STOP_FAILED</code> (stop protocol timed out).</li> <li>Terminal states: <code>FINISHED</code>, <code>ABORTED</code>, <code>STOP_FAILED</code>, <code>FAILED</code>.</li> <li>Cleanup gating: only <code>FINISHED</code> or <code>ABORTED</code> set <code>cleanup_allowed=True</code>; <code>STOP_FAILED</code>/<code>FAILED</code> keep provisioned nodes for inspection.</li> </ul>"},{"location":"ctrl_c_stop_flow/#phase-aware-stop-semantics","title":"Phase-Aware Stop Semantics","text":"<ul> <li>Global Setup: stop -&gt; <code>STOPPING_INTERRUPT_SETUP</code>; interrupt current playbook; proceed to teardown; finish as <code>ABORTED</code>.</li> <li>Workloads: stop -&gt; <code>STOPPING_WAIT_RUNNERS</code>; send stop file; wait for runner confirmations by <code>run_id</code>; on success -&gt; <code>STOPPING_TEARDOWN</code>, else <code>STOP_FAILED</code>.</li> <li>Global Teardown: stop -&gt; <code>STOPPING_INTERRUPT_TEARDOWN</code>; interrupt playbook; outcome <code>ABORTED</code> or <code>STOP_FAILED</code>.</li> </ul>"},{"location":"ctrl_c_stop_flow/#provisioning-cleanup-control","title":"Provisioning Cleanup Control","text":"<ul> <li><code>RunExecutionSummary.cleanup_allowed</code> reflects state-machine authorization.</li> <li><code>lb_ui</code> destroys provisioned nodes only when <code>cleanup_allowed=True</code>; otherwise it preserves them and warns the user.</li> </ul>"},{"location":"ctrl_c_stop_flow/#thread-model","title":"Thread Model","text":"<ul> <li>Controller worker thread runs orchestration via <code>ControllerRunner</code>, sharing the <code>ControllerStateMachine</code>.</li> <li>UI/main thread handles input and logging; SIGINT is converted into queued stop requests, never killing the controller thread.</li> <li>Ansible subprocesses are session-isolated; interrupted only via controller-driven <code>interrupt()</code>.</li> </ul>"},{"location":"ctrl_c_stop_flow/#verification-checklist","title":"Verification Checklist","text":"<ul> <li><code>uv run lb run --multipass</code> (or <code>--docker</code>):</li> <li>1st Ctrl+C during setup: dashboard stays open, warning appears, setup continues.</li> <li>2nd Ctrl+C during setup: setup playbook interrupted, teardown runs, provisioning cleanup only if <code>cleanup_allowed=True</code>.</li> <li>During workloads: stop waits for runner confirmations before teardown.</li> <li>During teardown: stop interrupts teardown and ends in <code>ABORTED</code> or <code>STOP_FAILED</code>, nodes preserved if not authorized for cleanup.</li> </ul>"},{"location":"diagrams/","title":"Diagrams","text":"<p>The diagrams below are generated on release builds. If you do not see the images, grab them from:</p> <ul> <li>Release assets: https://github.com/miciav/linux-benchmark-lib/releases</li> <li>Workflow artifacts: https://github.com/miciav/linux-benchmark-lib/actions/workflows/diagrams.yml</li> </ul>"},{"location":"diagrams/#class-diagram","title":"Class diagram","text":""},{"location":"diagrams/#package-diagram","title":"Package diagram","text":""},{"location":"diagrams/#how-to-regenerate","title":"How to regenerate","text":"<pre><code>pip install \"pylint==3.3.1\"\nmkdir -p docs/diagrams\npyreverse -o png -p linux-benchmark lb_runner lb_controller lb_app lb_ui lb_analytics lb_provisioner -S\nmv classes*.png docs/diagrams/classes.png\nmv packages*.png docs/diagrams/packages.png\npyreverse -o puml -p linux-benchmark lb_runner lb_controller lb_app lb_ui lb_analytics lb_provisioner -S\nmv classes*.puml docs/diagrams/classes.puml\nmv packages*.puml docs/diagrams/packages.puml\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone &lt;repository-url&gt;\ncd linux-benchmark-lib\n</code></pre> <ol> <li>Create a virtual environment and install:</li> </ol> <pre><code>uv venv\nuv pip install -e .  # runner only\n</code></pre>"},{"location":"installation/#extras","title":"Extras","text":"<pre><code>uv pip install -e \".[ui]\"          # CLI/TUI\nuv pip install -e \".[controller]\"  # Ansible + analytics\nuv pip install -e \".[ui,controller]\"  # full CLI\nuv pip install -e \".[dev]\"         # test + lint tools\nuv pip install -e \".[docs]\"        # mkdocs\n</code></pre> <p>Switch between dependency sets with the helper script:</p> <pre><code>bash scripts/switch_mode.sh base\nbash scripts/switch_mode.sh controller\nbash scripts/switch_mode.sh headless\nbash scripts/switch_mode.sh dev\n</code></pre>"},{"location":"interrupts/","title":"Interrupt Handling Design","text":"<p>This document describes the double-Ctrl+C interruption handling for remote benchmarks.</p>"},{"location":"interrupts/#goals","title":"Goals","text":"<ul> <li>Prevent accidental stops of long-running benchmarks.</li> <li>Ensure graceful teardown of remote workloads when a stop is confirmed.</li> <li>Provide clear UI feedback.</li> </ul>"},{"location":"interrupts/#architecture","title":"Architecture","text":"<p>The interrupt handling logic is separated into three layers:</p> <ol> <li>State Machine (<code>DoubleCtrlCStateMachine</code>)</li> <li>Pure logic component in <code>lb_controller/interrupts.py</code>.</li> <li>Tracks states: <code>RUNNING</code> -&gt; <code>STOP_ARMED</code> -&gt; <code>STOPPING</code> -&gt; <code>FINISHED</code>.</li> <li> <p>Decides action: <code>WARN_ARM</code>, <code>REQUEST_STOP</code>, or <code>DELEGATE</code> (allow default/force kill).</p> </li> <li> <p>Handler (<code>SigintDoublePressHandler</code>)</p> </li> <li>Context manager that installs/restores <code>signal.signal(SIGINT, ...)</code>.</li> <li>Routes signals to the state machine.</li> <li> <p>Executes callbacks based on decision (<code>on_first_sigint</code>, <code>on_confirmed_sigint</code>).</p> </li> <li> <p>Orchestration (<code>RunService</code>, <code>BenchmarkController</code>)</p> </li> <li><code>lb_app.services.run_service.RunService</code> installs the handler and provides UI callbacks.</li> <li><code>StopToken</code> in <code>lb_runner.stop_token</code> signals intent to stop across threads/processes.</li> <li><code>BenchmarkController</code> and <code>ControllerRunner</code> observe the token and coordinate teardown.</li> <li><code>AnsibleRunnerExecutor</code> interrupts active playbooks when a stop is requested.</li> </ol>"},{"location":"interrupts/#behavior","title":"Behavior","text":"<ul> <li>First Ctrl+C</li> <li>State: <code>RUNNING</code> -&gt; <code>STOP_ARMED</code>.</li> <li>Action: log \"Press Ctrl+C again to stop...\". Execution continues.</li> <li>Second Ctrl+C</li> <li>State: <code>STOP_ARMED</code> -&gt; <code>STOPPING</code>.</li> <li>Action: trigger <code>StopToken</code>.<ul> <li>Active Ansible playbook is terminated.</li> <li>Controller loop breaks.</li> <li>Plugin teardown runs (non-cancellable).</li> <li>Global teardown runs (non-cancellable).</li> </ul> </li> <li>Third Ctrl+C (Force)</li> <li>State: <code>STOPPING</code>.</li> <li>Action: delegate to Python default handler for a forced exit if teardown hangs.</li> </ul>"},{"location":"interrupts/#files","title":"Files","text":"<ul> <li><code>lb_controller/interrupts.py</code>: state machine and handler.</li> <li><code>lb_app/services/run_service.py</code>: wiring to UI and controller.</li> <li><code>lb_controller.engine.controller.py</code>: phase-aware stop logic.</li> <li><code>lb_controller.adapters.ansible_runner.py</code>: playbook interruption.</li> </ul>"},{"location":"plugins/","title":"Workloads & Plugins","text":""},{"location":"plugins/#workloads-and-plugins","title":"Workloads and Plugins","text":"<p>Linux Benchmark Library exposes workloads as plugins. Built-in plugins are loaded via entry points and include:</p> <ul> <li><code>stress_ng</code></li> <li><code>dd</code></li> <li><code>fio</code></li> <li><code>hpl</code></li> <li><code>stream</code></li> </ul> <p>Third-party plugins are installed into <code>lb_runner/plugins/_user</code> (override with <code>LB_USER_PLUGIN_DIR</code>).</p>"},{"location":"plugins/#cli-workflow","title":"CLI workflow","text":"<ul> <li>List plugins: <code>lb plugin list</code></li> <li>Enable a workload: <code>lb plugin list --enable stress_ng</code></li> <li>Interactive selection: <code>lb plugin select</code></li> <li>Install a plugin: <code>lb plugin install /path/to/plugin</code> or <code>lb plugin install https://github.com/...</code></li> <li>Uninstall a plugin: <code>lb plugin uninstall &lt;name&gt;</code></li> </ul>"},{"location":"plugins/#configuration","title":"Configuration","text":"<p>Workloads live in the config under <code>workloads</code>:</p> <pre><code>\"workloads\": {\n  \"stress_ng\": {\n    \"plugin\": \"stress_ng\",\n    \"enabled\": true,\n    \"options\": {\n      \"cpu_workers\": 4,\n      \"vm_workers\": 2\n    }\n  }\n}\n</code></pre> <p>You can also store typed plugin configs in <code>plugin_settings</code> (Pydantic models) when working programmatically.</p>"},{"location":"plugins/#plugin-structure-high-level","title":"Plugin structure (high level)","text":"<p>A plugin module exports a <code>WorkloadPlugin</code> instance named <code>PLUGIN</code> and may provide:</p> <ul> <li><code>config_cls</code> (Pydantic model for plugin settings)</li> <li><code>get_required_apt_packages()</code></li> <li><code>create_generator()</code> to emit workload commands</li> </ul> <p>The controller and CLI discover plugins via entry points and the user plugin directory.</p>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#quick-start","title":"Quick Start","text":""},{"location":"quickstart/#cli","title":"CLI","text":"<pre><code># Create a config and prompt for a remote host\nlb config init -i\n\n# Enable a workload\nlb plugin list --enable stress_ng\n\n# Run remotely (uses the config's remote hosts)\nlb run --remote --run-id demo-run\n</code></pre> <p>Dev-only provisioning (requires <code>.lb_dev_cli</code> or <code>LB_ENABLE_TEST_CLI=1</code>):</p> <pre><code>LB_ENABLE_TEST_CLI=1 lb run --docker --run-id demo-docker\n</code></pre>"},{"location":"quickstart/#python-api-controller","title":"Python API (Controller)","text":"<pre><code>from lb_controller.api import (\n    BenchmarkConfig,\n    BenchmarkController,\n    RemoteExecutionConfig,\n    RemoteHostConfig,\n)\n\nconfig = BenchmarkConfig(\n    repetitions=2,\n    remote_hosts=[\n        RemoteHostConfig(name=\"node1\", address=\"192.168.1.10\", user=\"ubuntu\")\n    ],\n    remote_execution=RemoteExecutionConfig(enabled=True),\n)\n\ncontroller = BenchmarkController(config)\nsummary = controller.run([\"stress_ng\"], run_id=\"demo-run\")\nprint(summary.per_host_output)\n</code></pre> <p>For runner-only integrations, use <code>lb_runner.api</code> and <code>lb_runner.engine.runner.LocalRunner</code>.</p>"},{"location":"remote_execution/","title":"Remote Execution","text":""},{"location":"remote_execution/#remote-execution","title":"Remote Execution","text":"<p>Remote runs are orchestrated by <code>lb_controller</code> using Ansible (install the <code>controller</code> extra). The CLI (<code>lb</code>) drives the controller through <code>lb_app</code> and runs workloads on configured hosts or provisioned targets.</p>"},{"location":"remote_execution/#configure-remote-hosts","title":"Configure remote hosts","text":"<p>Use <code>lb config init -i</code> to create a config and prompt for a remote host, or edit the config directly:</p> <pre><code>\"remote_hosts\": [\n  {\n    \"name\": \"node1\",\n    \"address\": \"192.168.1.10\",\n    \"user\": \"ubuntu\",\n    \"become\": true,\n    \"vars\": {\n      \"ansible_ssh_private_key_file\": \"~/.ssh/id_rsa\",\n      \"ansible_ssh_common_args\": \"-o StrictHostKeyChecking=no\"\n    }\n  }\n],\n\"remote_execution\": {\"enabled\": true}\n</code></pre> <p>Run with:</p> <pre><code>lb run --remote\n</code></pre> <p>Use <code>--remote/--no-remote</code> to override the config for a single run (local execution is not supported by the CLI).</p>"},{"location":"remote_execution/#provisioned-targets-dev-only","title":"Provisioned targets (dev-only)","text":"<p>The CLI can provision ephemeral nodes for testing:</p> <ul> <li><code>lb run --docker</code> uses Docker/Podman containers.</li> <li><code>lb run --multipass</code> uses Multipass VMs.</li> </ul> <p>These flags are available only in dev mode (<code>.lb_dev_cli</code> or <code>LB_ENABLE_TEST_CLI=1</code>). Use <code>--nodes</code> to select how many targets to provision (max 2).</p>"},{"location":"remote_execution/#stop-handling","title":"Stop handling","text":"<p>You can create a stop sentinel file during a run to request a graceful stop:</p> <pre><code>lb run --stop-file /tmp/lb.stop\n# touch /tmp/lb.stop to stop\n</code></pre> <p>The controller decides when cleanup is allowed; provisioned nodes are preserved if cleanup is disallowed or a failure occurs.</p>"},{"location":"reference/analytics/","title":"Analytics","text":"<p>Services for running post-processing on stored benchmark runs.</p>"},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsService","title":"AnalyticsService","text":"<p>Execute analytics against existing artifacts.</p>"},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsService-functions","title":"Functions","text":""},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsService.run","title":"run","text":"<pre><code>run(request)\n</code></pre> Source code in <code>lb_analytics/engine/service.py</code> <pre><code>def run(self, request: AnalyticsRequest) -&gt; List[Path]:\n    if request.kind == \"aggregate\":\n        return self._run_aggregate(request)\n    raise ValueError(f\"Unsupported analytics kind: {request.kind}\")\n</code></pre>"},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsRequest","title":"AnalyticsRequest  <code>dataclass</code>","text":"<pre><code>AnalyticsRequest(\n    run, kind=\"aggregate\", hosts=None, workloads=None\n)\n</code></pre> <p>Parameters to run analytics on a stored run.</p>"},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsRequest-attributes","title":"Attributes","text":""},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsRequest.hosts","title":"hosts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>hosts = None\n</code></pre>"},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsRequest.kind","title":"kind  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>kind = 'aggregate'\n</code></pre>"},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsRequest.run","title":"run  <code>instance-attribute</code>","text":"<pre><code>run\n</code></pre>"},{"location":"reference/analytics/#lb_analytics.engine.service.AnalyticsRequest.workloads","title":"workloads  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>workloads = None\n</code></pre>"},{"location":"reference/app/","title":"App &amp; UI API","text":"<p>Stable interfaces used by the CLI/TUI layer.</p>"},{"location":"reference/app/#application-client","title":"Application client","text":""},{"location":"reference/app/#lb_app.client.ApplicationClient","title":"ApplicationClient","text":"<pre><code>ApplicationClient()\n</code></pre> <p>               Bases: <code>AppClient</code></p> <p>Concrete application-layer client.</p> Source code in <code>lb_app/client.py</code> <pre><code>def __init__(self) -&gt; None:\n    configure_logging()\n    self._config_service = ConfigService()\n    self._run_service = RunService(registry_factory=create_registry)\n    self._provisioner = ProvisioningService(\n        enforce_ui_caller=True, allowed_callers=(\"lb_ui\", \"lb_app\")\n    )\n</code></pre>"},{"location":"reference/app/#lb_app.client.ApplicationClient-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.client.ApplicationClient.get_run_plan","title":"get_run_plan","text":"<pre><code>get_run_plan(config, tests, execution_mode='remote')\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def get_run_plan(self, config: BenchmarkConfig, tests: Sequence[str], execution_mode: str = \"remote\"):\n    return self._run_service.get_run_plan(config, list(tests), execution_mode=execution_mode)\n</code></pre>"},{"location":"reference/app/#lb_app.client.ApplicationClient.list_runs","title":"list_runs","text":"<pre><code>list_runs(config)\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def list_runs(self, config: BenchmarkConfig) -&gt; Iterable[RunJournal]:\n    return RunJournal.list_runs(config.output_dir)\n</code></pre>"},{"location":"reference/app/#lb_app.client.ApplicationClient.load_config","title":"load_config","text":"<pre><code>load_config(path=None)\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def load_config(self, path: Path | None = None) -&gt; BenchmarkConfig:\n    cfg, _, _ = self._config_service.load_for_read(path)\n    return cfg\n</code></pre>"},{"location":"reference/app/#lb_app.client.ApplicationClient.save_config","title":"save_config","text":"<pre><code>save_config(config, path)\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def save_config(self, config: BenchmarkConfig, path: Path) -&gt; None:\n    config.save(path)\n    self._config_service.write_saved_config_path(path)\n</code></pre>"},{"location":"reference/app/#lb_app.client.ApplicationClient.start_run","title":"start_run","text":"<pre><code>start_run(request, hooks)\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def start_run(self, request: RunRequest, hooks: UIHooks) -&gt; RunResult | None:\n    cfg = request.config\n    target_tests = list(\n        request.tests or [name for name, wl in cfg.workloads.items() if wl.enabled]\n    )\n    for name in target_tests:\n        if name not in cfg.workloads:\n            cfg.workloads[name] = WorkloadConfig(plugin=name, enabled=True)\n\n    context = self._run_service.create_session(\n        self._config_service,\n        tests=target_tests,\n        config_path=None,\n        run_id=request.run_id,\n        resume=request.resume,\n        repetitions=request.repetitions,\n        debug=request.debug,\n        intensity=request.intensity,\n        ui_adapter=request.ui_adapter,\n        setup=request.setup,\n        stop_file=request.stop_file,\n        execution_mode=request.execution_mode,\n        preloaded_config=cfg,\n    )\n\n    # Provision according to execution mode\n    prov_result = None\n    try:\n        cfg, prov_result = self._provision(\n            cfg,\n            request.execution_mode,\n            request.node_count,\n            request.docker_engine,\n        )\n    except ProvisioningError as exc:\n        hooks.on_warning(f\"Provisioning failed: {exc}\", ttl=5)\n        return None\n    context.config = cfg\n\n    run_result: RunResult | None = None\n    try:\n        output_cb = None\n        # If no UI adapter is provided, forward raw logs to hooks.\n        if request.ui_adapter is None:\n            output_cb = lambda text, end=\"\": hooks.on_log(text)\n\n        run_result = self._run_service.execute(\n            context,\n            run_id=request.run_id,\n            output_callback=output_cb,\n            ui_adapter=request.ui_adapter,\n        )\n        if run_result.summary and hasattr(run_result.summary, \"controller_state\"):\n            hooks.on_status(str(run_result.summary.controller_state))\n    finally:\n        if prov_result:\n            if run_result and run_result.summary and getattr(run_result.summary, \"cleanup_allowed\", False):\n                prov_result.destroy_all()\n            else:\n                prov_result.keep_nodes = True\n                hooks.on_warning(\"Leaving provisioned nodes for inspection\", ttl=5)\n    return run_result\n</code></pre>"},{"location":"reference/app/#app-layer-api","title":"App-layer API","text":""},{"location":"reference/app/#lb_app.api","title":"api","text":"<p>Stable application-layer API surface.</p>"},{"location":"reference/app/#lb_app.api-classes","title":"Classes","text":""},{"location":"reference/app/#lb_app.api.AppClient","title":"AppClient","text":"<p>               Bases: <code>Protocol</code></p> <p>Minimal interface that the UI can call into.</p>"},{"location":"reference/app/#lb_app.api.AppClient-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.AppClient.get_run_plan","title":"get_run_plan","text":"<pre><code>get_run_plan(config, tests, execution_mode='remote')\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def get_run_plan(self, config: BenchmarkConfig, tests: Sequence[str], execution_mode: str = \"remote\"): ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.AppClient.list_runs","title":"list_runs","text":"<pre><code>list_runs(config)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def list_runs(self, config: BenchmarkConfig) -&gt; Iterable[RunJournal]: ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.AppClient.load_config","title":"load_config","text":"<pre><code>load_config(path=None)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def load_config(self, path: Path | None = None) -&gt; BenchmarkConfig: ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.AppClient.save_config","title":"save_config","text":"<pre><code>save_config(config, path)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def save_config(self, config: BenchmarkConfig, path: Path) -&gt; None: ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.AppClient.start_run","title":"start_run","text":"<pre><code>start_run(request, hooks)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def start_run(self, request: RunRequest, hooks: UIHooks) -&gt; RunResult | None: ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.ApplicationClient","title":"ApplicationClient","text":"<pre><code>ApplicationClient()\n</code></pre> <p>               Bases: <code>AppClient</code></p> <p>Concrete application-layer client.</p> Source code in <code>lb_app/client.py</code> <pre><code>def __init__(self) -&gt; None:\n    configure_logging()\n    self._config_service = ConfigService()\n    self._run_service = RunService(registry_factory=create_registry)\n    self._provisioner = ProvisioningService(\n        enforce_ui_caller=True, allowed_callers=(\"lb_ui\", \"lb_app\")\n    )\n</code></pre>"},{"location":"reference/app/#lb_app.api.ApplicationClient-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.ApplicationClient.get_run_plan","title":"get_run_plan","text":"<pre><code>get_run_plan(config, tests, execution_mode='remote')\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def get_run_plan(self, config: BenchmarkConfig, tests: Sequence[str], execution_mode: str = \"remote\"):\n    return self._run_service.get_run_plan(config, list(tests), execution_mode=execution_mode)\n</code></pre>"},{"location":"reference/app/#lb_app.api.ApplicationClient.list_runs","title":"list_runs","text":"<pre><code>list_runs(config)\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def list_runs(self, config: BenchmarkConfig) -&gt; Iterable[RunJournal]:\n    return RunJournal.list_runs(config.output_dir)\n</code></pre>"},{"location":"reference/app/#lb_app.api.ApplicationClient.load_config","title":"load_config","text":"<pre><code>load_config(path=None)\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def load_config(self, path: Path | None = None) -&gt; BenchmarkConfig:\n    cfg, _, _ = self._config_service.load_for_read(path)\n    return cfg\n</code></pre>"},{"location":"reference/app/#lb_app.api.ApplicationClient.save_config","title":"save_config","text":"<pre><code>save_config(config, path)\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def save_config(self, config: BenchmarkConfig, path: Path) -&gt; None:\n    config.save(path)\n    self._config_service.write_saved_config_path(path)\n</code></pre>"},{"location":"reference/app/#lb_app.api.ApplicationClient.start_run","title":"start_run","text":"<pre><code>start_run(request, hooks)\n</code></pre> Source code in <code>lb_app/client.py</code> <pre><code>def start_run(self, request: RunRequest, hooks: UIHooks) -&gt; RunResult | None:\n    cfg = request.config\n    target_tests = list(\n        request.tests or [name for name, wl in cfg.workloads.items() if wl.enabled]\n    )\n    for name in target_tests:\n        if name not in cfg.workloads:\n            cfg.workloads[name] = WorkloadConfig(plugin=name, enabled=True)\n\n    context = self._run_service.create_session(\n        self._config_service,\n        tests=target_tests,\n        config_path=None,\n        run_id=request.run_id,\n        resume=request.resume,\n        repetitions=request.repetitions,\n        debug=request.debug,\n        intensity=request.intensity,\n        ui_adapter=request.ui_adapter,\n        setup=request.setup,\n        stop_file=request.stop_file,\n        execution_mode=request.execution_mode,\n        preloaded_config=cfg,\n    )\n\n    # Provision according to execution mode\n    prov_result = None\n    try:\n        cfg, prov_result = self._provision(\n            cfg,\n            request.execution_mode,\n            request.node_count,\n            request.docker_engine,\n        )\n    except ProvisioningError as exc:\n        hooks.on_warning(f\"Provisioning failed: {exc}\", ttl=5)\n        return None\n    context.config = cfg\n\n    run_result: RunResult | None = None\n    try:\n        output_cb = None\n        # If no UI adapter is provided, forward raw logs to hooks.\n        if request.ui_adapter is None:\n            output_cb = lambda text, end=\"\": hooks.on_log(text)\n\n        run_result = self._run_service.execute(\n            context,\n            run_id=request.run_id,\n            output_callback=output_cb,\n            ui_adapter=request.ui_adapter,\n        )\n        if run_result.summary and hasattr(run_result.summary, \"controller_state\"):\n            hooks.on_status(str(run_result.summary.controller_state))\n    finally:\n        if prov_result:\n            if run_result and run_result.summary and getattr(run_result.summary, \"cleanup_allowed\", False):\n                prov_result.destroy_all()\n            else:\n                prov_result.keep_nodes = True\n                hooks.on_warning(\"Leaving provisioned nodes for inspection\", ttl=5)\n    return run_result\n</code></pre>"},{"location":"reference/app/#lb_app.api.DashboardHandle","title":"DashboardHandle","text":"<p>               Bases: <code>Protocol</code></p> <p>Handle for a live dashboard visualization.</p>"},{"location":"reference/app/#lb_app.api.DashboardHandle-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.DashboardHandle.add_log","title":"add_log","text":"<pre><code>add_log(line)\n</code></pre> <p>Add a log line to the dashboard.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def add_log(self, line: str) -&gt; None:\n    \"\"\"Add a log line to the dashboard.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.DashboardHandle.live","title":"live","text":"<pre><code>live()\n</code></pre> <p>Return a context manager that keeps the dashboard live.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def live(self) -&gt; AbstractContextManager[None]:\n    \"\"\"Return a context manager that keeps the dashboard live.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.DashboardHandle.mark_event","title":"mark_event","text":"<pre><code>mark_event(source)\n</code></pre> <p>Mark an event occurrence (e.g., visual flash).</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def mark_event(self, source: str) -&gt; None:\n    \"\"\"Mark an event occurrence (e.g., visual flash).\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.DashboardHandle.refresh","title":"refresh","text":"<pre><code>refresh()\n</code></pre> <p>Trigger a refresh of the dashboard.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def refresh(self) -&gt; None:\n    \"\"\"Trigger a refresh of the dashboard.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorCheckGroup","title":"DoctorCheckGroup  <code>dataclass</code>","text":"<pre><code>DoctorCheckGroup(title, items, failures)\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorCheckGroup-attributes","title":"Attributes","text":""},{"location":"reference/app/#lb_app.api.DoctorCheckGroup.failures","title":"failures  <code>instance-attribute</code>","text":"<pre><code>failures\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorCheckGroup.items","title":"items  <code>instance-attribute</code>","text":"<pre><code>items\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorCheckGroup.title","title":"title  <code>instance-attribute</code>","text":"<pre><code>title\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorCheckItem","title":"DoctorCheckItem  <code>dataclass</code>","text":"<pre><code>DoctorCheckItem(label, ok, required)\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorCheckItem-attributes","title":"Attributes","text":""},{"location":"reference/app/#lb_app.api.DoctorCheckItem.label","title":"label  <code>instance-attribute</code>","text":"<pre><code>label\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorCheckItem.ok","title":"ok  <code>instance-attribute</code>","text":"<pre><code>ok\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorCheckItem.required","title":"required  <code>instance-attribute</code>","text":"<pre><code>required\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorReport","title":"DoctorReport  <code>dataclass</code>","text":"<pre><code>DoctorReport(groups, info_messages, total_failures)\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorReport-attributes","title":"Attributes","text":""},{"location":"reference/app/#lb_app.api.DoctorReport.groups","title":"groups  <code>instance-attribute</code>","text":"<pre><code>groups\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorReport.info_messages","title":"info_messages  <code>instance-attribute</code>","text":"<pre><code>info_messages\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorReport.total_failures","title":"total_failures  <code>instance-attribute</code>","text":"<pre><code>total_failures\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorService","title":"DoctorService","text":"<pre><code>DoctorService(config_service=None)\n</code></pre> <p>Service to check local prerequisites and environment health.</p> Source code in <code>lb_app/services/doctor_service.py</code> <pre><code>def __init__(\n    self,\n    config_service: Optional[ConfigService] = None,\n):\n    self.config_service = config_service or ConfigService()\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorService-attributes","title":"Attributes","text":""},{"location":"reference/app/#lb_app.api.DoctorService.config_service","title":"config_service  <code>instance-attribute</code>","text":"<pre><code>config_service = config_service or ConfigService()\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorService-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.DoctorService.check_all","title":"check_all","text":"<pre><code>check_all()\n</code></pre> <p>Run all checks.</p> Source code in <code>lb_app/services/doctor_service.py</code> <pre><code>def check_all(self) -&gt; DoctorReport:\n    \"\"\"Run all checks.\"\"\"\n    r1 = self.check_controller()\n    r2 = self.check_local_tools()\n    r3 = self.check_multipass()\n\n    return DoctorReport(\n        groups=r1.groups + r2.groups + r3.groups,\n        info_messages=r1.info_messages + r2.info_messages + r3.info_messages,\n        total_failures=r1.total_failures + r2.total_failures + r3.total_failures,\n    )\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorService.check_controller","title":"check_controller","text":"<pre><code>check_controller()\n</code></pre> <p>Check controller-side requirements (Python deps, ansible-runner).</p> Source code in <code>lb_app/services/doctor_service.py</code> <pre><code>def check_controller(self) -&gt; DoctorReport:\n    \"\"\"Check controller-side requirements (Python deps, ansible-runner).\"\"\"\n    groups = []\n    py_deps = [\n        (\"psutil\", self._check_import(\"psutil\"), True),\n        (\"pandas\", self._check_import(\"pandas\"), True),\n        (\"numpy\", self._check_import(\"numpy\"), True),\n        (\"matplotlib\", self._check_import(\"matplotlib\"), True),\n        (\"seaborn\", self._check_import(\"seaborn\"), True),\n        (\"jc\", self._check_import(\"jc\"), True),\n        (\n            \"influxdb-client (optional)\",\n            self._check_import(\"influxdb_client\"),\n            False,\n        ),\n    ]\n    groups.append(self._build_check_group(\"Python Dependencies\", py_deps))\n\n    controller_tools = [\n        (\"ansible-runner (python)\", self._check_import(\"ansible_runner\"), True),\n        (\"ansible-playbook\", self._check_command(\"ansible-playbook\"), True),\n    ]\n    groups.append(self._build_check_group(\"Controller Tools\", controller_tools))\n\n    resolved, stale = self.config_service.resolve_config_path(None)\n    cfg_items = [\n        (\"Active config\", resolved is not None, False),\n        (\"Stale default path\", stale is None, False),\n    ]\n    groups.append(self._build_check_group(\"Config Resolution\", cfg_items))\n\n    info = (\n        f\"Python: {platform.python_version()} ({platform.python_implementation()}) \"\n        f\"on {platform.system()} {platform.release()}\"\n    )\n\n    return DoctorReport(\n        groups=groups,\n        info_messages=[info],\n        total_failures=sum(g.failures for g in groups),\n    )\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorService.check_local_tools","title":"check_local_tools","text":"<pre><code>check_local_tools()\n</code></pre> <p>Check local workload tools required by installed plugins.</p> Source code in <code>lb_app/services/doctor_service.py</code> <pre><code>def check_local_tools(self) -&gt; DoctorReport:\n    \"\"\"Check local workload tools required by installed plugins.\"\"\"\n    registry = create_registry()\n    items: List[Tuple[str, bool, bool]] = []\n\n    # Common system tools that are always good to have\n    common_tools = [\"sar\", \"vmstat\", \"iostat\", \"mpstat\", \"pidstat\"]\n    for tool in common_tools:\n        items.append(\n            (f\"{tool} (system)\", self._check_command(tool), False)\n        )\n\n    # Plugin-specific tools\n    for plugin in registry.available(load_entrypoints=True).values():\n        # Support both Legacy and new Interface via duck typing or method presence\n        if hasattr(plugin, \"get_required_local_tools\"):\n            required_tools = plugin.get_required_local_tools()\n            for tool in required_tools:\n                label = f\"{tool} ({plugin.name})\"\n                items.append((label, self._check_command(tool), True))\n\n    messages = []\n    if not items:\n        messages.append(\"No plugins with local tool requirements found.\")\n        return DoctorReport(groups=[], info_messages=messages, total_failures=0)\n\n    # Sort by label\n    items.sort(key=lambda x: x[0])\n    group = self._build_check_group(\"Local Workload Tools\", items)\n    return DoctorReport(\n        groups=[group],\n        info_messages=messages,\n        total_failures=group.failures,\n    )\n</code></pre>"},{"location":"reference/app/#lb_app.api.DoctorService.check_multipass","title":"check_multipass","text":"<pre><code>check_multipass()\n</code></pre> <p>Check if Multipass is installed (used by integration test).</p> Source code in <code>lb_app/services/doctor_service.py</code> <pre><code>def check_multipass(self) -&gt; DoctorReport:\n    \"\"\"Check if Multipass is installed (used by integration test).\"\"\"\n    items = [(\"multipass\", self._check_command(\"multipass\"), True)]\n    group = self._build_check_group(\"Multipass\", items)\n    return DoctorReport(\n        groups=[group], info_messages=[], total_failures=group.failures\n    )\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpDashboardHandle","title":"NoOpDashboardHandle","text":"<p>               Bases: <code>DashboardHandle</code></p> <p>No-op dashboard handle.</p>"},{"location":"reference/app/#lb_app.api.NoOpDashboardHandle-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.NoOpDashboardHandle.add_log","title":"add_log","text":"<pre><code>add_log(line)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def add_log(self, line: str) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpDashboardHandle.live","title":"live","text":"<pre><code>live()\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def live(self) -&gt; AbstractContextManager[None]:\n    return nullcontext()\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpDashboardHandle.mark_event","title":"mark_event","text":"<pre><code>mark_event(source)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def mark_event(self, source: str) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpDashboardHandle.refresh","title":"refresh","text":"<pre><code>refresh()\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def refresh(self) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpProgressHandle","title":"NoOpProgressHandle","text":"<p>               Bases: <code>ProgressHandle</code></p> <p>No-op progress handle.</p>"},{"location":"reference/app/#lb_app.api.NoOpProgressHandle-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.NoOpProgressHandle.finish","title":"finish","text":"<pre><code>finish()\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def finish(self) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpProgressHandle.update","title":"update","text":"<pre><code>update(completed)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def update(self, completed: int) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter","title":"NoOpUIAdapter","text":"<p>               Bases: <code>UIAdapter</code></p> <p>No-op UI adapter that discards all output.</p>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.create_dashboard","title":"create_dashboard","text":"<pre><code>create_dashboard(plan, journal, ui_log_file=None)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def create_dashboard(self, plan: list[dict[str, Any]], journal: Any, ui_log_file: IO[str] | None = None) -&gt; DashboardHandle:\n    return NoOpDashboardHandle()\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.create_progress","title":"create_progress","text":"<pre><code>create_progress(description, total)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def create_progress(self, description: str, total: int) -&gt; ProgressHandle:\n    return NoOpProgressHandle()\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.prompt_multipass_scenario","title":"prompt_multipass_scenario","text":"<pre><code>prompt_multipass_scenario(options, default_level)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def prompt_multipass_scenario(self, options: list[str], default_level: str) -&gt; tuple[str, str] | None:  # pragma: no cover - trivial\n    return None\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.show_error","title":"show_error","text":"<pre><code>show_error(message)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_error(self, message: str) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.show_info","title":"show_info","text":"<pre><code>show_info(message)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_info(self, message: str) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.show_panel","title":"show_panel","text":"<pre><code>show_panel(message, title=None, border_style=None)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_panel(self, message: str, title: str | None = None, border_style: str | None = None) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.show_rule","title":"show_rule","text":"<pre><code>show_rule(title)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_rule(self, title: str) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.show_success","title":"show_success","text":"<pre><code>show_success(message)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_success(self, message: str) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.show_table","title":"show_table","text":"<pre><code>show_table(title, columns, rows)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_table(self, title: str, columns: Sequence[str], rows: list[Sequence[str]]) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.show_warning","title":"show_warning","text":"<pre><code>show_warning(message)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_warning(self, message: str) -&gt; None:  # pragma: no cover - trivial\n    pass\n</code></pre>"},{"location":"reference/app/#lb_app.api.NoOpUIAdapter.status","title":"status","text":"<pre><code>status(message)\n</code></pre> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def status(self, message: str) -&gt; AbstractContextManager[None]:\n    return nullcontext()\n</code></pre>"},{"location":"reference/app/#lb_app.api.ProgressHandle","title":"ProgressHandle","text":"<p>               Bases: <code>Protocol</code></p> <p>Progress task handle for updating completion.</p>"},{"location":"reference/app/#lb_app.api.ProgressHandle-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.ProgressHandle.finish","title":"finish","text":"<pre><code>finish()\n</code></pre> <p>Mark the task as finished and flush any pending output.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def finish(self) -&gt; None:\n    \"\"\"Mark the task as finished and flush any pending output.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.ProgressHandle.update","title":"update","text":"<pre><code>update(completed)\n</code></pre> <p>Update the task with the absolute completed amount.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def update(self, completed: int) -&gt; None:\n    \"\"\"Update the task with the absolute completed amount.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest","title":"RunRequest  <code>dataclass</code>","text":"<pre><code>RunRequest(\n    config,\n    tests,\n    run_id=None,\n    resume=None,\n    debug=False,\n    intensity=None,\n    setup=True,\n    stop_file=None,\n    execution_mode=\"remote\",\n    repetitions=None,\n    node_count=1,\n    docker_engine=\"docker\",\n    ui_adapter=None,\n)\n</code></pre> <p>Inputs required to start a run from the UI.</p>"},{"location":"reference/app/#lb_app.api.RunRequest-attributes","title":"Attributes","text":""},{"location":"reference/app/#lb_app.api.RunRequest.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.debug","title":"debug  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>debug = False\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.docker_engine","title":"docker_engine  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>docker_engine = 'docker'\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.execution_mode","title":"execution_mode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>execution_mode = 'remote'\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.intensity","title":"intensity  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>intensity = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.node_count","title":"node_count  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>node_count = 1\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.repetitions","title":"repetitions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>repetitions = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.resume","title":"resume  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>resume = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.run_id","title":"run_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_id = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.setup","title":"setup  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>setup = True\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.stop_file","title":"stop_file  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>stop_file = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.tests","title":"tests  <code>instance-attribute</code>","text":"<pre><code>tests\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunRequest.ui_adapter","title":"ui_adapter  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ui_adapter = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunResult","title":"RunResult  <code>dataclass</code>","text":"<pre><code>RunResult(\n    context,\n    summary,\n    journal_path=None,\n    log_path=None,\n    ui_log_path=None,\n)\n</code></pre> <p>Outcome of a run.</p>"},{"location":"reference/app/#lb_app.api.RunResult-attributes","title":"Attributes","text":""},{"location":"reference/app/#lb_app.api.RunResult.context","title":"context  <code>instance-attribute</code>","text":"<pre><code>context\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunResult.journal_path","title":"journal_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>journal_path = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunResult.log_path","title":"log_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>log_path = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunResult.summary","title":"summary  <code>instance-attribute</code>","text":"<pre><code>summary\n</code></pre>"},{"location":"reference/app/#lb_app.api.RunResult.ui_log_path","title":"ui_log_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ui_log_path = None\n</code></pre>"},{"location":"reference/app/#lb_app.api.TestService","title":"TestService","text":"<pre><code>TestService(ui=None, config_service=None)\n</code></pre> <p>Service for test configuration and interactions.</p> Source code in <code>lb_app/services/test_service.py</code> <pre><code>def __init__(\n    self,\n    ui: UIAdapter | None = None,\n    config_service: ConfigService | None = None,\n) -&gt; None:\n    self.ui: UIAdapter = ui or NoOpUIAdapter()\n    self.config_service: ConfigService = config_service or ConfigService()\n</code></pre>"},{"location":"reference/app/#lb_app.api.TestService-attributes","title":"Attributes","text":""},{"location":"reference/app/#lb_app.api.TestService.config_service","title":"config_service  <code>instance-attribute</code>","text":"<pre><code>config_service = config_service or ConfigService()\n</code></pre>"},{"location":"reference/app/#lb_app.api.TestService.ui","title":"ui  <code>instance-attribute</code>","text":"<pre><code>ui = ui or NoOpUIAdapter()\n</code></pre>"},{"location":"reference/app/#lb_app.api.TestService-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.TestService.build_multipass_scenario","title":"build_multipass_scenario","text":"<pre><code>build_multipass_scenario(intensity, selection)\n</code></pre> <p>Construct the scenario details for the test plan.</p> Source code in <code>lb_app/services/test_service.py</code> <pre><code>def build_multipass_scenario(\n    self, intensity: Dict[str, Any], selection: str\n) -&gt; MultipassScenario:\n    \"\"\"Construct the scenario details for the test plan.\"\"\"\n\n    # Defaults for generic single workload\n    target = \"tests/e2e/test_multipass_benchmark.py\"\n    target_label = \"benchmark\"\n    workload_label = selection\n    duration_label = f\"{selection} (default duration)\"\n    workload_rows = []\n    env_vars = {\"LB_MULTIPASS_WORKLOADS\": selection}\n\n    # Helper to build specific rows\n    def row_stress_ng():\n        return (\"stress_ng\", f\"{intensity['stress']}s\", \"1\", \"0s/0s\", f\"timeout={intensity['stress']}s, cpu_workers=1\")\n\n    def row_dd():\n        return (\"dd\", f\"approx {intensity['dd_count']}MiB\", \"1\", \"0s/0s\", f\"bs=1M, count={intensity['dd_count']}\")\n\n    def row_fio():\n        return (\"fio\", f\"{intensity['fio_runtime']}s\", \"1\", \"0s/0s\", f\"size={intensity['fio_size']}, randrw, bs=4k\")\n\n    if selection == \"multi\":\n        target = \"tests/e2e/test_multipass_multi_workloads.py\"\n        target_label = \"multi-workloads\"\n        workload_label = \"stress_ng, dd, fio\"\n        duration_label = (\n            f\"stress_ng {intensity['stress']}s; \"\n            f\"dd ~{intensity['dd_count']}MiB; \"\n            f\"fio {intensity['fio_runtime']}s/{intensity['fio_size']}\"\n        )\n        workload_rows = [row_stress_ng(), row_dd(), row_fio()]\n        env_vars = {} # Uses its own hardcoded logic or we could migrate it\n\n    elif selection == \"stress_ng\":\n        duration_label = f\"stress_ng {intensity['stress']}s\"\n        workload_rows = [row_stress_ng()]\n\n    elif selection == \"dd\":\n        duration_label = f\"dd ~{intensity['dd_count']}MiB\"\n        workload_rows = [row_dd()]\n\n    elif selection == \"fio\":\n        duration_label = f\"fio {intensity['fio_runtime']}s\"\n        workload_rows = [row_fio()]\n\n    else:\n        # Generic fallback for workloads not explicitly detailed in intensity\n        duration_label = \"default\"\n        workload_rows = [(selection, \"default\", \"1\", \"0s/0s\", \"default config\")]\n\n    return MultipassScenario(\n        target=target,\n        target_label=target_label,\n        workload_label=workload_label,\n        duration_label=duration_label,\n        workload_rows=workload_rows,\n        env_vars=env_vars\n    )\n</code></pre>"},{"location":"reference/app/#lb_app.api.TestService.get_multipass_intensity","title":"get_multipass_intensity","text":"<pre><code>get_multipass_intensity(force_env=None)\n</code></pre> <p>Return intensity parameters based on LB_MULTIPASS_FORCE env var or argument.</p> Source code in <code>lb_app/services/test_service.py</code> <pre><code>def get_multipass_intensity(self, force_env: Optional[str] = None) -&gt; Dict[str, Any]:\n    \"\"\"\n    Return intensity parameters based on LB_MULTIPASS_FORCE env var or argument.\n    \"\"\"\n    level = (force_env or os.environ.get(\"LB_MULTIPASS_FORCE\", \"medium\")).lower()\n    normalized = {\n        \"bassa\": \"low\",\n        \"low\": \"low\",\n        \"media\": \"medium\",\n        \"medium\": \"medium\",\n        \"alta\": \"high\",\n        \"high\": \"high\",\n    }.get(level, \"medium\")\n\n    if normalized == \"low\":\n        return {\n            \"level\": \"low\",\n            \"stress\": 3,\n            \"dd_count\": 8,\n            \"fio_runtime\": 3,\n            \"fio_size\": \"32M\",\n            \"stress_duration\": 3,\n            \"stress_timeout\": 3,\n        }\n    if normalized == \"high\":\n        return {\n            \"level\": \"high\",\n            \"stress\": 10,\n            \"dd_count\": 64,\n            \"fio_runtime\": 10,\n            \"fio_size\": \"128M\",\n            \"stress_duration\": 10,\n            \"stress_timeout\": 10,\n        }\n    return {\n        \"level\": \"medium\",\n        \"stress\": 5,\n        \"dd_count\": 32,\n        \"fio_runtime\": 5,\n        \"fio_size\": \"64M\",\n        \"stress_duration\": 5,\n        \"stress_timeout\": 5,\n    }\n</code></pre>"},{"location":"reference/app/#lb_app.api.TestService.select_multipass","title":"select_multipass","text":"<pre><code>select_multipass(\n    force_interactive=False, default_level=\"medium\"\n)\n</code></pre> <p>Select a Multipass scenario; fall back to defaults when non-interactive.</p> Source code in <code>lb_app/services/test_service.py</code> <pre><code>def select_multipass(\n    self, force_interactive: bool = False, default_level: str = \"medium\"\n) -&gt; tuple[str, str]:\n    \"\"\"Select a Multipass scenario; fall back to defaults when non-interactive.\"\"\"\n    cfg = self.config_service.create_default_config()\n    workload_names = list(cfg.workloads.keys())\n    if not workload_names:\n        return \"stress_ng\", default_level\n\n    options = list(dict.fromkeys(workload_names + [\"multi\"]))\n\n    interactive = force_interactive or (sys.stdin.isatty() and sys.stdout.isatty())\n    if interactive:\n        choice = self.ui.prompt_multipass_scenario(options, default_level)\n        if choice is not None:\n            return choice\n\n    return options[0], default_level\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter","title":"UIAdapter","text":"<p>               Bases: <code>Protocol</code></p> <p>Minimal interface for presentation concerns.</p>"},{"location":"reference/app/#lb_app.api.UIAdapter-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.UIAdapter.create_dashboard","title":"create_dashboard","text":"<pre><code>create_dashboard(plan, journal, ui_log_file=None)\n</code></pre> <p>Create a run dashboard.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def create_dashboard(self, plan: list[dict[str, Any]], journal: Any, ui_log_file: IO[str] | None = None) -&gt; DashboardHandle:\n    \"\"\"Create a run dashboard.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.create_progress","title":"create_progress","text":"<pre><code>create_progress(description, total)\n</code></pre> <p>Create a progress task.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def create_progress(self, description: str, total: int) -&gt; ProgressHandle:\n    \"\"\"Create a progress task.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.prompt_multipass_scenario","title":"prompt_multipass_scenario","text":"<pre><code>prompt_multipass_scenario(options, default_level)\n</code></pre> <p>Prompt user for multipass scenario selection.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def prompt_multipass_scenario(self, options: list[str], default_level: str) -&gt; tuple[str, str] | None:\n    \"\"\"Prompt user for multipass scenario selection.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.show_error","title":"show_error","text":"<pre><code>show_error(message)\n</code></pre> <p>Render an error message.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_error(self, message: str) -&gt; None:\n    \"\"\"Render an error message.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.show_info","title":"show_info","text":"<pre><code>show_info(message)\n</code></pre> <p>Render an informational message.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_info(self, message: str) -&gt; None:\n    \"\"\"Render an informational message.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.show_panel","title":"show_panel","text":"<pre><code>show_panel(message, title=None, border_style=None)\n</code></pre> <p>Render a block/panel container.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_panel(self, message: str, title: str | None = None, border_style: str | None = None) -&gt; None:\n    \"\"\"Render a block/panel container.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.show_rule","title":"show_rule","text":"<pre><code>show_rule(title)\n</code></pre> <p>Render a horizontal rule with a title.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_rule(self, title: str) -&gt; None:\n    \"\"\"Render a horizontal rule with a title.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.show_success","title":"show_success","text":"<pre><code>show_success(message)\n</code></pre> <p>Render a success message.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_success(self, message: str) -&gt; None:\n    \"\"\"Render a success message.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.show_table","title":"show_table","text":"<pre><code>show_table(title, columns, rows)\n</code></pre> <p>Render a simple table.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_table(self, title: str, columns: Sequence[str], rows: list[Sequence[str]]) -&gt; None:\n    \"\"\"Render a simple table.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.show_warning","title":"show_warning","text":"<pre><code>show_warning(message)\n</code></pre> <p>Render a warning message.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def show_warning(self, message: str) -&gt; None:\n    \"\"\"Render a warning message.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIAdapter.status","title":"status","text":"<pre><code>status(message)\n</code></pre> <p>Context manager that shows a status/spinner while work is running.</p> Source code in <code>lb_app/ui_interfaces.py</code> <pre><code>def status(self, message: str) -&gt; AbstractContextManager[None]:\n    \"\"\"Context manager that shows a status/spinner while work is running.\"\"\"\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIHooks","title":"UIHooks","text":"<p>               Bases: <code>Protocol</code></p> <p>Callbacks invoked by the application layer to update the UI.</p>"},{"location":"reference/app/#lb_app.api.UIHooks-functions","title":"Functions","text":""},{"location":"reference/app/#lb_app.api.UIHooks.on_event","title":"on_event","text":"<pre><code>on_event(event)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def on_event(self, event: RunEvent) -&gt; None: ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIHooks.on_journal","title":"on_journal","text":"<pre><code>on_journal(journal)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def on_journal(self, journal: RunJournal) -&gt; None: ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIHooks.on_log","title":"on_log","text":"<pre><code>on_log(line)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def on_log(self, line: str) -&gt; None: ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIHooks.on_status","title":"on_status","text":"<pre><code>on_status(controller_state)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def on_status(self, controller_state: str) -&gt; None: ...\n</code></pre>"},{"location":"reference/app/#lb_app.api.UIHooks.on_warning","title":"on_warning","text":"<pre><code>on_warning(message, ttl=10.0)\n</code></pre> Source code in <code>lb_app/interfaces.py</code> <pre><code>def on_warning(self, message: str, ttl: float = 10.0) -&gt; None: ...\n</code></pre>"},{"location":"reference/app/#ui-composition-helpers","title":"UI composition helpers","text":""},{"location":"reference/app/#lb_ui.dependencies.create_ui","title":"create_ui","text":"<pre><code>create_ui(headless=False)\n</code></pre> <p>Create UI and adapter; headless UI can be supplied later if needed.</p> Source code in <code>lb_ui/dependencies.py</code> <pre><code>def create_ui(headless: bool = False) -&gt; Tuple[UI, UIAdapter]:\n    \"\"\"Create UI and adapter; headless UI can be supplied later if needed.\"\"\"\n    ui: UI = TUI()\n    adapter: UIAdapter = TUIAdapter(ui)\n    if headless:\n        from lb_ui.ui.system.headless import HeadlessUI\n        ui = HeadlessUI()\n        adapter = TUIAdapter(ui)\n    return ui, adapter\n</code></pre>"},{"location":"reference/app/#lb_ui.dependencies.create_services","title":"create_services","text":"<pre><code>create_services()\n</code></pre> <p>Instantiate core services used by the CLI.</p> Source code in <code>lb_ui/dependencies.py</code> <pre><code>def create_services() -&gt; tuple[ConfigService, DoctorService, TestService, AnalyticsService, ApplicationClient]:\n    \"\"\"Instantiate core services used by the CLI.\"\"\"\n    config_service = ConfigService()\n    doctor_service = DoctorService(config_service=config_service)\n    test_service = TestService()\n    analytics_service = AnalyticsService()\n    app_client = ApplicationClient()\n    return config_service, doctor_service, test_service, analytics_service, app_client\n</code></pre>"},{"location":"reference/app/#lb_ui.dependencies.load_dev_mode","title":"load_dev_mode","text":"<pre><code>load_dev_mode(cli_root)\n</code></pre> <p>Return True when dev mode is enabled via marker file or pyproject flag.</p> Source code in <code>lb_ui/dependencies.py</code> <pre><code>def load_dev_mode(cli_root: Path) -&gt; bool:\n    \"\"\"Return True when dev mode is enabled via marker file or pyproject flag.\"\"\"\n    marker = cli_root / \".lb_dev_cli\"\n    if marker.exists():\n        return True\n    pyproject = cli_root / \"pyproject.toml\"\n    if pyproject.exists():\n        try:\n            data = tomllib.loads(pyproject.read_text())\n            tool_cfg = data.get(\"tool\", {}).get(\"lb_ui\", {}) or {}\n            if isinstance(tool_cfg, dict):\n                dev_flag = tool_cfg.get(\"dev_mode\")\n                if isinstance(dev_flag, bool):\n                    return dev_flag\n        except Exception:\n            pass\n    return False\n</code></pre>"},{"location":"reference/controller/","title":"Controller API","text":"<p>Orchestration helpers for remote runs, Ansible execution, and run catalogs.</p>"},{"location":"reference/controller/#public-surface","title":"Public surface","text":""},{"location":"reference/controller/#lb_controller.api","title":"api","text":"<p>Public controller API surface.</p>"},{"location":"reference/controller/#lb_controller.api-classes","title":"Classes","text":""},{"location":"reference/controller/#lb_controller.api.BenchmarkController","title":"BenchmarkController","text":"<pre><code>BenchmarkController(\n    config,\n    executor=None,\n    output_callback=None,\n    output_formatter=None,\n    journal_refresh=None,\n    stop_token=None,\n    stop_timeout_s=30.0,\n    state_machine=None,\n)\n</code></pre> <p>Controller coordinating remote benchmark runs.</p> Source code in <code>lb_controller/engine/controller.py</code> <pre><code>def __init__(\n    self,\n    config: BenchmarkConfig,\n    executor: Optional[RemoteExecutor] = None,\n    output_callback: Optional[Callable[[str, str], None]] = None,\n    output_formatter: Optional[Any] = None,  # Inject the formatter instance\n    journal_refresh: Optional[Callable[[], None]] = None,\n    stop_token: StopToken | None = None,\n    stop_timeout_s: float = 30.0,\n    state_machine: ControllerStateMachine | None = None,\n):\n    self.config = config\n    self.output_formatter = output_formatter\n    self.stop_token = stop_token\n    self._stop_timeout_s = stop_timeout_s\n    self.lifecycle = RunLifecycle()\n    self.state_machine = state_machine or ControllerStateMachine()\n    # Enable streaming if a callback is provided\n    stream = output_callback is not None\n    self.executor = executor or AnsibleRunnerExecutor(\n        output_callback=output_callback,\n        stream_output=stream,\n        stop_token=stop_token,\n    )\n    self.plugin_registry = create_registry()\n    self._journal_refresh = journal_refresh\n    # Use event stream as the source of truth; avoid mass RUNNING/COMPLETED updates.\n    self._use_progress_stream = True\n    self.coordinator: Optional[StopCoordinator] = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.BenchmarkController.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController.coordinator","title":"coordinator  <code>instance-attribute</code>","text":"<pre><code>coordinator = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController.executor","title":"executor  <code>instance-attribute</code>","text":"<pre><code>executor = executor or AnsibleRunnerExecutor(\n    output_callback=output_callback,\n    stream_output=stream,\n    stop_token=stop_token,\n)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController.lifecycle","title":"lifecycle  <code>instance-attribute</code>","text":"<pre><code>lifecycle = RunLifecycle()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController.output_formatter","title":"output_formatter  <code>instance-attribute</code>","text":"<pre><code>output_formatter = output_formatter\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController.plugin_registry","title":"plugin_registry  <code>instance-attribute</code>","text":"<pre><code>plugin_registry = create_registry()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController.state_machine","title":"state_machine  <code>instance-attribute</code>","text":"<pre><code>state_machine = state_machine or ControllerStateMachine()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController.stop_token","title":"stop_token  <code>instance-attribute</code>","text":"<pre><code>stop_token = stop_token\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.BenchmarkController.on_event","title":"on_event","text":"<pre><code>on_event(event)\n</code></pre> <p>Process an event for stop coordination.</p> Source code in <code>lb_controller/engine/controller.py</code> <pre><code>def on_event(self, event: RunEvent) -&gt; None:\n    \"\"\"Process an event for stop coordination.\"\"\"\n    if self.coordinator:\n        self.coordinator.process_event(event)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.BenchmarkController.run","title":"run","text":"<pre><code>run(\n    test_types,\n    run_id=None,\n    journal=None,\n    resume=False,\n    journal_path=None,\n)\n</code></pre> <p>Execute the configured benchmarks on remote hosts.</p> <p>Parameters:</p> Name Type Description Default <code>test_types</code> <code>List[str]</code> <p>List of benchmark identifiers to execute.</p> required <code>run_id</code> <code>Optional[str]</code> <p>Optional run identifier. If not provided, a timestamp-based id is generated.</p> <code>None</code> <code>journal</code> <code>Optional[RunJournal]</code> <p>Optional pre-loaded journal used for resume flows.</p> <code>None</code> <code>resume</code> <code>bool</code> <p>When True, reuse the provided journal instead of creating a new one.</p> <code>False</code> <code>journal_path</code> <code>Optional[Path]</code> <p>Optional override for where the journal is persisted.</p> <code>None</code> Source code in <code>lb_controller/engine/controller.py</code> <pre><code>def run(\n    self,\n    test_types: List[str],\n    run_id: Optional[str] = None,\n    journal: Optional[RunJournal] = None,\n    resume: bool = False,\n    journal_path: Optional[Path] = None,\n) -&gt; RunExecutionSummary:\n    \"\"\"\n    Execute the configured benchmarks on remote hosts.\n\n    Args:\n        test_types: List of benchmark identifiers to execute.\n        run_id: Optional run identifier. If not provided, a timestamp-based\n            id is generated.\n        journal: Optional pre-loaded journal used for resume flows.\n        resume: When True, reuse the provided journal instead of creating a new one.\n        journal_path: Optional override for where the journal is persisted.\n    \"\"\"\n    if not self.config.remote_hosts:\n        raise ValueError(\"At least one remote host must be configured.\")\n    if resume and journal is None:\n        raise ValueError(\"Resume requested without a journal instance.\")\n\n    phases: Dict[str, ExecutionResult] = {}\n    flags = _RunFlags()\n    state = self._prepare_run_state(test_types, run_id, journal, journal_path)\n\n    def ui_log(msg: str) -&gt; None:\n        logger.info(msg)\n\n    ui_log(f\"Starting Run {state.resolved_run_id}\")\n\n    if self.config.remote_execution.run_setup:\n        early_summary = self._run_global_setup(state, phases, flags, ui_log)\n        if early_summary:\n            return early_summary\n\n    if (\n        not self._stop_requested()\n        and self.state_machine.state != ControllerState.RUNNING_WORKLOADS\n    ):\n        self._transition(ControllerState.RUNNING_WORKLOADS)\n\n    flags = self._run_workloads(state, phases, flags, ui_log)\n    self._run_global_teardown(state, phases, flags, ui_log)\n\n    ui_log(\"Run Finished.\")\n    time.sleep(1)\n\n    self.lifecycle.finish()\n    return self._build_summary(state, phases, flags)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService","title":"ConfigService","text":"<pre><code>ConfigService(config_home=None)\n</code></pre> <p>Resolve, load, and mutate BenchmarkConfig files.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def __init__(self, config_home: Optional[Path] = None) -&gt; None:\n    xdg = os.environ.get(\"XDG_CONFIG_HOME\")\n    base = Path(xdg) if xdg else Path.home() / \".config\"\n    self.config_home = (config_home or base) / \"lb\"\n    self.default_target = self.config_home / DEFAULT_CONFIG_NAME\n    self.pointer = self.config_home / DEFAULT_CONFIG_POINTER\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.ConfigService.config_home","title":"config_home  <code>instance-attribute</code>","text":"<pre><code>config_home = (config_home or base) / 'lb'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.default_target","title":"default_target  <code>instance-attribute</code>","text":"<pre><code>default_target = config_home / DEFAULT_CONFIG_NAME\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.pointer","title":"pointer  <code>instance-attribute</code>","text":"<pre><code>pointer = config_home / DEFAULT_CONFIG_POINTER\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.ConfigService.add_remote_host","title":"add_remote_host","text":"<pre><code>add_remote_host(\n    host, config, enable_remote=True, set_default=False\n)\n</code></pre> <p>Add or replace a remote host definition and persist the config.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def add_remote_host(\n    self,\n    host: RemoteHostConfig,\n    config: Optional[Path],\n    enable_remote: bool = True,\n    set_default: bool = False,\n) -&gt; Tuple[BenchmarkConfig, Path, Optional[Path]]:\n    \"\"\"Add or replace a remote host definition and persist the config.\"\"\"\n    cfg, target, stale, _ = self.load_for_write(config, allow_create=True)\n    cfg.remote_hosts = [existing for existing in cfg.remote_hosts if existing.name != host.name]\n    cfg.remote_hosts.append(host)\n    cfg.remote_execution.enabled = enable_remote\n    cfg.save(target)\n    if set_default:\n        self.write_saved_config_path(target)\n    return cfg, target, stale\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.clear_saved_config_path","title":"clear_saved_config_path","text":"<pre><code>clear_saved_config_path()\n</code></pre> <p>Remove the stored config pointer.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def clear_saved_config_path(self) -&gt; None:\n    \"\"\"Remove the stored config pointer.\"\"\"\n    if self.pointer.exists():\n        self.pointer.unlink()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.create_default_config","title":"create_default_config","text":"<pre><code>create_default_config()\n</code></pre> <p>Create a fresh BenchmarkConfig populated with all installed plugins.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def create_default_config(self) -&gt; BenchmarkConfig:\n    \"\"\"Create a fresh BenchmarkConfig populated with all installed plugins.\"\"\"\n    from .plugin_service import create_registry\n    from lb_runner.plugin_system.settings import (\n        ensure_workloads_from_plugin_settings,\n        populate_default_plugin_settings,\n    )\n\n    registry = create_registry()\n\n    cfg = BenchmarkConfig()\n    # Clear any legacy hardcoded defaults if BenchmarkConfig still has them (redundant safety)\n    cfg.workloads = {} \n    cfg.plugin_settings = {}\n\n    available = registry.available(load_entrypoints=True)\n    populate_default_plugin_settings(\n        cfg,\n        registry=registry,\n        load_entrypoints=True,\n        allow_dataclasses=True,\n    )\n    ensure_workloads_from_plugin_settings(\n        cfg, dump_mode=\"json\", convert_dataclasses=True\n    )\n\n    for name, plugin in available.items():\n        if name not in cfg.workloads:\n            cfg.workloads[name] = WorkloadConfig(plugin=name, enabled=False)\n\n    return cfg\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.ensure_home","title":"ensure_home","text":"<pre><code>ensure_home()\n</code></pre> <p>Create the config home directory.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def ensure_home(self) -&gt; None:\n    \"\"\"Create the config home directory.\"\"\"\n    self.config_home.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.load_for_read","title":"load_for_read","text":"<pre><code>load_for_read(config_path)\n</code></pre> <p>Load a config for read-only scenarios.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def load_for_read(self, config_path: Optional[Path]) -&gt; Tuple[BenchmarkConfig, Optional[Path], Optional[Path]]:\n    \"\"\"Load a config for read-only scenarios.\"\"\"\n    resolved, stale = self.resolve_config_path(config_path)\n    if resolved is None:\n        # Fallback to creating a default one in memory if none exists on disk?\n        # Or return empty? Current behavior was \"using built-in defaults\".\n        # Let's use our dynamic defaults.\n        return self.create_default_config(), None, stale\n\n    cfg = BenchmarkConfig.load(resolved)\n    self._hydrate_config(cfg)\n    return cfg, resolved, stale\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.load_for_write","title":"load_for_write","text":"<pre><code>load_for_write(config_path, allow_create=True)\n</code></pre> <p>Load a config for mutation and return (config, target_path, stale_pointer, created_new).</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def load_for_write(\n    self,\n    config_path: Optional[Path],\n    allow_create: bool = True,\n) -&gt; Tuple[BenchmarkConfig, Path, Optional[Path], bool]:\n    \"\"\"\n    Load a config for mutation and return (config, target_path, stale_pointer, created_new).\n    \"\"\"\n    resolved, stale = self.resolve_config_path(config_path)\n    target = resolved or self.default_target\n    created = False\n\n    if target.exists():\n        cfg = BenchmarkConfig.load(target)\n        self._hydrate_config(cfg)\n    else:\n        if not allow_create:\n            raise FileNotFoundError(f\"Config file not found: {target}\")\n        target.parent.mkdir(parents=True, exist_ok=True)\n        cfg = self.create_default_config()\n        created = True\n\n    return cfg, target, stale, created\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.open_editor","title":"open_editor","text":"<pre><code>open_editor(config_path)\n</code></pre> <p>Open the resolved config file in the system editor.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def open_editor(self, config_path: Optional[Path]) -&gt; Path:\n    \"\"\"\n    Open the resolved config file in the system editor.\n    \"\"\"\n    resolved, stale = self.resolve_config_path(config_path)\n    if resolved is None:\n        raise FileNotFoundError(\"No config file found to edit. Run `lb config init` first.\")\n\n    editor = os.environ.get(\"EDITOR\")\n    if not editor:\n        raise EnvironmentError(f\"Set $EDITOR or open the file manually: {resolved}\")\n\n    try:\n        subprocess.run([editor, str(resolved)], check=False)\n    except Exception as exc:\n        raise RuntimeError(f\"Failed to launch editor: {exc}\") from exc\n\n    return resolved\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.read_saved_config_path","title":"read_saved_config_path","text":"<pre><code>read_saved_config_path()\n</code></pre> <p>Public wrapper returning (valid_path, stale_path).</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def read_saved_config_path(self) -&gt; Tuple[Optional[Path], Optional[Path]]:\n    \"\"\"Public wrapper returning (valid_path, stale_path).\"\"\"\n    return self._read_saved_config_path()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.remove_plugin","title":"remove_plugin","text":"<pre><code>remove_plugin(name, config)\n</code></pre> <p>Remove a plugin's workload and settings from a config file.</p> <p>Returns (config, target_path, stale_pointer, removed_flag).</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def remove_plugin(\n    self,\n    name: str,\n    config: Optional[Path],\n) -&gt; Tuple[BenchmarkConfig, Path, Optional[Path], bool]:\n    \"\"\"\n    Remove a plugin's workload and settings from a config file.\n\n    Returns (config, target_path, stale_pointer, removed_flag).\n    \"\"\"\n    cfg, target, stale, _ = self.load_for_write(config, allow_create=False)\n    removed = False\n    if name in cfg.workloads:\n        cfg.workloads.pop(name, None)\n        removed = True\n    if name in cfg.plugin_settings:\n        cfg.plugin_settings.pop(name, None)\n        removed = True\n    cfg.save(target)\n    return cfg, target, stale, removed\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.resolve_config_path","title":"resolve_config_path","text":"<pre><code>resolve_config_path(config_path)\n</code></pre> <p>Return (resolved_config, stale_pointer_target). Respects explicit path, environment variable LB_CONFIG_PATH, stored pointer, or local benchmark_config.json.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def resolve_config_path(self, config_path: Optional[Path]) -&gt; Tuple[Optional[Path], Optional[Path]]:\n    \"\"\"\n    Return (resolved_config, stale_pointer_target).\n    Respects explicit path, environment variable LB_CONFIG_PATH, stored pointer, or local benchmark_config.json.\n    \"\"\"\n    if config_path is not None:\n        return Path(config_path).expanduser(), None\n\n    env_path = os.environ.get(\"LB_CONFIG_PATH\")\n    if env_path:\n        return Path(env_path), None\n\n    saved, stale = self._read_saved_config_path()\n    if saved:\n        return saved, None\n    if stale:\n        return None, stale\n\n    local = Path(\"benchmark_config.json\")\n    if local.exists():\n        return local, None\n    if self.default_target.exists():\n        return self.default_target, None\n    return None, None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.update_workload_enabled","title":"update_workload_enabled","text":"<pre><code>update_workload_enabled(name, enabled, config, set_default)\n</code></pre> <p>Enable/disable workload and persist the config.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def update_workload_enabled(\n    self,\n    name: str,\n    enabled: bool,\n    config: Optional[Path],\n    set_default: bool,\n) -&gt; Tuple[BenchmarkConfig, Path, Optional[Path]]:\n    \"\"\"Enable/disable workload and persist the config.\"\"\"\n    cfg, target, stale, _ = self.load_for_write(config, allow_create=True)\n\n    # Enforce that the plugin exists if we are enabling it\n    if enabled:\n        from .plugin_service import create_registry\n\n        registry = create_registry()\n        if name not in registry.available():\n            raise ValueError(f\"Plugin '{name}' is not installed. Use `lb plugin list` to see available plugins.\")\n\n        # Initialize default config if missing\n        if name not in cfg.plugin_settings:\n            plugin = registry.get(name)\n            if hasattr(plugin, 'config_cls'):\n                cfg.plugin_settings[name] = plugin.config_cls()\n\n    workload = cfg.workloads.get(name) or WorkloadConfig(plugin=name, options={})\n    workload.enabled = enabled\n    cfg.workloads[name] = workload\n\n    # Save will serialize the config objects back to dicts/json automatically\n    cfg.save(target)\n\n    if set_default:\n        self.write_saved_config_path(target)\n    return cfg, target, stale\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ConfigService.write_saved_config_path","title":"write_saved_config_path","text":"<pre><code>write_saved_config_path(path)\n</code></pre> <p>Persist a pointer to the preferred config path.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def write_saved_config_path(self, path: Path) -&gt; None:\n    \"\"\"Persist a pointer to the preferred config path.\"\"\"\n    self.ensure_home()\n    self.pointer.write_text(str(path.expanduser()))\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerRunner","title":"ControllerRunner","text":"<pre><code>ControllerRunner(\n    run_callable,\n    stop_token=None,\n    on_state_change=None,\n    state_machine=None,\n)\n</code></pre> <p>Run a BenchmarkController in a dedicated thread with state tracking.</p> <p>Parameters:</p> Name Type Description Default <code>run_callable</code> <code>Callable[[], Any]</code> <p>A callable that executes the controller and returns a summary.</p> required <code>stop_token</code> <code>StopToken | None</code> <p>Optional stop token to request graceful termination.</p> <code>None</code> <code>on_state_change</code> <code>Optional[StateCallback]</code> <p>Optional callback invoked on every state transition.</p> <code>None</code> Source code in <code>lb_controller/adapters/remote_runner.py</code> <pre><code>def __init__(\n    self,\n    run_callable: Callable[[], Any],\n    stop_token: StopToken | None = None,\n    on_state_change: Optional[StateCallback] = None,\n    state_machine: ControllerStateMachine | None = None,\n) -&gt; None:\n    \"\"\"\n    Args:\n        run_callable: A callable that executes the controller and returns a summary.\n        stop_token: Optional stop token to request graceful termination.\n        on_state_change: Optional callback invoked on every state transition.\n    \"\"\"\n    self._run_callable = run_callable\n    self._stop_token = stop_token\n    self._machine = state_machine or ControllerStateMachine()\n    if on_state_change:\n        self._machine.register_callback(on_state_change)\n    self._thread: threading.Thread | None = None\n    self._result: Any = None\n    self._exception: BaseException | None = None\n    self._done = threading.Event()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerRunner-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.ControllerRunner.exception","title":"exception  <code>property</code>","text":"<pre><code>exception\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerRunner.result","title":"result  <code>property</code>","text":"<pre><code>result\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerRunner.state","title":"state  <code>property</code>","text":"<pre><code>state\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerRunner-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.ControllerRunner.arm_stop","title":"arm_stop","text":"<pre><code>arm_stop(reason=None)\n</code></pre> <p>Signal the controller to stop gracefully.</p> Source code in <code>lb_controller/adapters/remote_runner.py</code> <pre><code>def arm_stop(self, reason: str | None = None) -&gt; None:\n    \"\"\"Signal the controller to stop gracefully.\"\"\"\n    try:\n        self._machine.transition(ControllerState.STOP_ARMED, reason=reason)\n    except Exception:\n        # Ignore invalid transition; best-effort arming\n        pass\n    if self._stop_token:\n        try:\n            self._stop_token.request_stop()\n        except Exception:\n            pass\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerRunner.start","title":"start","text":"<pre><code>start()\n</code></pre> <p>Start the controller thread.</p> Source code in <code>lb_controller/adapters/remote_runner.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start the controller thread.\"\"\"\n    if self._thread and self._thread.is_alive():\n        return\n    self._thread = threading.Thread(target=self._run, name=\"lb-controller-runner\", daemon=True)\n    self._thread.start()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerRunner.wait","title":"wait","text":"<pre><code>wait(timeout=None)\n</code></pre> <p>Block until completion or timeout; re-raise exceptions from the worker.</p> Source code in <code>lb_controller/adapters/remote_runner.py</code> <pre><code>def wait(self, timeout: float | None = None) -&gt; Any:\n    \"\"\"Block until completion or timeout; re-raise exceptions from the worker.\"\"\"\n    finished = self._done.wait(timeout=timeout)\n    if not finished:\n        return None\n    if self._exception:\n        raise self._exception\n    return self._result\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState","title":"ControllerState","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Phase-aware controller lifecycle states.</p>"},{"location":"reference/controller/#lb_controller.api.ControllerState-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.ControllerState.ABORTED","title":"ABORTED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ABORTED = 'aborted'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.FAILED","title":"FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FAILED = 'failed'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.FINISHED","title":"FINISHED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FINISHED = 'finished'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.INIT","title":"INIT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>INIT = 'init'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.RUNNING_GLOBAL_SETUP","title":"RUNNING_GLOBAL_SETUP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RUNNING_GLOBAL_SETUP = 'running_global_setup'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.RUNNING_GLOBAL_TEARDOWN","title":"RUNNING_GLOBAL_TEARDOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RUNNING_GLOBAL_TEARDOWN = 'running_global_teardown'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.RUNNING_WORKLOADS","title":"RUNNING_WORKLOADS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RUNNING_WORKLOADS = 'running_workloads'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.STOPPING_INTERRUPT_SETUP","title":"STOPPING_INTERRUPT_SETUP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STOPPING_INTERRUPT_SETUP = 'stopping_interrupt_setup'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.STOPPING_INTERRUPT_TEARDOWN","title":"STOPPING_INTERRUPT_TEARDOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STOPPING_INTERRUPT_TEARDOWN = 'stopping_interrupt_teardown'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.STOPPING_TEARDOWN","title":"STOPPING_TEARDOWN  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STOPPING_TEARDOWN = 'stopping_teardown'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.STOPPING_WAIT_RUNNERS","title":"STOPPING_WAIT_RUNNERS  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STOPPING_WAIT_RUNNERS = 'stopping_wait_runners'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.STOP_ARMED","title":"STOP_ARMED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STOP_ARMED = 'stop_armed'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerState.STOP_FAILED","title":"STOP_FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>STOP_FAILED = 'stop_failed'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine","title":"ControllerStateMachine","text":"<pre><code>ControllerStateMachine()\n</code></pre> <p>Thread-safe controller state tracker.</p> Source code in <code>lb_controller/models/state.py</code> <pre><code>def __init__(self) -&gt; None:\n    self._state = ControllerState.INIT\n    self._lock = threading.RLock()\n    self._reason: Optional[str] = None\n    self._callbacks: list[Callable[[ControllerState, Optional[str]], None]] = []\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine.reason","title":"reason  <code>property</code>","text":"<pre><code>reason\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine.state","title":"state  <code>property</code>","text":"<pre><code>state\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine.allows_cleanup","title":"allows_cleanup","text":"<pre><code>allows_cleanup()\n</code></pre> Source code in <code>lb_controller/models/state.py</code> <pre><code>def allows_cleanup(self) -&gt; bool:\n    with self._lock:\n        return self._state in {\n            ControllerState.FINISHED,\n            ControllerState.ABORTED,\n        }\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine.is_terminal","title":"is_terminal","text":"<pre><code>is_terminal()\n</code></pre> Source code in <code>lb_controller/models/state.py</code> <pre><code>def is_terminal(self) -&gt; bool:\n    with self._lock:\n        return self._state in _TERMINAL_STATES\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine.register_callback","title":"register_callback","text":"<pre><code>register_callback(callback)\n</code></pre> <p>Register a callback invoked on every transition.</p> Source code in <code>lb_controller/models/state.py</code> <pre><code>def register_callback(\n    self, callback: Callable[[ControllerState, Optional[str]], None]\n) -&gt; None:\n    \"\"\"Register a callback invoked on every transition.\"\"\"\n    self._callbacks.append(callback)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine.snapshot","title":"snapshot","text":"<pre><code>snapshot()\n</code></pre> Source code in <code>lb_controller/models/state.py</code> <pre><code>def snapshot(self) -&gt; tuple[ControllerState, Optional[str]]:\n    with self._lock:\n        return self._state, self._reason\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.ControllerStateMachine.transition","title":"transition","text":"<pre><code>transition(new_state, reason=None)\n</code></pre> <p>Attempt a state transition; raise ValueError if invalid.</p> Source code in <code>lb_controller/models/state.py</code> <pre><code>def transition(\n    self, new_state: ControllerState, reason: Optional[str] = None\n) -&gt; ControllerState:\n    \"\"\"Attempt a state transition; raise ValueError if invalid.\"\"\"\n    with self._lock:\n        allowed = _ALLOWED_TRANSITIONS.get(self._state, set())\n        if new_state not in allowed and new_state not in {\n            ControllerState.FAILED,\n            ControllerState.ABORTED,\n            ControllerState.STOP_FAILED,\n        }:\n            raise ValueError(f\"Invalid transition {self._state} -&gt; {new_state}\")\n        self._state = new_state\n        self._reason = reason\n        for cb in list(self._callbacks):\n            try:\n                cb(self._state, self._reason)\n            except Exception:\n                continue\n        return self._state\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.DoubleCtrlCStateMachine","title":"DoubleCtrlCStateMachine  <code>dataclass</code>","text":"<pre><code>DoubleCtrlCStateMachine(state=RunInterruptState.RUNNING)\n</code></pre> <p>Double-press Ctrl+C confirmation state machine.</p> <p>Policy: the second Ctrl+C confirms stop at any time after the first press, until the run finishes (no timeout window).</p>"},{"location":"reference/controller/#lb_controller.api.DoubleCtrlCStateMachine-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.DoubleCtrlCStateMachine.state","title":"state  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>state = RUNNING\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.DoubleCtrlCStateMachine-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.DoubleCtrlCStateMachine.mark_finished","title":"mark_finished","text":"<pre><code>mark_finished()\n</code></pre> <p>Transition to FINISHED and disable further confirmation handling.</p> Source code in <code>lb_controller/engine/interrupts.py</code> <pre><code>def mark_finished(self) -&gt; None:\n    \"\"\"Transition to FINISHED and disable further confirmation handling.\"\"\"\n    self.state = RunInterruptState.FINISHED\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.DoubleCtrlCStateMachine.on_sigint","title":"on_sigint","text":"<pre><code>on_sigint(*, run_active)\n</code></pre> <p>Process a SIGINT and return what the caller should do next.</p> Source code in <code>lb_controller/engine/interrupts.py</code> <pre><code>def on_sigint(self, *, run_active: bool) -&gt; SigintDecision:\n    \"\"\"Process a SIGINT and return what the caller should do next.\"\"\"\n    if not run_active or self.state == RunInterruptState.FINISHED:\n        return SigintDecision.DELEGATE\n\n    if self.state == RunInterruptState.RUNNING:\n        self.state = RunInterruptState.STOP_ARMED\n        return SigintDecision.WARN_ARM\n\n    if self.state == RunInterruptState.STOP_ARMED:\n        self.state = RunInterruptState.STOPPING\n        return SigintDecision.REQUEST_STOP\n\n    # In STOPPING we swallow further Ctrl+C while the run is active to avoid\n    # tearing down the process; the caller can still expose an explicit exit.\n    return SigintDecision.IGNORE\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.DoubleCtrlCStateMachine.reset_arm","title":"reset_arm","text":"<pre><code>reset_arm()\n</code></pre> <p>Return to RUNNING from STOP_ARMED after a timeout window.</p> Source code in <code>lb_controller/engine/interrupts.py</code> <pre><code>def reset_arm(self) -&gt; None:\n    \"\"\"Return to RUNNING from STOP_ARMED after a timeout window.\"\"\"\n    if self.state == RunInterruptState.STOP_ARMED:\n        self.state = RunInterruptState.RUNNING\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.LogSink","title":"LogSink","text":"<pre><code>LogSink(journal, journal_path, log_file=None)\n</code></pre> <p>Persist events and mirror them to the run journal and optional stdout/log file.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def __init__(\n    self, journal: RunJournal, journal_path: Path, log_file: Path | None = None\n):\n    self.journal = journal\n    self.journal_path = journal_path\n    self.log_file = log_file\n    self._log_handle = None\n    if log_file:\n        log_file.parent.mkdir(parents=True, exist_ok=True)\n        self._log_handle = log_file.open(\"a\", encoding=\"utf-8\")\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.LogSink-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.LogSink.journal","title":"journal  <code>instance-attribute</code>","text":"<pre><code>journal = journal\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.LogSink.journal_path","title":"journal_path  <code>instance-attribute</code>","text":"<pre><code>journal_path = journal_path\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.LogSink.log_file","title":"log_file  <code>instance-attribute</code>","text":"<pre><code>log_file = log_file\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.LogSink-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.LogSink.close","title":"close","text":"<pre><code>close()\n</code></pre> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def close(self) -&gt; None:\n    if self._log_handle:\n        try:\n            self._log_handle.close()\n        except Exception:\n            pass\n        self._log_handle = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.LogSink.emit","title":"emit","text":"<pre><code>emit(event)\n</code></pre> <p>Handle a single event.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def emit(self, event: RunEvent) -&gt; None:\n    \"\"\"Handle a single event.\"\"\"\n    self._update_journal(event)\n    self._write_log(event)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.LogSink.emit_many","title":"emit_many","text":"<pre><code>emit_many(events)\n</code></pre> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def emit_many(self, events: Iterable[RunEvent]) -&gt; None:\n    for ev in events:\n        self.emit(ev)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.PluginInstaller","title":"PluginInstaller","text":"<pre><code>PluginInstaller()\n</code></pre> <p>Helper to install and uninstall user plugins.</p> Source code in <code>lb_controller/services/plugin_service.py</code> <pre><code>def __init__(self):\n    self.plugin_dir = resolve_user_plugin_dir()\n    self.plugin_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.PluginInstaller-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.PluginInstaller.plugin_dir","title":"plugin_dir  <code>instance-attribute</code>","text":"<pre><code>plugin_dir = resolve_user_plugin_dir()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.PluginInstaller-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.PluginInstaller.install","title":"install","text":"<pre><code>install(source_path, manifest_path=None, force=False)\n</code></pre> <p>Install a plugin from a file (.py), directory, archive (.zip, .tar.gz), or git URL. Returns the name of the installed plugin.</p> Source code in <code>lb_controller/services/plugin_service.py</code> <pre><code>def install(self, source_path: Union[Path, str], manifest_path: Optional[Path] = None, force: bool = False) -&gt; str:\n    \"\"\"\n    Install a plugin from a file (.py), directory, archive (.zip, .tar.gz), or git URL.\n    Returns the name of the installed plugin.\n    \"\"\"\n    if isinstance(source_path, Path):\n        raw_source = str(source_path)\n    else:\n        raw_source = source_path\n\n    if self._looks_like_git_url(raw_source):\n        return self._install_from_git(raw_source, force)\n\n    source_path = Path(raw_source).resolve()\n    if not source_path.exists():\n        raise FileNotFoundError(f\"Source not found: {source_path}\")\n\n    if source_path.is_dir():\n        return self._install_directory(source_path, force)\n\n    if source_path.suffix == \".py\":\n        return self._install_file(source_path, manifest_path, force)\n\n    if self._is_supported_archive(source_path):\n        return self._install_archive(source_path, force)\n\n    raise ValueError(\n        f\"Unsupported source: {source_path}. Expected a .py file, directory, or archive (.zip/.tar.gz)\"\n    )\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.PluginInstaller.package","title":"package","text":"<pre><code>package(source_dir, output_path=None)\n</code></pre> <p>Create a compressed plugin archive (.tar.gz) from a directory. Returns the path to the created archive.</p> Source code in <code>lb_controller/services/plugin_service.py</code> <pre><code>def package(self, source_dir: Path, output_path: Optional[Path] = None) -&gt; Path:\n    \"\"\"\n    Create a compressed plugin archive (.tar.gz) from a directory.\n    Returns the path to the created archive.\n    \"\"\"\n    source_dir = Path(source_dir).resolve()\n    if not source_dir.is_dir():\n        raise ValueError(f\"Source directory not found: {source_dir}\")\n\n    target = Path(output_path).resolve() if output_path else Path(tempfile.mkdtemp()) / f\"{source_dir.name}.tar.gz\"\n    return self._package_directory(source_dir, target)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.PluginInstaller.uninstall","title":"uninstall","text":"<pre><code>uninstall(plugin_name)\n</code></pre> <p>Uninstall a user plugin by name.  Removes the plugin directory (if valid) or the .py/.yaml files.</p> Source code in <code>lb_controller/services/plugin_service.py</code> <pre><code>def uninstall(self, plugin_name: str) -&gt; bool:\n    \"\"\"\n    Uninstall a user plugin by name. \n    Removes the plugin directory (if valid) or the .py/.yaml files.\n    \"\"\"\n    target_py = self.plugin_dir / f\"{plugin_name}.py\"\n    target_yaml = self.plugin_dir / f\"{plugin_name}.yaml\"\n    target_yml = self.plugin_dir / f\"{plugin_name}.yml\"\n    target_dir = self.plugin_dir / plugin_name\n\n    found = False\n\n    # 1. Check for directory plugin\n    if target_dir.exists() and target_dir.is_dir():\n        shutil.rmtree(target_dir)\n        logger.info(f\"Removed plugin directory: {target_dir}\")\n        found = True\n\n    # 2. Check for single file plugin\n    if target_py.exists():\n        target_py.unlink()\n        logger.info(f\"Removed plugin source: {target_py}\")\n        found = True\n\n    for manifest in [target_yaml, target_yml]:\n        if manifest.exists():\n            manifest.unlink()\n            logger.info(f\"Removed plugin manifest: {manifest}\")\n\n    if not found:\n        logger.warning(f\"Plugin '{plugin_name}' not found in user directory.\")\n\n    return found\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunCatalogService","title":"RunCatalogService","text":"<pre><code>RunCatalogService(\n    output_dir, report_dir=None, data_export_dir=None\n)\n</code></pre> <p>Discover run directories and their basic metadata.</p> Source code in <code>lb_controller/services/run_catalog_service.py</code> <pre><code>def __init__(\n    self,\n    output_dir: Path,\n    report_dir: Optional[Path] = None,\n    data_export_dir: Optional[Path] = None,\n) -&gt; None:\n    self.output_dir = output_dir.resolve()\n    self.report_dir = report_dir.resolve() if report_dir else None\n    self.data_export_dir = data_export_dir.resolve() if data_export_dir else None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunCatalogService-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.RunCatalogService.data_export_dir","title":"data_export_dir  <code>instance-attribute</code>","text":"<pre><code>data_export_dir = resolve() if data_export_dir else None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunCatalogService.output_dir","title":"output_dir  <code>instance-attribute</code>","text":"<pre><code>output_dir = resolve()\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunCatalogService.report_dir","title":"report_dir  <code>instance-attribute</code>","text":"<pre><code>report_dir = resolve() if report_dir else None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunCatalogService-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.RunCatalogService.get_run","title":"get_run","text":"<pre><code>get_run(run_id)\n</code></pre> <p>Return RunInfo for the given run_id if present.</p> Source code in <code>lb_controller/services/run_catalog_service.py</code> <pre><code>def get_run(self, run_id: str) -&gt; Optional[RunInfo]:\n    \"\"\"Return RunInfo for the given run_id if present.\"\"\"\n    output_root = self._resolve_output_root(run_id)\n    if output_root is None:\n        return None\n\n    report_root = self._resolve_optional_root(self.report_dir, run_id)\n    export_root = self._resolve_optional_root(self.data_export_dir, run_id)\n\n    journal_path = output_root / \"run_journal.json\"\n    journal_data = self._load_journal(journal_path)\n    created_at = self._extract_created_at(journal_data)\n    hosts, workloads = self._extract_hosts_workloads(journal_data)\n\n    if not hosts:\n        hosts = self._fallback_hosts(output_root)\n    if not workloads and hosts:\n        workloads = self._fallback_workloads(output_root, hosts)\n\n    return RunInfo(\n        run_id=run_id,\n        output_root=output_root,\n        report_root=self._existing_or_none(report_root),\n        data_export_root=self._existing_or_none(export_root),\n        hosts=sorted(hosts),\n        workloads=sorted(workloads),\n        created_at=created_at,\n        journal_path=journal_path if journal_path.exists() else None,\n    )\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunCatalogService.list_runs","title":"list_runs","text":"<pre><code>list_runs()\n</code></pre> <p>Return all runs found under output_dir, newest first when possible.</p> Source code in <code>lb_controller/services/run_catalog_service.py</code> <pre><code>def list_runs(self) -&gt; List[RunInfo]:\n    \"\"\"Return all runs found under output_dir, newest first when possible.\"\"\"\n    if not self.output_dir.exists():\n        return []\n\n    runs: List[RunInfo] = []\n    for item in self.output_dir.iterdir():\n        if not item.is_dir():\n            continue\n        run_id = item.name\n        if not run_id.startswith(\"run-\"):\n            continue\n        info = self.get_run(run_id)\n        if info:\n            runs.append(info)\n\n    runs.sort(\n        key=lambda r: r.created_at.timestamp() if r.created_at else 0.0,\n        reverse=True,\n    )\n    return runs\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary","title":"RunExecutionSummary  <code>dataclass</code>","text":"<pre><code>RunExecutionSummary(\n    run_id,\n    per_host_output,\n    phases,\n    success,\n    output_root,\n    report_root,\n    data_export_root,\n    controller_state=None,\n    cleanup_allowed=False,\n)\n</code></pre> <p>Summary of a complete controller run.</p>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.cleanup_allowed","title":"cleanup_allowed  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cleanup_allowed = False\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.controller_state","title":"controller_state  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>controller_state = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.data_export_root","title":"data_export_root  <code>instance-attribute</code>","text":"<pre><code>data_export_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.output_root","title":"output_root  <code>instance-attribute</code>","text":"<pre><code>output_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.per_host_output","title":"per_host_output  <code>instance-attribute</code>","text":"<pre><code>per_host_output\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.phases","title":"phases  <code>instance-attribute</code>","text":"<pre><code>phases\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.report_root","title":"report_root  <code>instance-attribute</code>","text":"<pre><code>report_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.run_id","title":"run_id  <code>instance-attribute</code>","text":"<pre><code>run_id\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunExecutionSummary.success","title":"success  <code>instance-attribute</code>","text":"<pre><code>success\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunInfo","title":"RunInfo  <code>dataclass</code>","text":"<pre><code>RunInfo(\n    run_id,\n    output_root,\n    report_root,\n    data_export_root,\n    hosts,\n    workloads,\n    created_at,\n    journal_path,\n)\n</code></pre> <p>Lightweight metadata about a benchmark run.</p>"},{"location":"reference/controller/#lb_controller.api.RunInfo-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.RunInfo.created_at","title":"created_at  <code>instance-attribute</code>","text":"<pre><code>created_at\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunInfo.data_export_root","title":"data_export_root  <code>instance-attribute</code>","text":"<pre><code>data_export_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunInfo.hosts","title":"hosts  <code>instance-attribute</code>","text":"<pre><code>hosts\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunInfo.journal_path","title":"journal_path  <code>instance-attribute</code>","text":"<pre><code>journal_path\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunInfo.output_root","title":"output_root  <code>instance-attribute</code>","text":"<pre><code>output_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunInfo.report_root","title":"report_root  <code>instance-attribute</code>","text":"<pre><code>report_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunInfo.run_id","title":"run_id  <code>instance-attribute</code>","text":"<pre><code>run_id\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunInfo.workloads","title":"workloads  <code>instance-attribute</code>","text":"<pre><code>workloads\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal","title":"RunJournal  <code>dataclass</code>","text":"<pre><code>RunJournal(run_id, tasks=dict(), metadata=dict())\n</code></pre> <p>Contains the entire execution plan and state.</p>"},{"location":"reference/controller/#lb_controller.api.RunJournal-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.RunJournal.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata = field(default_factory=dict)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.run_id","title":"run_id  <code>instance-attribute</code>","text":"<pre><code>run_id\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.tasks","title":"tasks  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tasks = field(default_factory=dict)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.RunJournal.add_task","title":"add_task","text":"<pre><code>add_task(task)\n</code></pre> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def add_task(self, task: TaskState) -&gt; None:\n    self.tasks[task.key] = task\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.get_task","title":"get_task","text":"<pre><code>get_task(host, workload, rep)\n</code></pre> <p>Return a specific task or None when absent.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def get_task(self, host: str, workload: str, rep: int) -&gt; Optional[TaskState]:\n    \"\"\"Return a specific task or None when absent.\"\"\"\n    key = f\"{host}::{workload}::{rep}\"\n    return self.tasks.get(key)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.get_tasks_by_host","title":"get_tasks_by_host","text":"<pre><code>get_tasks_by_host(host)\n</code></pre> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def get_tasks_by_host(self, host: str) -&gt; List[TaskState]:\n    return sorted(\n        [t for t in self.tasks.values() if t.host == host],\n        key=lambda x: x.repetition,\n    )\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.initialize","title":"initialize  <code>classmethod</code>","text":"<pre><code>initialize(run_id, config, test_types)\n</code></pre> <p>Factory to create a new journal based on configuration.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>@classmethod\ndef initialize(\n    cls, run_id: str, config: Any, test_types: List[str]\n) -&gt; \"RunJournal\":\n    \"\"\"Factory to create a new journal based on configuration.\"\"\"\n    journal = cls(run_id=run_id)\n    cfg_dump = _config_dump(config)\n    journal.metadata = {\n        \"created_at\": datetime.now().isoformat(),\n        \"config_summary\": str(config),  # Simple representation\n        \"repetitions\": getattr(config, \"repetitions\", None),\n        \"system_info\": {},  # host -&gt; summary string/path mapping\n        \"config_dump\": cfg_dump,\n        \"config_hash\": _config_hash(cfg_dump),\n    }\n\n    # Pre-populate tasks based on config\n    # We iterate test_types order to keep logical sequence\n    hosts = (\n        config.remote_hosts\n        if getattr(config, \"remote_hosts\", None)\n        else [SimpleNamespace(name=\"localhost\")]\n    )\n    for test_name in test_types:\n        if test_name not in config.workloads:\n            continue\n\n        for host in hosts:\n            for rep in range(1, config.repetitions + 1):\n                task = TaskState(\n                    host=host.name,\n                    workload=test_name,\n                    repetition=rep,\n                    status=RunStatus.PENDING,\n                )\n                journal.add_task(task)\n    return journal\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(path, config=None)\n</code></pre> <p>Load journal from disk, optionally validating against a config.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>@classmethod\ndef load(cls, path: Path, config: Any | None = None) -&gt; \"RunJournal\":\n    \"\"\"Load journal from disk, optionally validating against a config.\"\"\"\n    with open(path, \"r\") as f:\n        data = json.load(f)\n\n    metadata = data.get(\"metadata\", {}) or {}\n    cfg_dump = metadata.get(\"config_dump\")\n    cfg_hash = metadata.get(\"config_hash\")\n\n    if config is not None:\n        expected_reps = metadata.get(\"repetitions\")\n        if expected_reps and getattr(config, \"repetitions\", None) != expected_reps:\n            raise ValueError(\n                \"Config does not match journal repetitions; aborting resume.\"\n            )\n        if cfg_hash and cfg_dump:\n            current_dump = _config_dump(config)\n            current_hash = _config_hash(current_dump)\n            if current_hash != cfg_hash:\n                raise ValueError(\n                    \"Config hash mismatch for resume; supply matching config or rely on journal config_dump.\"\n                )\n    tasks_data = data.pop(\"tasks\", [])\n    journal = cls(**data)\n    journal.tasks = {}\n    for t in tasks_data:\n        task = TaskState(**t)\n        journal.tasks[task.key] = task\n    if not getattr(journal, \"metadata\", None):\n        journal.metadata = metadata\n    return journal\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.rehydrate_config","title":"rehydrate_config","text":"<pre><code>rehydrate_config()\n</code></pre> <p>Return a BenchmarkConfig reconstructed from the stored config_dump.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def rehydrate_config(self) -&gt; BenchmarkConfig | None:\n    \"\"\"\n    Return a BenchmarkConfig reconstructed from the stored config_dump.\n    \"\"\"\n    cfg_dump = (self.metadata or {}).get(\"config_dump\")\n    if not cfg_dump:\n        return None\n    try:\n        return BenchmarkConfig.model_validate(cfg_dump)\n    except Exception:\n        return None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.save","title":"save","text":"<pre><code>save(path)\n</code></pre> <p>Persist journal to disk.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def save(self, path: Path) -&gt; None:\n    \"\"\"Persist journal to disk.\"\"\"\n    data = asdict(self)\n    # Ensure path exists\n    if isinstance(path, str):\n        path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    serialized = data.copy()\n    serialized[\"tasks\"] = [asdict(task) for task in self.tasks.values()]\n\n    with open(path, \"w\") as f:\n        json.dump(serialized, f, indent=2, default=str)\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.should_run","title":"should_run","text":"<pre><code>should_run(host, workload, rep)\n</code></pre> <p>Determines if a task should be executed. Returns True if task is PENDING or FAILED (and we want to retry). For now, we skip COMPLETED tasks.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def should_run(self, host: str, workload: str, rep: int) -&gt; bool:\n    \"\"\"\n    Determines if a task should be executed.\n    Returns True if task is PENDING or FAILED (and we want to retry).\n    For now, we skip COMPLETED tasks.\n    \"\"\"\n    task = self.get_task(host, workload, rep)\n    if task:\n        return task.status not in (RunStatus.COMPLETED, RunStatus.SKIPPED)\n    # If task not found, it's technically new, so run it (though this shouldn't happen if initialized correctly)\n    return True\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunJournal.update_task","title":"update_task","text":"<pre><code>update_task(\n    host, workload, rep, status, action=\"\", error=None\n)\n</code></pre> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def update_task(\n    self,\n    host: str,\n    workload: str,\n    rep: int,\n    status: str,\n    action: str = \"\",\n    error: Optional[str] = None,\n) -&gt; None:\n    task = self.get_task(host, workload, rep)\n    if not task:\n        return\n    now_ts = datetime.now().timestamp()\n    self._update_task_timings(task, status, now_ts)\n    task.status = status\n    task.timestamp = now_ts\n    if action:\n        task.current_action = action\n    if error:\n        task.error = error\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunStatus","title":"RunStatus","text":""},{"location":"reference/controller/#lb_controller.api.RunStatus-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.RunStatus.COMPLETED","title":"COMPLETED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>COMPLETED = 'COMPLETED'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunStatus.FAILED","title":"FAILED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>FAILED = 'FAILED'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunStatus.PENDING","title":"PENDING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>PENDING = 'PENDING'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunStatus.RUNNING","title":"RUNNING  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>RUNNING = 'RUNNING'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.RunStatus.SKIPPED","title":"SKIPPED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SKIPPED = 'SKIPPED'\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.SigintDoublePressHandler","title":"SigintDoublePressHandler","text":"<pre><code>SigintDoublePressHandler(\n    *,\n    state_machine,\n    run_active,\n    on_first_sigint,\n    on_confirmed_sigint\n)\n</code></pre> <p>               Bases: <code>AbstractContextManager['SigintDoublePressHandler']</code></p> <p>Installs a SIGINT handler that implements double-press confirmation.</p> Source code in <code>lb_controller/engine/interrupts.py</code> <pre><code>def __init__(\n    self,\n    *,\n    state_machine: DoubleCtrlCStateMachine,\n    run_active: Callable[[], bool],\n    on_first_sigint: Callable[[], None],\n    on_confirmed_sigint: Callable[[], None],\n) -&gt; None:\n    self._sm = state_machine\n    self._run_active = run_active\n    self._on_first = on_first_sigint\n    self._on_confirmed = on_confirmed_sigint\n    self._prev_handler: Any = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState","title":"TaskState  <code>dataclass</code>","text":"<pre><code>TaskState(\n    host,\n    workload,\n    repetition,\n    status=RunStatus.PENDING,\n    current_action=\"\",\n    timestamp=(lambda: datetime.now().timestamp())(),\n    error=None,\n    started_at=None,\n    finished_at=None,\n    duration_seconds=None,\n)\n</code></pre> <p>Represents a single atomic unit of work (Host + Workload + Repetition).</p>"},{"location":"reference/controller/#lb_controller.api.TaskState-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.api.TaskState.current_action","title":"current_action  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>current_action = ''\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.duration_seconds","title":"duration_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>duration_seconds = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.error","title":"error  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>error = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.finished_at","title":"finished_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>finished_at = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.host","title":"host  <code>instance-attribute</code>","text":"<pre><code>host\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.key","title":"key  <code>property</code>","text":"<pre><code>key\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.repetition","title":"repetition  <code>instance-attribute</code>","text":"<pre><code>repetition\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.started_at","title":"started_at  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>started_at = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.status","title":"status  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>status = PENDING\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp = field(default_factory=lambda: timestamp())\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.TaskState.workload","title":"workload  <code>instance-attribute</code>","text":"<pre><code>workload\n</code></pre>"},{"location":"reference/controller/#lb_controller.api-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.api.build_plugin_table","title":"build_plugin_table","text":"<pre><code>build_plugin_table(registry, enabled=None)\n</code></pre> <p>Return headers and rows describing available workload plugins.</p> <p>The caller is responsible for rendering the table via its own UI adapter.</p> Source code in <code>lb_controller/services/plugin_service.py</code> <pre><code>def build_plugin_table(registry: PluginRegistry, enabled: Optional[Dict[str, bool]] = None) -&gt; tuple[List[str], List[List[str]]]:\n    \"\"\"\n    Return headers and rows describing available workload plugins.\n\n    The caller is responsible for rendering the table via its own UI adapter.\n    \"\"\"\n    rows: List[List[str]] = []\n    for name, plugin in sorted(registry.available(load_entrypoints=True).items()):\n        description = getattr(plugin, \"description\", \"\")\n        config_name = plugin.config_cls.__name__\n        if enabled is None:\n            rows.append([name, description, config_name])\n        else:\n            status = \"\u2713\" if enabled.get(name) else \"\u2717\"\n            rows.append([name, status, description, config_name])\n\n    headers: List[str] = [\"Name\", \"Description\", \"Config\"]\n    if enabled is not None:\n        headers.insert(1, \"Enabled\")\n    return headers, rows\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.create_registry","title":"create_registry","text":"<pre><code>create_registry(refresh=False)\n</code></pre> <p>Build a plugin registry with built-ins, entry points, and user plugins.</p> Source code in <code>lb_controller/services/plugin_service.py</code> <pre><code>def create_registry(refresh: bool = False) -&gt; PluginRegistry:\n    \"\"\"\n    Build a plugin registry with built-ins, entry points, and user plugins.\n    \"\"\"\n    global _REGISTRY_CACHE\n    if not refresh and _REGISTRY_CACHE is not None:\n        return _REGISTRY_CACHE\n    _REGISTRY_CACHE = PluginRegistry(builtin_plugins())\n    return _REGISTRY_CACHE\n</code></pre>"},{"location":"reference/controller/#lb_controller.api.pending_exists","title":"pending_exists","text":"<pre><code>pending_exists(journal, tests, hosts, repetitions)\n</code></pre> <p>Return True if any repetition remains to run.</p> Source code in <code>lb_controller/models/pending.py</code> <pre><code>def pending_exists(\n    journal: RunJournal,\n    tests: Iterable[str],\n    hosts: Sequence[RemoteHostConfig],\n    repetitions: int,\n) -&gt; bool:\n    \"\"\"Return True if any repetition remains to run.\"\"\"\n    for host in hosts:\n        for test_name in tests:\n            for rep in range(1, repetitions + 1):\n                if journal.should_run(host.name, test_name, rep):\n                    return True\n    return False\n</code></pre>"},{"location":"reference/controller/#benchmark-controller","title":"Benchmark controller","text":""},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController","title":"BenchmarkController","text":"<pre><code>BenchmarkController(\n    config,\n    executor=None,\n    output_callback=None,\n    output_formatter=None,\n    journal_refresh=None,\n    stop_token=None,\n    stop_timeout_s=30.0,\n    state_machine=None,\n)\n</code></pre> <p>Controller coordinating remote benchmark runs.</p> Source code in <code>lb_controller/engine/controller.py</code> <pre><code>def __init__(\n    self,\n    config: BenchmarkConfig,\n    executor: Optional[RemoteExecutor] = None,\n    output_callback: Optional[Callable[[str, str], None]] = None,\n    output_formatter: Optional[Any] = None,  # Inject the formatter instance\n    journal_refresh: Optional[Callable[[], None]] = None,\n    stop_token: StopToken | None = None,\n    stop_timeout_s: float = 30.0,\n    state_machine: ControllerStateMachine | None = None,\n):\n    self.config = config\n    self.output_formatter = output_formatter\n    self.stop_token = stop_token\n    self._stop_timeout_s = stop_timeout_s\n    self.lifecycle = RunLifecycle()\n    self.state_machine = state_machine or ControllerStateMachine()\n    # Enable streaming if a callback is provided\n    stream = output_callback is not None\n    self.executor = executor or AnsibleRunnerExecutor(\n        output_callback=output_callback,\n        stream_output=stream,\n        stop_token=stop_token,\n    )\n    self.plugin_registry = create_registry()\n    self._journal_refresh = journal_refresh\n    # Use event stream as the source of truth; avoid mass RUNNING/COMPLETED updates.\n    self._use_progress_stream = True\n    self.coordinator: Optional[StopCoordinator] = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.coordinator","title":"coordinator  <code>instance-attribute</code>","text":"<pre><code>coordinator = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.executor","title":"executor  <code>instance-attribute</code>","text":"<pre><code>executor = executor or AnsibleRunnerExecutor(\n    output_callback=output_callback,\n    stream_output=stream,\n    stop_token=stop_token,\n)\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.lifecycle","title":"lifecycle  <code>instance-attribute</code>","text":"<pre><code>lifecycle = RunLifecycle()\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.output_formatter","title":"output_formatter  <code>instance-attribute</code>","text":"<pre><code>output_formatter = output_formatter\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.plugin_registry","title":"plugin_registry  <code>instance-attribute</code>","text":"<pre><code>plugin_registry = create_registry()\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.state_machine","title":"state_machine  <code>instance-attribute</code>","text":"<pre><code>state_machine = state_machine or ControllerStateMachine()\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.stop_token","title":"stop_token  <code>instance-attribute</code>","text":"<pre><code>stop_token = stop_token\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.on_event","title":"on_event","text":"<pre><code>on_event(event)\n</code></pre> <p>Process an event for stop coordination.</p> Source code in <code>lb_controller/engine/controller.py</code> <pre><code>def on_event(self, event: RunEvent) -&gt; None:\n    \"\"\"Process an event for stop coordination.\"\"\"\n    if self.coordinator:\n        self.coordinator.process_event(event)\n</code></pre>"},{"location":"reference/controller/#lb_controller.engine.controller.BenchmarkController.run","title":"run","text":"<pre><code>run(\n    test_types,\n    run_id=None,\n    journal=None,\n    resume=False,\n    journal_path=None,\n)\n</code></pre> <p>Execute the configured benchmarks on remote hosts.</p> <p>Parameters:</p> Name Type Description Default <code>test_types</code> <code>List[str]</code> <p>List of benchmark identifiers to execute.</p> required <code>run_id</code> <code>Optional[str]</code> <p>Optional run identifier. If not provided, a timestamp-based id is generated.</p> <code>None</code> <code>journal</code> <code>Optional[RunJournal]</code> <p>Optional pre-loaded journal used for resume flows.</p> <code>None</code> <code>resume</code> <code>bool</code> <p>When True, reuse the provided journal instead of creating a new one.</p> <code>False</code> <code>journal_path</code> <code>Optional[Path]</code> <p>Optional override for where the journal is persisted.</p> <code>None</code> Source code in <code>lb_controller/engine/controller.py</code> <pre><code>def run(\n    self,\n    test_types: List[str],\n    run_id: Optional[str] = None,\n    journal: Optional[RunJournal] = None,\n    resume: bool = False,\n    journal_path: Optional[Path] = None,\n) -&gt; RunExecutionSummary:\n    \"\"\"\n    Execute the configured benchmarks on remote hosts.\n\n    Args:\n        test_types: List of benchmark identifiers to execute.\n        run_id: Optional run identifier. If not provided, a timestamp-based\n            id is generated.\n        journal: Optional pre-loaded journal used for resume flows.\n        resume: When True, reuse the provided journal instead of creating a new one.\n        journal_path: Optional override for where the journal is persisted.\n    \"\"\"\n    if not self.config.remote_hosts:\n        raise ValueError(\"At least one remote host must be configured.\")\n    if resume and journal is None:\n        raise ValueError(\"Resume requested without a journal instance.\")\n\n    phases: Dict[str, ExecutionResult] = {}\n    flags = _RunFlags()\n    state = self._prepare_run_state(test_types, run_id, journal, journal_path)\n\n    def ui_log(msg: str) -&gt; None:\n        logger.info(msg)\n\n    ui_log(f\"Starting Run {state.resolved_run_id}\")\n\n    if self.config.remote_execution.run_setup:\n        early_summary = self._run_global_setup(state, phases, flags, ui_log)\n        if early_summary:\n            return early_summary\n\n    if (\n        not self._stop_requested()\n        and self.state_machine.state != ControllerState.RUNNING_WORKLOADS\n    ):\n        self._transition(ControllerState.RUNNING_WORKLOADS)\n\n    flags = self._run_workloads(state, phases, flags, ui_log)\n    self._run_global_teardown(state, phases, flags, ui_log)\n\n    ui_log(\"Run Finished.\")\n    time.sleep(1)\n\n    self.lifecycle.finish()\n    return self._build_summary(state, phases, flags)\n</code></pre>"},{"location":"reference/controller/#ansible-executor","title":"Ansible executor","text":""},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor","title":"AnsibleRunnerExecutor","text":"<pre><code>AnsibleRunnerExecutor(\n    private_data_dir=None,\n    runner_fn=None,\n    stream_output=False,\n    output_callback=None,\n    stop_token=None,\n)\n</code></pre> <p>               Bases: <code>RemoteExecutor</code></p> <p>Remote executor implemented with ansible-runner.</p> <p>Initialize the executor.</p> <p>Parameters:</p> Name Type Description Default <code>private_data_dir</code> <code>Optional[Path]</code> <p>Directory used by ansible-runner.</p> <code>None</code> <code>runner_fn</code> <code>Optional[Callable[..., Any]]</code> <p>Optional runner callable for testing. Defaults to ansible_runner.run when not provided.</p> <code>None</code> <code>stream_output</code> <code>bool</code> <p>When True, stream Ansible stdout events to the local process (useful for visibility in long-running tasks).</p> <code>False</code> <code>output_callback</code> <code>Optional[Callable[[str, str], None]]</code> <p>Optional callback to handle stdout stream.              Signature: (text: str, end: str) -&gt; None</p> <code>None</code> Source code in <code>lb_controller/adapters/ansible_runner.py</code> <pre><code>def __init__(\n    self,\n    private_data_dir: Optional[Path] = None,\n    runner_fn: Optional[Callable[..., Any]] = None,\n    stream_output: bool = False,\n    output_callback: Optional[Callable[[str, str], None]] = None,\n    stop_token: StopToken | None = None,\n):\n    \"\"\"\n    Initialize the executor.\n\n    Args:\n        private_data_dir: Directory used by ansible-runner.\n        runner_fn: Optional runner callable for testing. Defaults to\n            ansible_runner.run when not provided.\n        stream_output: When True, stream Ansible stdout events to the local\n            process (useful for visibility in long-running tasks).\n        output_callback: Optional callback to handle stdout stream.\n                         Signature: (text: str, end: str) -&gt; None\n    \"\"\"\n    self.private_data_dir = private_data_dir or Path(\".ansible_runner\")\n    self.private_data_dir.mkdir(parents=True, exist_ok=True)\n    self.event_log_path = self.private_data_dir / \"lb_events.jsonl\"\n    self._runner_fn = runner_fn\n    self.stream_output = stream_output\n    self.stop_token = stop_token\n    self._interrupt_flag = threading.Event()\n    self._active_process: subprocess.Popen[str] | None = None\n    self._active_label: str | None = None\n    self._lock = threading.Lock()\n    # Force Ansible temp into a writable location inside the runner dir to avoid host-level permission issues\n    self.local_tmp = self.private_data_dir / \"tmp\"\n    self.local_tmp.mkdir(parents=True, exist_ok=True)\n    if stream_output and output_callback is None:\n        # Default to streaming to stdout when caller requests streaming but\n        # doesn't provide a handler.\n        def _default_cb(text: str, end: str = \"\") -&gt; None:\n            sys.stdout.write(text + end)\n            sys.stdout.flush()\n\n        self.output_callback = _default_cb\n    else:\n        self.output_callback = output_callback\n</code></pre>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.event_log_path","title":"event_log_path  <code>instance-attribute</code>","text":"<pre><code>event_log_path = private_data_dir / 'lb_events.jsonl'\n</code></pre>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.is_running","title":"is_running  <code>property</code>","text":"<pre><code>is_running\n</code></pre> <p>Return True when a playbook is in-flight.</p>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.local_tmp","title":"local_tmp  <code>instance-attribute</code>","text":"<pre><code>local_tmp = private_data_dir / 'tmp'\n</code></pre>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.output_callback","title":"output_callback  <code>instance-attribute</code>","text":"<pre><code>output_callback = _default_cb\n</code></pre>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.private_data_dir","title":"private_data_dir  <code>instance-attribute</code>","text":"<pre><code>private_data_dir = private_data_dir or Path(\n    \".ansible_runner\"\n)\n</code></pre>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.stop_token","title":"stop_token  <code>instance-attribute</code>","text":"<pre><code>stop_token = stop_token\n</code></pre>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.stream_output","title":"stream_output  <code>instance-attribute</code>","text":"<pre><code>stream_output = stream_output\n</code></pre>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.interrupt","title":"interrupt","text":"<pre><code>interrupt()\n</code></pre> <p>Request interruption of the current playbook execution.</p> Source code in <code>lb_controller/adapters/ansible_runner.py</code> <pre><code>def interrupt(self) -&gt; None:\n    \"\"\"Request interruption of the current playbook execution.\"\"\"\n    self._interrupt_flag.set()\n    with self._lock:\n        proc = self._active_process\n    if proc and proc.poll() is None:\n        try:\n            proc.terminate()\n        except Exception:\n            try:\n                proc.kill()\n            except Exception:\n                pass\n    with self._lock:\n        self._active_process = None\n        self._active_label = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.adapters.ansible_runner.AnsibleRunnerExecutor.run_playbook","title":"run_playbook","text":"<pre><code>run_playbook(\n    playbook_path,\n    inventory,\n    extravars=None,\n    tags=None,\n    limit_hosts=None,\n    *,\n    cancellable=True\n)\n</code></pre> <p>Execute a playbook using ansible-runner.</p> Source code in <code>lb_controller/adapters/ansible_runner.py</code> <pre><code>def run_playbook(\n    self,\n    playbook_path: Path,\n    inventory: InventorySpec,\n    extravars: Optional[Dict[str, Any]] = None,\n    tags: Optional[List[str]] = None,\n    limit_hosts: Optional[List[str]] = None,\n    *,\n    cancellable: bool = True,\n) -&gt; ExecutionResult:\n    \"\"\"Execute a playbook using ansible-runner.\"\"\"\n    self._interrupt_flag.clear()\n    if cancellable and (\n        self._interrupt_flag.is_set()\n        or (self.stop_token and self.stop_token.should_stop())\n    ):\n        return ExecutionResult(rc=1, status=\"stopped\", stats={})\n    if not playbook_path.exists():\n        raise FileNotFoundError(f\"Playbook not found: {playbook_path}\")\n\n    inventory_path = self._prepare_inventory(inventory)\n    runner_fn = self._runner_fn or self._import_runner()\n\n    # Ensure playbook path is absolute so runner can find it\n    # regardless of private_data_dir location\n    abs_playbook_path = playbook_path.resolve()\n\n    label = abs_playbook_path.name\n    logger.info(\n        \"Running playbook %s against %d host(s)\", label, len(inventory.hosts)\n    )\n    self._active_label = label\n\n    merged_extravars = extravars.copy() if extravars else {}\n    merged_extravars.setdefault(\"_lb_inventory_path\", str(inventory_path))\n\n    repo_roles = (ANSIBLE_ROOT / \"roles\").resolve()\n    runner_roles = (self.private_data_dir / \"roles\").resolve()\n    callback_dir = (ANSIBLE_ROOT / \"callback_plugins\").resolve()\n    repo_collections = (ANSIBLE_ROOT / \"collections\").resolve()\n    runner_collections = (self.private_data_dir / \"collections\").resolve()\n    if repo_collections.exists():\n        shutil.copytree(\n            repo_collections,\n            runner_collections,\n            dirs_exist_ok=True,\n        )\n    envvars = {\n        \"ANSIBLE_ROLES_PATH\": f\"{runner_roles}:{repo_roles}\",\n        \"ANSIBLE_COLLECTIONS_PATHS\": f\"{runner_collections}:{repo_collections}\",\n        \"ANSIBLE_LOCAL_TEMP\": str(self.local_tmp),\n        \"ANSIBLE_REMOTE_TMP\": \"/tmp/.ansible\",\n        \"ANSIBLE_CONFIG\": str((ANSIBLE_ROOT / \"ansible.cfg\").resolve()),\n        # Use default callback; debug tasks echo LB_EVENT markers.\n        \"ANSIBLE_STDOUT_CALLBACK\": \"default\",\n        \"ANSIBLE_CALLBACK_PLUGINS\": str(callback_dir),\n        \"ANSIBLE_CALLBACKS_ENABLED\": \"lb_events\",\n        \"LB_EVENT_LOG_PATH\": str(self.event_log_path),\n    }\n\n    try:\n        if self._runner_fn:\n            result = runner_fn(\n                private_data_dir=str(self.private_data_dir),\n                playbook=str(abs_playbook_path),\n                inventory=str(inventory_path.resolve()),\n                extravars=merged_extravars,\n                tags=\",\".join(tags) if tags else None,\n                envvars=envvars,\n                limit=\",\".join(limit_hosts) if limit_hosts else None,\n            )\n        else:\n            result = self._run_subprocess_playbook(\n                abs_playbook_path=abs_playbook_path,\n                inventory_path=inventory_path,\n                extravars=merged_extravars,\n                tags=tags,\n                envvars=envvars,\n                limit_hosts=limit_hosts,\n                cancellable=cancellable,\n            )\n    finally:\n        self._active_label = None\n\n    rc = getattr(result, \"rc\", 1)\n    status = getattr(result, \"status\", \"failed\")\n    stats = getattr(result, \"stats\", {}) or {}\n    logger.info(\n        \"Playbook %s finished with rc=%s status=%s\",\n        playbook_path,\n        rc,\n        status,\n    )\n    return ExecutionResult(rc=rc, status=status, stats=stats)\n</code></pre>"},{"location":"reference/controller/#config-and-registry-services","title":"Config and registry services","text":""},{"location":"reference/controller/#lb_controller.services.ConfigService","title":"ConfigService","text":"<pre><code>ConfigService(config_home=None)\n</code></pre> <p>Resolve, load, and mutate BenchmarkConfig files.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def __init__(self, config_home: Optional[Path] = None) -&gt; None:\n    xdg = os.environ.get(\"XDG_CONFIG_HOME\")\n    base = Path(xdg) if xdg else Path.home() / \".config\"\n    self.config_home = (config_home or base) / \"lb\"\n    self.default_target = self.config_home / DEFAULT_CONFIG_NAME\n    self.pointer = self.config_home / DEFAULT_CONFIG_POINTER\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.services.ConfigService.config_home","title":"config_home  <code>instance-attribute</code>","text":"<pre><code>config_home = (config_home or base) / 'lb'\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.default_target","title":"default_target  <code>instance-attribute</code>","text":"<pre><code>default_target = config_home / DEFAULT_CONFIG_NAME\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.pointer","title":"pointer  <code>instance-attribute</code>","text":"<pre><code>pointer = config_home / DEFAULT_CONFIG_POINTER\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.services.ConfigService.add_remote_host","title":"add_remote_host","text":"<pre><code>add_remote_host(\n    host, config, enable_remote=True, set_default=False\n)\n</code></pre> <p>Add or replace a remote host definition and persist the config.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def add_remote_host(\n    self,\n    host: RemoteHostConfig,\n    config: Optional[Path],\n    enable_remote: bool = True,\n    set_default: bool = False,\n) -&gt; Tuple[BenchmarkConfig, Path, Optional[Path]]:\n    \"\"\"Add or replace a remote host definition and persist the config.\"\"\"\n    cfg, target, stale, _ = self.load_for_write(config, allow_create=True)\n    cfg.remote_hosts = [existing for existing in cfg.remote_hosts if existing.name != host.name]\n    cfg.remote_hosts.append(host)\n    cfg.remote_execution.enabled = enable_remote\n    cfg.save(target)\n    if set_default:\n        self.write_saved_config_path(target)\n    return cfg, target, stale\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.clear_saved_config_path","title":"clear_saved_config_path","text":"<pre><code>clear_saved_config_path()\n</code></pre> <p>Remove the stored config pointer.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def clear_saved_config_path(self) -&gt; None:\n    \"\"\"Remove the stored config pointer.\"\"\"\n    if self.pointer.exists():\n        self.pointer.unlink()\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.create_default_config","title":"create_default_config","text":"<pre><code>create_default_config()\n</code></pre> <p>Create a fresh BenchmarkConfig populated with all installed plugins.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def create_default_config(self) -&gt; BenchmarkConfig:\n    \"\"\"Create a fresh BenchmarkConfig populated with all installed plugins.\"\"\"\n    from .plugin_service import create_registry\n    from lb_runner.plugin_system.settings import (\n        ensure_workloads_from_plugin_settings,\n        populate_default_plugin_settings,\n    )\n\n    registry = create_registry()\n\n    cfg = BenchmarkConfig()\n    # Clear any legacy hardcoded defaults if BenchmarkConfig still has them (redundant safety)\n    cfg.workloads = {} \n    cfg.plugin_settings = {}\n\n    available = registry.available(load_entrypoints=True)\n    populate_default_plugin_settings(\n        cfg,\n        registry=registry,\n        load_entrypoints=True,\n        allow_dataclasses=True,\n    )\n    ensure_workloads_from_plugin_settings(\n        cfg, dump_mode=\"json\", convert_dataclasses=True\n    )\n\n    for name, plugin in available.items():\n        if name not in cfg.workloads:\n            cfg.workloads[name] = WorkloadConfig(plugin=name, enabled=False)\n\n    return cfg\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.ensure_home","title":"ensure_home","text":"<pre><code>ensure_home()\n</code></pre> <p>Create the config home directory.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def ensure_home(self) -&gt; None:\n    \"\"\"Create the config home directory.\"\"\"\n    self.config_home.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.load_for_read","title":"load_for_read","text":"<pre><code>load_for_read(config_path)\n</code></pre> <p>Load a config for read-only scenarios.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def load_for_read(self, config_path: Optional[Path]) -&gt; Tuple[BenchmarkConfig, Optional[Path], Optional[Path]]:\n    \"\"\"Load a config for read-only scenarios.\"\"\"\n    resolved, stale = self.resolve_config_path(config_path)\n    if resolved is None:\n        # Fallback to creating a default one in memory if none exists on disk?\n        # Or return empty? Current behavior was \"using built-in defaults\".\n        # Let's use our dynamic defaults.\n        return self.create_default_config(), None, stale\n\n    cfg = BenchmarkConfig.load(resolved)\n    self._hydrate_config(cfg)\n    return cfg, resolved, stale\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.load_for_write","title":"load_for_write","text":"<pre><code>load_for_write(config_path, allow_create=True)\n</code></pre> <p>Load a config for mutation and return (config, target_path, stale_pointer, created_new).</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def load_for_write(\n    self,\n    config_path: Optional[Path],\n    allow_create: bool = True,\n) -&gt; Tuple[BenchmarkConfig, Path, Optional[Path], bool]:\n    \"\"\"\n    Load a config for mutation and return (config, target_path, stale_pointer, created_new).\n    \"\"\"\n    resolved, stale = self.resolve_config_path(config_path)\n    target = resolved or self.default_target\n    created = False\n\n    if target.exists():\n        cfg = BenchmarkConfig.load(target)\n        self._hydrate_config(cfg)\n    else:\n        if not allow_create:\n            raise FileNotFoundError(f\"Config file not found: {target}\")\n        target.parent.mkdir(parents=True, exist_ok=True)\n        cfg = self.create_default_config()\n        created = True\n\n    return cfg, target, stale, created\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.open_editor","title":"open_editor","text":"<pre><code>open_editor(config_path)\n</code></pre> <p>Open the resolved config file in the system editor.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def open_editor(self, config_path: Optional[Path]) -&gt; Path:\n    \"\"\"\n    Open the resolved config file in the system editor.\n    \"\"\"\n    resolved, stale = self.resolve_config_path(config_path)\n    if resolved is None:\n        raise FileNotFoundError(\"No config file found to edit. Run `lb config init` first.\")\n\n    editor = os.environ.get(\"EDITOR\")\n    if not editor:\n        raise EnvironmentError(f\"Set $EDITOR or open the file manually: {resolved}\")\n\n    try:\n        subprocess.run([editor, str(resolved)], check=False)\n    except Exception as exc:\n        raise RuntimeError(f\"Failed to launch editor: {exc}\") from exc\n\n    return resolved\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.read_saved_config_path","title":"read_saved_config_path","text":"<pre><code>read_saved_config_path()\n</code></pre> <p>Public wrapper returning (valid_path, stale_path).</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def read_saved_config_path(self) -&gt; Tuple[Optional[Path], Optional[Path]]:\n    \"\"\"Public wrapper returning (valid_path, stale_path).\"\"\"\n    return self._read_saved_config_path()\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.remove_plugin","title":"remove_plugin","text":"<pre><code>remove_plugin(name, config)\n</code></pre> <p>Remove a plugin's workload and settings from a config file.</p> <p>Returns (config, target_path, stale_pointer, removed_flag).</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def remove_plugin(\n    self,\n    name: str,\n    config: Optional[Path],\n) -&gt; Tuple[BenchmarkConfig, Path, Optional[Path], bool]:\n    \"\"\"\n    Remove a plugin's workload and settings from a config file.\n\n    Returns (config, target_path, stale_pointer, removed_flag).\n    \"\"\"\n    cfg, target, stale, _ = self.load_for_write(config, allow_create=False)\n    removed = False\n    if name in cfg.workloads:\n        cfg.workloads.pop(name, None)\n        removed = True\n    if name in cfg.plugin_settings:\n        cfg.plugin_settings.pop(name, None)\n        removed = True\n    cfg.save(target)\n    return cfg, target, stale, removed\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.resolve_config_path","title":"resolve_config_path","text":"<pre><code>resolve_config_path(config_path)\n</code></pre> <p>Return (resolved_config, stale_pointer_target). Respects explicit path, environment variable LB_CONFIG_PATH, stored pointer, or local benchmark_config.json.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def resolve_config_path(self, config_path: Optional[Path]) -&gt; Tuple[Optional[Path], Optional[Path]]:\n    \"\"\"\n    Return (resolved_config, stale_pointer_target).\n    Respects explicit path, environment variable LB_CONFIG_PATH, stored pointer, or local benchmark_config.json.\n    \"\"\"\n    if config_path is not None:\n        return Path(config_path).expanduser(), None\n\n    env_path = os.environ.get(\"LB_CONFIG_PATH\")\n    if env_path:\n        return Path(env_path), None\n\n    saved, stale = self._read_saved_config_path()\n    if saved:\n        return saved, None\n    if stale:\n        return None, stale\n\n    local = Path(\"benchmark_config.json\")\n    if local.exists():\n        return local, None\n    if self.default_target.exists():\n        return self.default_target, None\n    return None, None\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.update_workload_enabled","title":"update_workload_enabled","text":"<pre><code>update_workload_enabled(name, enabled, config, set_default)\n</code></pre> <p>Enable/disable workload and persist the config.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def update_workload_enabled(\n    self,\n    name: str,\n    enabled: bool,\n    config: Optional[Path],\n    set_default: bool,\n) -&gt; Tuple[BenchmarkConfig, Path, Optional[Path]]:\n    \"\"\"Enable/disable workload and persist the config.\"\"\"\n    cfg, target, stale, _ = self.load_for_write(config, allow_create=True)\n\n    # Enforce that the plugin exists if we are enabling it\n    if enabled:\n        from .plugin_service import create_registry\n\n        registry = create_registry()\n        if name not in registry.available():\n            raise ValueError(f\"Plugin '{name}' is not installed. Use `lb plugin list` to see available plugins.\")\n\n        # Initialize default config if missing\n        if name not in cfg.plugin_settings:\n            plugin = registry.get(name)\n            if hasattr(plugin, 'config_cls'):\n                cfg.plugin_settings[name] = plugin.config_cls()\n\n    workload = cfg.workloads.get(name) or WorkloadConfig(plugin=name, options={})\n    workload.enabled = enabled\n    cfg.workloads[name] = workload\n\n    # Save will serialize the config objects back to dicts/json automatically\n    cfg.save(target)\n\n    if set_default:\n        self.write_saved_config_path(target)\n    return cfg, target, stale\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.ConfigService.write_saved_config_path","title":"write_saved_config_path","text":"<pre><code>write_saved_config_path(path)\n</code></pre> <p>Persist a pointer to the preferred config path.</p> Source code in <code>lb_controller/services/config_service.py</code> <pre><code>def write_saved_config_path(self, path: Path) -&gt; None:\n    \"\"\"Persist a pointer to the preferred config path.\"\"\"\n    self.ensure_home()\n    self.pointer.write_text(str(path.expanduser()))\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.create_registry","title":"create_registry","text":"<pre><code>create_registry(refresh=False)\n</code></pre> <p>Build a plugin registry with built-ins, entry points, and user plugins.</p> Source code in <code>lb_controller/services/plugin_service.py</code> <pre><code>def create_registry(refresh: bool = False) -&gt; PluginRegistry:\n    \"\"\"\n    Build a plugin registry with built-ins, entry points, and user plugins.\n    \"\"\"\n    global _REGISTRY_CACHE\n    if not refresh and _REGISTRY_CACHE is not None:\n        return _REGISTRY_CACHE\n    _REGISTRY_CACHE = PluginRegistry(builtin_plugins())\n    return _REGISTRY_CACHE\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.RunCatalogService","title":"RunCatalogService","text":"<pre><code>RunCatalogService(\n    output_dir, report_dir=None, data_export_dir=None\n)\n</code></pre> <p>Discover run directories and their basic metadata.</p> Source code in <code>lb_controller/services/run_catalog_service.py</code> <pre><code>def __init__(\n    self,\n    output_dir: Path,\n    report_dir: Optional[Path] = None,\n    data_export_dir: Optional[Path] = None,\n) -&gt; None:\n    self.output_dir = output_dir.resolve()\n    self.report_dir = report_dir.resolve() if report_dir else None\n    self.data_export_dir = data_export_dir.resolve() if data_export_dir else None\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.RunCatalogService-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.services.RunCatalogService.data_export_dir","title":"data_export_dir  <code>instance-attribute</code>","text":"<pre><code>data_export_dir = resolve() if data_export_dir else None\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.RunCatalogService.output_dir","title":"output_dir  <code>instance-attribute</code>","text":"<pre><code>output_dir = resolve()\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.RunCatalogService.report_dir","title":"report_dir  <code>instance-attribute</code>","text":"<pre><code>report_dir = resolve() if report_dir else None\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.RunCatalogService-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.services.RunCatalogService.get_run","title":"get_run","text":"<pre><code>get_run(run_id)\n</code></pre> <p>Return RunInfo for the given run_id if present.</p> Source code in <code>lb_controller/services/run_catalog_service.py</code> <pre><code>def get_run(self, run_id: str) -&gt; Optional[RunInfo]:\n    \"\"\"Return RunInfo for the given run_id if present.\"\"\"\n    output_root = self._resolve_output_root(run_id)\n    if output_root is None:\n        return None\n\n    report_root = self._resolve_optional_root(self.report_dir, run_id)\n    export_root = self._resolve_optional_root(self.data_export_dir, run_id)\n\n    journal_path = output_root / \"run_journal.json\"\n    journal_data = self._load_journal(journal_path)\n    created_at = self._extract_created_at(journal_data)\n    hosts, workloads = self._extract_hosts_workloads(journal_data)\n\n    if not hosts:\n        hosts = self._fallback_hosts(output_root)\n    if not workloads and hosts:\n        workloads = self._fallback_workloads(output_root, hosts)\n\n    return RunInfo(\n        run_id=run_id,\n        output_root=output_root,\n        report_root=self._existing_or_none(report_root),\n        data_export_root=self._existing_or_none(export_root),\n        hosts=sorted(hosts),\n        workloads=sorted(workloads),\n        created_at=created_at,\n        journal_path=journal_path if journal_path.exists() else None,\n    )\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.RunCatalogService.list_runs","title":"list_runs","text":"<pre><code>list_runs()\n</code></pre> <p>Return all runs found under output_dir, newest first when possible.</p> Source code in <code>lb_controller/services/run_catalog_service.py</code> <pre><code>def list_runs(self) -&gt; List[RunInfo]:\n    \"\"\"Return all runs found under output_dir, newest first when possible.\"\"\"\n    if not self.output_dir.exists():\n        return []\n\n    runs: List[RunInfo] = []\n    for item in self.output_dir.iterdir():\n        if not item.is_dir():\n            continue\n        run_id = item.name\n        if not run_id.startswith(\"run-\"):\n            continue\n        info = self.get_run(run_id)\n        if info:\n            runs.append(info)\n\n    runs.sort(\n        key=lambda r: r.created_at.timestamp() if r.created_at else 0.0,\n        reverse=True,\n    )\n    return runs\n</code></pre>"},{"location":"reference/controller/#journals-and-execution-types","title":"Journals and execution types","text":""},{"location":"reference/controller/#lb_controller.services.journal.RunJournal","title":"RunJournal  <code>dataclass</code>","text":"<pre><code>RunJournal(run_id, tasks=dict(), metadata=dict())\n</code></pre> <p>Contains the entire execution plan and state.</p>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata = field(default_factory=dict)\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.run_id","title":"run_id  <code>instance-attribute</code>","text":"<pre><code>run_id\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.tasks","title":"tasks  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>tasks = field(default_factory=dict)\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal-functions","title":"Functions","text":""},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.add_task","title":"add_task","text":"<pre><code>add_task(task)\n</code></pre> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def add_task(self, task: TaskState) -&gt; None:\n    self.tasks[task.key] = task\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.get_task","title":"get_task","text":"<pre><code>get_task(host, workload, rep)\n</code></pre> <p>Return a specific task or None when absent.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def get_task(self, host: str, workload: str, rep: int) -&gt; Optional[TaskState]:\n    \"\"\"Return a specific task or None when absent.\"\"\"\n    key = f\"{host}::{workload}::{rep}\"\n    return self.tasks.get(key)\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.get_tasks_by_host","title":"get_tasks_by_host","text":"<pre><code>get_tasks_by_host(host)\n</code></pre> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def get_tasks_by_host(self, host: str) -&gt; List[TaskState]:\n    return sorted(\n        [t for t in self.tasks.values() if t.host == host],\n        key=lambda x: x.repetition,\n    )\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.initialize","title":"initialize  <code>classmethod</code>","text":"<pre><code>initialize(run_id, config, test_types)\n</code></pre> <p>Factory to create a new journal based on configuration.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>@classmethod\ndef initialize(\n    cls, run_id: str, config: Any, test_types: List[str]\n) -&gt; \"RunJournal\":\n    \"\"\"Factory to create a new journal based on configuration.\"\"\"\n    journal = cls(run_id=run_id)\n    cfg_dump = _config_dump(config)\n    journal.metadata = {\n        \"created_at\": datetime.now().isoformat(),\n        \"config_summary\": str(config),  # Simple representation\n        \"repetitions\": getattr(config, \"repetitions\", None),\n        \"system_info\": {},  # host -&gt; summary string/path mapping\n        \"config_dump\": cfg_dump,\n        \"config_hash\": _config_hash(cfg_dump),\n    }\n\n    # Pre-populate tasks based on config\n    # We iterate test_types order to keep logical sequence\n    hosts = (\n        config.remote_hosts\n        if getattr(config, \"remote_hosts\", None)\n        else [SimpleNamespace(name=\"localhost\")]\n    )\n    for test_name in test_types:\n        if test_name not in config.workloads:\n            continue\n\n        for host in hosts:\n            for rep in range(1, config.repetitions + 1):\n                task = TaskState(\n                    host=host.name,\n                    workload=test_name,\n                    repetition=rep,\n                    status=RunStatus.PENDING,\n                )\n                journal.add_task(task)\n    return journal\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(path, config=None)\n</code></pre> <p>Load journal from disk, optionally validating against a config.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>@classmethod\ndef load(cls, path: Path, config: Any | None = None) -&gt; \"RunJournal\":\n    \"\"\"Load journal from disk, optionally validating against a config.\"\"\"\n    with open(path, \"r\") as f:\n        data = json.load(f)\n\n    metadata = data.get(\"metadata\", {}) or {}\n    cfg_dump = metadata.get(\"config_dump\")\n    cfg_hash = metadata.get(\"config_hash\")\n\n    if config is not None:\n        expected_reps = metadata.get(\"repetitions\")\n        if expected_reps and getattr(config, \"repetitions\", None) != expected_reps:\n            raise ValueError(\n                \"Config does not match journal repetitions; aborting resume.\"\n            )\n        if cfg_hash and cfg_dump:\n            current_dump = _config_dump(config)\n            current_hash = _config_hash(current_dump)\n            if current_hash != cfg_hash:\n                raise ValueError(\n                    \"Config hash mismatch for resume; supply matching config or rely on journal config_dump.\"\n                )\n    tasks_data = data.pop(\"tasks\", [])\n    journal = cls(**data)\n    journal.tasks = {}\n    for t in tasks_data:\n        task = TaskState(**t)\n        journal.tasks[task.key] = task\n    if not getattr(journal, \"metadata\", None):\n        journal.metadata = metadata\n    return journal\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.rehydrate_config","title":"rehydrate_config","text":"<pre><code>rehydrate_config()\n</code></pre> <p>Return a BenchmarkConfig reconstructed from the stored config_dump.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def rehydrate_config(self) -&gt; BenchmarkConfig | None:\n    \"\"\"\n    Return a BenchmarkConfig reconstructed from the stored config_dump.\n    \"\"\"\n    cfg_dump = (self.metadata or {}).get(\"config_dump\")\n    if not cfg_dump:\n        return None\n    try:\n        return BenchmarkConfig.model_validate(cfg_dump)\n    except Exception:\n        return None\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.save","title":"save","text":"<pre><code>save(path)\n</code></pre> <p>Persist journal to disk.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def save(self, path: Path) -&gt; None:\n    \"\"\"Persist journal to disk.\"\"\"\n    data = asdict(self)\n    # Ensure path exists\n    if isinstance(path, str):\n        path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    serialized = data.copy()\n    serialized[\"tasks\"] = [asdict(task) for task in self.tasks.values()]\n\n    with open(path, \"w\") as f:\n        json.dump(serialized, f, indent=2, default=str)\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.should_run","title":"should_run","text":"<pre><code>should_run(host, workload, rep)\n</code></pre> <p>Determines if a task should be executed. Returns True if task is PENDING or FAILED (and we want to retry). For now, we skip COMPLETED tasks.</p> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def should_run(self, host: str, workload: str, rep: int) -&gt; bool:\n    \"\"\"\n    Determines if a task should be executed.\n    Returns True if task is PENDING or FAILED (and we want to retry).\n    For now, we skip COMPLETED tasks.\n    \"\"\"\n    task = self.get_task(host, workload, rep)\n    if task:\n        return task.status not in (RunStatus.COMPLETED, RunStatus.SKIPPED)\n    # If task not found, it's technically new, so run it (though this shouldn't happen if initialized correctly)\n    return True\n</code></pre>"},{"location":"reference/controller/#lb_controller.services.journal.RunJournal.update_task","title":"update_task","text":"<pre><code>update_task(\n    host, workload, rep, status, action=\"\", error=None\n)\n</code></pre> Source code in <code>lb_controller/services/journal.py</code> <pre><code>def update_task(\n    self,\n    host: str,\n    workload: str,\n    rep: int,\n    status: str,\n    action: str = \"\",\n    error: Optional[str] = None,\n) -&gt; None:\n    task = self.get_task(host, workload, rep)\n    if not task:\n        return\n    now_ts = datetime.now().timestamp()\n    self._update_task_timings(task, status, now_ts)\n    task.status = status\n    task.timestamp = now_ts\n    if action:\n        task.current_action = action\n    if error:\n        task.error = error\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary","title":"RunExecutionSummary  <code>dataclass</code>","text":"<pre><code>RunExecutionSummary(\n    run_id,\n    per_host_output,\n    phases,\n    success,\n    output_root,\n    report_root,\n    data_export_root,\n    controller_state=None,\n    cleanup_allowed=False,\n)\n</code></pre> <p>Summary of a complete controller run.</p>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary-attributes","title":"Attributes","text":""},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.cleanup_allowed","title":"cleanup_allowed  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cleanup_allowed = False\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.controller_state","title":"controller_state  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>controller_state = None\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.data_export_root","title":"data_export_root  <code>instance-attribute</code>","text":"<pre><code>data_export_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.output_root","title":"output_root  <code>instance-attribute</code>","text":"<pre><code>output_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.per_host_output","title":"per_host_output  <code>instance-attribute</code>","text":"<pre><code>per_host_output\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.phases","title":"phases  <code>instance-attribute</code>","text":"<pre><code>phases\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.report_root","title":"report_root  <code>instance-attribute</code>","text":"<pre><code>report_root\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.run_id","title":"run_id  <code>instance-attribute</code>","text":"<pre><code>run_id\n</code></pre>"},{"location":"reference/controller/#lb_controller.models.types.RunExecutionSummary.success","title":"success  <code>instance-attribute</code>","text":"<pre><code>success\n</code></pre>"},{"location":"reference/provisioner/","title":"Provisioning helpers","text":"<p>Utilities that bridge provisioning results with the controller.</p>"},{"location":"reference/provisioner/#lb_provisioner.services.utils.cleanup_provisioned_nodes","title":"cleanup_provisioned_nodes","text":"<pre><code>cleanup_provisioned_nodes(\n    provisioning_result, result, presenter\n)\n</code></pre> <p>Apply cleanup policy using controller authorization.</p> <p>Expects <code>result.summary.cleanup_allowed</code> to indicate permission to teardown.</p> Source code in <code>lb_provisioner/services/utils.py</code> <pre><code>def cleanup_provisioned_nodes(provisioning_result: ProvisioningResult, result, presenter) -&gt; None:\n    \"\"\"\n    Apply cleanup policy using controller authorization.\n\n    Expects `result.summary.cleanup_allowed` to indicate permission to teardown.\n    \"\"\"\n    if not provisioning_result:\n        return\n    allow_cleanup = bool(result and getattr(result, \"summary\", None) and getattr(result.summary, \"cleanup_allowed\", False))\n    if result and getattr(result, \"summary\", None) and not getattr(result.summary, \"success\", True):\n        presenter.warning(\"Run failed; preserving provisioned nodes for inspection.\")\n        provisioning_result.keep_nodes = True\n    if not allow_cleanup:\n        presenter.warning(\"Controller did not authorize cleanup; provisioned nodes preserved.\")\n        provisioning_result.keep_nodes = True\n    provisioning_result.destroy_all()\n</code></pre>"},{"location":"reference/provisioner/#lb_provisioner.models.types.ProvisioningResult","title":"ProvisioningResult  <code>dataclass</code>","text":"<pre><code>ProvisioningResult(nodes, keep_nodes=False)\n</code></pre> <p>Aggregate provisioning outcome.</p>"},{"location":"reference/provisioner/#lb_provisioner.models.types.ProvisioningResult-attributes","title":"Attributes","text":""},{"location":"reference/provisioner/#lb_provisioner.models.types.ProvisioningResult.keep_nodes","title":"keep_nodes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>keep_nodes = False\n</code></pre>"},{"location":"reference/provisioner/#lb_provisioner.models.types.ProvisioningResult.nodes","title":"nodes  <code>instance-attribute</code>","text":"<pre><code>nodes\n</code></pre>"},{"location":"reference/provisioner/#lb_provisioner.models.types.ProvisioningResult-functions","title":"Functions","text":""},{"location":"reference/provisioner/#lb_provisioner.models.types.ProvisioningResult.destroy_all","title":"destroy_all","text":"<pre><code>destroy_all()\n</code></pre> <p>Destroy all provisioned nodes in best-effort fashion.</p> Source code in <code>lb_provisioner/models/types.py</code> <pre><code>def destroy_all(self) -&gt; None:\n    \"\"\"Destroy all provisioned nodes in best-effort fashion.\"\"\"\n    if self.keep_nodes:\n        return\n    for node in self.nodes:\n        node.teardown()\n</code></pre>"},{"location":"reference/runner/","title":"Runner API","text":"<p>Entry points for running workloads locally and working with the plugin system.</p>"},{"location":"reference/runner/#public-surface","title":"Public surface","text":""},{"location":"reference/runner/#lb_runner.api","title":"api","text":"<p>Stable runner API surface.</p>"},{"location":"reference/runner/#lb_runner.api-classes","title":"Classes","text":""},{"location":"reference/runner/#lb_runner.api.BaseGenerator","title":"BaseGenerator","text":"<pre><code>BaseGenerator(name)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for all workload generators.</p> <p>Initialize the base generator.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the generator</p> required Source code in <code>lb_runner/plugin_system/base_generator.py</code> <pre><code>def __init__(self, name: str):\n    \"\"\"\n    Initialize the base generator.\n\n    Args:\n        name: Name of the generator\n    \"\"\"\n    self.name = name\n    self._is_running = False\n    self._thread: Optional[threading.Thread] = None\n    self._result: Optional[Any] = None\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BaseGenerator-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.api.BaseGenerator.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name = name\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BaseGenerator-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.api.BaseGenerator.check_prerequisites","title":"check_prerequisites","text":"<pre><code>check_prerequisites()\n</code></pre> <p>Check if the generator's prerequisites are met.</p> <p>Delegates to the protected _validate_environment method.</p> Source code in <code>lb_runner/plugin_system/base_generator.py</code> <pre><code>def check_prerequisites(self) -&gt; bool:\n    \"\"\"\n    Check if the generator's prerequisites are met.\n\n    Delegates to the protected _validate_environment method.\n    \"\"\"\n    return self._validate_environment()\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BaseGenerator.cleanup","title":"cleanup","text":"<pre><code>cleanup()\n</code></pre> <p>Optional post-run hook executed after collectors stop and results are persisted.</p> <p>Generators can override to remove temporary artifacts created during a single repetition without affecting shared setup/provisioning.</p> Source code in <code>lb_runner/plugin_system/base_generator.py</code> <pre><code>def cleanup(self) -&gt; None:\n    \"\"\"\n    Optional post-run hook executed after collectors stop and results are persisted.\n\n    Generators can override to remove temporary artifacts created during a single\n    repetition without affecting shared setup/provisioning.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BaseGenerator.get_result","title":"get_result","text":"<pre><code>get_result()\n</code></pre> <p>Get the result of the workload generation.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The result obtained from the workload generation</p> Source code in <code>lb_runner/plugin_system/base_generator.py</code> <pre><code>def get_result(self) -&gt; Any:\n    \"\"\"\n    Get the result of the workload generation.\n\n    Returns:\n        The result obtained from the workload generation\n    \"\"\"\n    return self._result\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BaseGenerator.prepare","title":"prepare","text":"<pre><code>prepare()\n</code></pre> <p>Optional pre-run hook executed synchronously before collectors start.</p> <p>Generators can override to perform expensive setup (e.g., build binaries) so collectors do not capture that time. Default is a no-op.</p> Source code in <code>lb_runner/plugin_system/base_generator.py</code> <pre><code>def prepare(self) -&gt; None:\n    \"\"\"\n    Optional pre-run hook executed synchronously before collectors start.\n\n    Generators can override to perform expensive setup (e.g., build binaries)\n    so collectors do not capture that time. Default is a no-op.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BaseGenerator.start","title":"start","text":"<pre><code>start()\n</code></pre> <p>Start the workload generation in a background thread.</p> Source code in <code>lb_runner/plugin_system/base_generator.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start the workload generation in a background thread.\"\"\"\n    if self._is_running:\n        logger.warning(f\"{self.name} generator is already running\")\n        return\n\n    if not self._validate_environment():\n        raise RuntimeError(f\"{self.name} generator cannot run in this environment\")\n\n    self._is_running = True\n    def _wrapper() -&gt; None:\n        try:\n            self._run_command()\n        finally:\n            # Always clear running flag when the worker exits (success or failure)\n            self._is_running = False\n\n    self._thread = threading.Thread(target=_wrapper)\n    self._thread.start()\n\n    logger.info(f\"{self.name} generator started\")\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BaseGenerator.stop","title":"stop","text":"<pre><code>stop()\n</code></pre> <p>Stop the workload generation.</p> Source code in <code>lb_runner/plugin_system/base_generator.py</code> <pre><code>def stop(self) -&gt; None:\n    \"\"\"Stop the workload generation.\"\"\"\n    if self._is_running:\n        # Signal the workload to stop only if it thinks it's running\n        self._stop_workload()\n        self._is_running = False\n    else:\n        logger.debug(f\"{self.name} generator was already stopped or finished\")\n\n    # Always ensure the thread is joined to avoid zombies\n    if self._thread and self._thread.is_alive():\n        try:\n            self._thread.join(timeout=5.0)\n            if self._thread.is_alive():\n                logger.warning(f\"{self.name} thread did not terminate gracefully\")\n        except Exception as e:\n            logger.error(f\"Error joining thread for {self.name}: {e}\")\n\n    logger.info(f\"{self.name} generator stopped\")\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig","title":"BenchmarkConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Main configuration for benchmark tests.</p>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.collect_system_info","title":"collect_system_info  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>collect_system_info = Field(\n    default=True,\n    description=\"Collect system information before running benchmarks\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.collectors","title":"collectors  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>collectors = Field(\n    default_factory=MetricCollectorConfig,\n    description=\"Configuration for metric collectors\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.cooldown_seconds","title":"cooldown_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cooldown_seconds = Field(\n    default=5,\n    ge=0,\n    description=\"Cooldown period after test finishes\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.data_export_dir","title":"data_export_dir  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>data_export_dir = Field(\n    default=Path(\"./data_exports\"),\n    description=\"Directory for raw data exports\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.influxdb_bucket","title":"influxdb_bucket  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_bucket = Field(\n    default=\"performance\", description=\"InfluxDB Bucket\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.influxdb_enabled","title":"influxdb_enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_enabled = Field(\n    default=False, description=\"Enable InfluxDB integration\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.influxdb_org","title":"influxdb_org  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_org = Field(\n    default=\"benchmark\", description=\"InfluxDB Organization\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.influxdb_token","title":"influxdb_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_token = Field(\n    default=\"\", description=\"InfluxDB API Token\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.influxdb_url","title":"influxdb_url  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_url = Field(\n    default=\"http://localhost:8086\",\n    description=\"InfluxDB URL\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.metrics_interval_seconds","title":"metrics_interval_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metrics_interval_seconds = Field(\n    default=1.0,\n    gt=0,\n    description=\"Interval for metric collection in seconds\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.output_dir","title":"output_dir  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>output_dir = Field(\n    default=Path(\"./benchmark_results\"),\n    description=\"Root directory for all benchmark output\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.plugin_settings","title":"plugin_settings  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>plugin_settings = Field(\n    default_factory=dict,\n    description=\"Dictionary of plugin-specific Pydantic config models\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.remote_execution","title":"remote_execution  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>remote_execution = Field(\n    default_factory=RemoteExecutionConfig,\n    description=\"Configuration for remote execution\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.remote_hosts","title":"remote_hosts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>remote_hosts = Field(\n    default_factory=list,\n    description=\"List of remote hosts for benchmarking\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.repetitions","title":"repetitions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>repetitions = Field(\n    default=3,\n    gt=0,\n    description=\"Number of repetitions for each test\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.report_dir","title":"report_dir  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>report_dir = Field(\n    default=Path(\"./reports\"),\n    description=\"Directory for generated reports\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.test_duration_seconds","title":"test_duration_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>test_duration_seconds = Field(\n    default=3600,\n    gt=0,\n    description=\"Default duration for tests in seconds\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.warmup_seconds","title":"warmup_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>warmup_seconds = Field(\n    default=5,\n    ge=0,\n    description=\"Warmup period before metric collection starts\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.workloads","title":"workloads  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>workloads = Field(\n    default_factory=dict,\n    description=\"Dictionary of workload definitions\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.ensure_output_dirs","title":"ensure_output_dirs","text":"<pre><code>ensure_output_dirs()\n</code></pre> <p>Ensures all configured output directories exist.</p> Source code in <code>lb_runner/models/config.py</code> <pre><code>def ensure_output_dirs(self) -&gt; None:\n    \"\"\"Ensures all configured output directories exist.\"\"\"\n    for path in (self.output_dir, self.report_dir, self.data_export_dir):\n        path.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Dict[str, Any]) -&gt; \"BenchmarkConfig\":\n    # Use Pydantic's built-in dictionary parsing and validation\n    # Pydantic will handle nested models and Path conversions automatically\n    return cls.model_validate(data)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_str)\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; \"BenchmarkConfig\":\n    # Use Pydantic's built-in JSON parsing and validation\n    return cls.model_validate_json(json_str)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filepath)\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>@classmethod\ndef load(cls, filepath: Path) -&gt; \"BenchmarkConfig\":\n    return cls.model_validate_json(filepath.read_text())\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.BenchmarkConfig.save","title":"save","text":"<pre><code>save(filepath)\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>def save(self, filepath: Path) -&gt; None:\n    filepath.write_text(self.model_dump_json(indent=2))\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.PluginRegistry","title":"PluginRegistry","text":"<pre><code>PluginRegistry(plugins=None)\n</code></pre> <p>In-memory registry that supports built-in, entry-point, and user directory plugins.</p> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def __init__(self, plugins: Optional[Iterable[Any]] = None):\n    self._workloads: Dict[str, IWorkloadPlugin] = {}\n    self._collectors: Dict[str, CollectorPlugin] = {}\n    self._pending_entrypoints: Dict[str, importlib.metadata.EntryPoint] = {}\n    if plugins:\n        for plugin in plugins:\n            self.register(plugin)\n    self._discover_entrypoint_plugins()\n    self._load_user_plugins()\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.PluginRegistry-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.api.PluginRegistry.available","title":"available","text":"<pre><code>available(load_entrypoints=False)\n</code></pre> <p>Return available workload plugins.</p> <p>When load_entrypoints is True, pending entry-point plugins are resolved and registered; otherwise only already-registered plugins are returned.</p> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def available(self, load_entrypoints: bool = False) -&gt; Dict[str, Any]:\n    \"\"\"\n    Return available workload plugins.\n\n    When load_entrypoints is True, pending entry-point plugins are resolved and\n    registered; otherwise only already-registered plugins are returned.\n    \"\"\"\n    if load_entrypoints:\n        self._load_pending_entrypoints()\n    return dict(self._workloads)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.PluginRegistry.available_collectors","title":"available_collectors","text":"<pre><code>available_collectors()\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def available_collectors(self) -&gt; Dict[str, CollectorPlugin]:\n    return dict(self._collectors)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.PluginRegistry.create_collectors","title":"create_collectors","text":"<pre><code>create_collectors(config)\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def create_collectors(self, config: BenchmarkConfig) -&gt; list[BaseCollector]:\n    collectors = []\n    for plugin in self._collectors.values():\n        if plugin.should_run(config):\n            try:\n                collector = plugin.factory(config)\n                collectors.append(collector)\n            except Exception as e:\n                logger.error(f\"Failed to create collector {plugin.name}: {e}\")\n    return collectors\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.PluginRegistry.create_generator","title":"create_generator","text":"<pre><code>create_generator(plugin_name, options=None)\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def create_generator(\n    self, plugin_name: str, options: Optional[Dict[str, Any]] = None\n) -&gt; BaseGenerator:\n    plugin = self.get(plugin_name)\n\n    # New style: we need to handle config instantiation here or in the plugin\n    # The interface says `create_generator(config: Any)`.\n    # We need to convert dict -&gt; config_obj.\n\n    if options is None:\n        options = {}\n\n    # If options is already the config object, pass it\n    if isinstance(options, plugin.config_cls):\n        return plugin.create_generator(options)\n\n    # Otherwise instantiate from dict\n    config_obj = plugin.config_cls(**options)\n    return plugin.create_generator(config_obj)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.PluginRegistry.get","title":"get","text":"<pre><code>get(name)\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def get(self, name: str) -&gt; IWorkloadPlugin:\n    if name not in self._workloads and name in self._pending_entrypoints:\n        self._load_entrypoint(name)\n    if name not in self._workloads:\n        raise KeyError(f\"Workload Plugin '{name}' not found\")\n    return self._workloads[name]\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.PluginRegistry.get_collector","title":"get_collector","text":"<pre><code>get_collector(name)\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def get_collector(self, name: str) -&gt; CollectorPlugin:\n    if name not in self._collectors:\n        raise KeyError(f\"Collector Plugin '{name}' not found\")\n    return self._collectors[name]\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.PluginRegistry.register","title":"register","text":"<pre><code>register(plugin)\n</code></pre> <p>Register a new plugin.</p> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def register(self, plugin: Any) -&gt; None:\n    \"\"\"Register a new plugin.\"\"\"\n    if isinstance(plugin, IWorkloadPlugin):\n        self._workloads[plugin.name] = plugin\n    elif isinstance(plugin, CollectorPlugin):\n        self._collectors[plugin.name] = plugin\n    else:\n        # Try duck typing for IWorkloadPlugin if strict check fails (e.g. different import paths)\n        if hasattr(plugin, \"name\") and hasattr(plugin, \"create_generator\"):\n            self._workloads[plugin.name] = plugin\n        else:\n            raise TypeError(f\"Unknown plugin type: {type(plugin)}\")\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig","title":"RemoteExecutionConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for remote execution via Ansible.</p>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.collect_playbook","title":"collect_playbook  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>collect_playbook = Field(\n    default_factory=lambda: ANSIBLE_ROOT\n    / \"playbooks\"\n    / \"collect.yml\",\n    description=\"Path to the Ansible collect playbook\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled = Field(\n    default=False, description=\"Enable remote execution\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.inventory_path","title":"inventory_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>inventory_path = Field(\n    default=None,\n    description=\"Path to a custom Ansible inventory file\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.run_collect","title":"run_collect  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_collect = Field(\n    default=True,\n    description=\"Execute collection playbooks after tests\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.run_playbook","title":"run_playbook  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_playbook = Field(\n    default_factory=lambda: ANSIBLE_ROOT\n    / \"playbooks\"\n    / \"run_benchmark.yml\",\n    description=\"Path to the Ansible run playbook\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.run_setup","title":"run_setup  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_setup = Field(\n    default=True,\n    description=\"Execute setup playbooks before tests\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.run_teardown","title":"run_teardown  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_teardown = Field(\n    default=True,\n    description=\"Execute teardown playbooks after tests\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.setup_playbook","title":"setup_playbook  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>setup_playbook = Field(\n    default_factory=lambda: ANSIBLE_ROOT\n    / \"playbooks\"\n    / \"setup.yml\",\n    description=\"Path to the Ansible setup playbook\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.teardown_playbook","title":"teardown_playbook  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>teardown_playbook = Field(\n    default_factory=lambda: ANSIBLE_ROOT\n    / \"playbooks\"\n    / \"teardown.yml\",\n    description=\"Path to the Ansible teardown playbook\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.upgrade_pip","title":"upgrade_pip  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>upgrade_pip = Field(\n    default=False,\n    description=\"Upgrade pip inside the benchmark virtual environment during setup\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteExecutionConfig.use_container_fallback","title":"use_container_fallback  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>use_container_fallback = Field(\n    default=False,\n    description=\"Use container-based fallback for remote execution\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig","title":"RemoteHostConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a remote benchmark host.</p>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.address","title":"address  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>address = Field(\n    description=\"IP address or hostname of the remote host\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.become","title":"become  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>become = Field(\n    default=True,\n    description=\"Use Ansible become (sudo) for escalated privileges\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.become_method","title":"become_method  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>become_method = Field(\n    default=\"sudo\", description=\"Ansible become method\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name = Field(description='Unique name for the remote host')\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.port","title":"port  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>port = Field(\n    default=22, gt=0, description=\"SSH port for connection\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.user","title":"user  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>user = Field(\n    default=\"root\", description=\"SSH user for connection\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.vars","title":"vars  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>vars = Field(\n    default_factory=dict,\n    description=\"Additional Ansible variables for this host\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.ansible_host_line","title":"ansible_host_line","text":"<pre><code>ansible_host_line()\n</code></pre> <p>Render an INI-style inventory line for this host (compat helper).</p> Source code in <code>lb_runner/models/config.py</code> <pre><code>def ansible_host_line(self) -&gt; str:\n    \"\"\"Render an INI-style inventory line for this host (compat helper).\"\"\"\n    parts = [\n        self.name,\n        f\"ansible_host={self.address}\",\n        f\"ansible_port={self.port}\",\n        f\"ansible_user={self.user}\",\n    ]\n    if self.become:\n        parts.append(\"ansible_become=true\")\n    if self.become_method:\n        parts.append(f\"ansible_become_method={self.become_method}\")\n    for key, value in self.vars.items():\n        val = str(value)\n        if \" \" in val:\n            val = f'\"{val}\"'\n        parts.append(f\"{key}={val}\")\n    return \" \".join(parts)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RemoteHostConfig.validate_name_not_empty","title":"validate_name_not_empty","text":"<pre><code>validate_name_not_empty()\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_name_not_empty(self) -&gt; 'RemoteHostConfig':\n    if not self.name or not self.name.strip():\n        raise ValueError(\"RemoteHostConfig: 'name' must be non-empty\")\n    return self\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent","title":"RunEvent  <code>dataclass</code>","text":"<pre><code>RunEvent(\n    run_id,\n    host,\n    workload,\n    repetition,\n    total_repetitions,\n    status,\n    message=\"\",\n    timestamp=0.0,\n    type=\"status\",\n    level=\"INFO\",\n)\n</code></pre> <p>A structured event emitted during a run.</p>"},{"location":"reference/runner/#lb_runner.api.RunEvent-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.api.RunEvent.host","title":"host  <code>instance-attribute</code>","text":"<pre><code>host\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.level","title":"level  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>level = 'INFO'\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.message","title":"message  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>message = ''\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.repetition","title":"repetition  <code>instance-attribute</code>","text":"<pre><code>repetition\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.run_id","title":"run_id  <code>instance-attribute</code>","text":"<pre><code>run_id\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.status","title":"status  <code>instance-attribute</code>","text":"<pre><code>status\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.timestamp","title":"timestamp  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timestamp = 0.0\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.total_repetitions","title":"total_repetitions  <code>instance-attribute</code>","text":"<pre><code>total_repetitions\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.type","title":"type  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>type = 'status'\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.workload","title":"workload  <code>instance-attribute</code>","text":"<pre><code>workload\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.api.RunEvent.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> Source code in <code>lb_runner/models/events.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    return asdict(self)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.RunEvent.to_json","title":"to_json","text":"<pre><code>to_json()\n</code></pre> Source code in <code>lb_runner/models/events.py</code> <pre><code>def to_json(self) -&gt; str:\n    return json.dumps(self.to_dict())\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.StdoutEmitter","title":"StdoutEmitter","text":"<p>Emit progress markers to stdout for parsing in Ansible streams.</p>"},{"location":"reference/runner/#lb_runner.api.StdoutEmitter-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.api.StdoutEmitter.emit","title":"emit","text":"<pre><code>emit(event)\n</code></pre> Source code in <code>lb_runner/models/events.py</code> <pre><code>def emit(self, event: RunEvent) -&gt; None:\n    print(f\"LB_EVENT {event.to_json()}\", flush=True)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadConfig","title":"WorkloadConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration wrapper for workload plugins.</p>"},{"location":"reference/runner/#lb_runner.api.WorkloadConfig-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.api.WorkloadConfig.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled = Field(\n    default=True,\n    description=\"Enable or disable this workload\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadConfig.intensity","title":"intensity  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>intensity = Field(\n    default=\"user_defined\",\n    description=\"Pre-defined intensity level (low, medium, high, user_defined)\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadConfig.options","title":"options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options = Field(\n    default_factory=dict,\n    description=\"Plugin-specific options for the workload\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadConfig.plugin","title":"plugin  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>plugin = Field(description='Name of the plugin to use')\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadIntensity","title":"WorkloadIntensity","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"reference/runner/#lb_runner.api.WorkloadIntensity-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.api.WorkloadIntensity.HIGH","title":"HIGH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HIGH = 'high'\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadIntensity.LOW","title":"LOW  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LOW = 'low'\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadIntensity.MEDIUM","title":"MEDIUM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEDIUM = 'medium'\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadIntensity.USER_DEFINED","title":"USER_DEFINED  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>USER_DEFINED = 'user_defined'\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin","title":"WorkloadPlugin","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for all workload plugins.</p> <p>A plugin encapsulates the logic for: 1. Configuration (schema) 2. Execution (Generator creation) 3. Metadata (Name, description) 4. Assets (Ansible playbooks)</p>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.config_cls","title":"config_cls  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>config_cls\n</code></pre> <p>The Pydantic model used for configuration. The ConfigService will use this to deserialize raw JSON.</p>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.description","title":"description  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>description\n</code></pre> <p>Human-readable description.</p>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.name","title":"name  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>name\n</code></pre> <p>Unique identifier for the workload (e.g., 'stress_ng').</p>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.create_generator","title":"create_generator  <code>abstractmethod</code>","text":"<pre><code>create_generator(config)\n</code></pre> <p>Create a new instance of the workload generator.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>BasePluginConfig</code> <p>An instance of self.config_cls</p> required Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>@abstractmethod\ndef create_generator(self, config: BasePluginConfig) -&gt; Any: # Changed type hint\n    \"\"\"\n    Create a new instance of the workload generator.\n\n    Args:\n        config: An instance of self.config_cls\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.export_results_to_csv","title":"export_results_to_csv","text":"<pre><code>export_results_to_csv(\n    results, output_dir, run_id, test_name\n)\n</code></pre> <p>Normalize plugin-specific results into CSV files stored in output_dir.</p> <p>Default implementation flattens generator_result and metadata into a single CSV. Plugins with richer report formats can override to write multiple CSVs.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def export_results_to_csv(\n    self,\n    results: List[Dict[str, Any]],\n    output_dir: Path,\n    run_id: str,\n    test_name: str,\n) -&gt; List[Path]:\n    \"\"\"\n    Normalize plugin-specific results into CSV files stored in output_dir.\n\n    Default implementation flattens generator_result and metadata into a single CSV.\n    Plugins with richer report formats can override to write multiple CSVs.\n    \"\"\"\n    rows: list[dict[str, Any]] = []\n    for entry in results:\n        row = {\n            \"run_id\": run_id,\n            \"workload\": test_name,\n            \"repetition\": entry.get(\"repetition\"),\n            \"duration_seconds\": entry.get(\"duration_seconds\"),\n            \"success\": entry.get(\"success\"),\n        }\n        gen_result = entry.get(\"generator_result\") or {}\n        if isinstance(gen_result, dict):\n            for key, value in gen_result.items():\n                row[f\"generator_{key}\"] = value\n        rows.append(row)\n\n    if not rows:\n        return []\n\n    df = pd.DataFrame(rows)\n    output_dir.mkdir(parents=True, exist_ok=True)\n    csv_path = output_dir / f\"{test_name}_plugin.csv\"\n    df.to_csv(csv_path, index=False)\n    return [csv_path]\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.get_ansible_setup_extravars","title":"get_ansible_setup_extravars","text":"<pre><code>get_ansible_setup_extravars()\n</code></pre> <p>Return extra vars merged into the plugin setup playbook run.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def get_ansible_setup_extravars(self) -&gt; Dict[str, Any]:\n    \"\"\"Return extra vars merged into the plugin setup playbook run.\"\"\"\n    return {}\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.get_ansible_setup_path","title":"get_ansible_setup_path","text":"<pre><code>get_ansible_setup_path()\n</code></pre> <p>Return the path to the Ansible setup playbook. Executed before the workload runs on remote hosts.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def get_ansible_setup_path(self) -&gt; Optional[Path]:\n    \"\"\"\n    Return the path to the Ansible setup playbook.\n    Executed before the workload runs on remote hosts.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.get_ansible_teardown_extravars","title":"get_ansible_teardown_extravars","text":"<pre><code>get_ansible_teardown_extravars()\n</code></pre> <p>Return extra vars merged into the plugin teardown playbook run.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def get_ansible_teardown_extravars(self) -&gt; Dict[str, Any]:\n    \"\"\"Return extra vars merged into the plugin teardown playbook run.\"\"\"\n    return {}\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.get_ansible_teardown_path","title":"get_ansible_teardown_path","text":"<pre><code>get_ansible_teardown_path()\n</code></pre> <p>Return the path to the Ansible teardown playbook. Executed after the workload runs (even on failure) on remote hosts.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def get_ansible_teardown_path(self) -&gt; Optional[Path]:\n    \"\"\"\n    Return the path to the Ansible teardown playbook.\n    Executed after the workload runs (even on failure) on remote hosts.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.get_preset_config","title":"get_preset_config","text":"<pre><code>get_preset_config(level)\n</code></pre> <p>Return a configuration object for the specified intensity level. If USER_DEFINED or not implemented, return None.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def get_preset_config(self, level: WorkloadIntensity) -&gt; Optional[BasePluginConfig]: # Changed type hint\n    \"\"\"\n    Return a configuration object for the specified intensity level.\n    If USER_DEFINED or not implemented, return None.\n    \"\"\"\n    return None\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.get_required_apt_packages","title":"get_required_apt_packages","text":"<pre><code>get_required_apt_packages()\n</code></pre> <p>Return list of APT packages required by this plugin.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def get_required_apt_packages(self) -&gt; List[str]:\n    \"\"\"Return list of APT packages required by this plugin.\"\"\"\n    return []\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.get_required_local_tools","title":"get_required_local_tools","text":"<pre><code>get_required_local_tools()\n</code></pre> <p>Return list of command-line tools required by this plugin for local execution. Used by <code>lb doctor</code> to verify the local environment.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def get_required_local_tools(self) -&gt; List[str]:\n    \"\"\"\n    Return list of command-line tools required by this plugin for local execution.\n    Used by `lb doctor` to verify the local environment.\n    \"\"\"\n    return []\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.get_required_pip_packages","title":"get_required_pip_packages","text":"<pre><code>get_required_pip_packages()\n</code></pre> <p>Return list of Python packages required by this plugin.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def get_required_pip_packages(self) -&gt; List[str]:\n    \"\"\"Return list of Python packages required by this plugin.\"\"\"\n    return []\n</code></pre>"},{"location":"reference/runner/#lb_runner.api.WorkloadPlugin.load_config_from_file","title":"load_config_from_file","text":"<pre><code>load_config_from_file(config_file_path)\n</code></pre> <p>Loads and validates plugin configuration from a YAML file.</p> <p>The method merges common configuration (from the 'common' section) with plugin-specific configuration (from the 'plugins.' section). Plugin-specific settings override common settings. Finally, the merged configuration is validated against <code>self.config_cls</code>. <p>Parameters:</p> Name Type Description Default <code>config_file_path</code> <code>Path</code> <p>The path to the YAML configuration file.</p> required <p>Returns:</p> Type Description <code>BasePluginConfig</code> <p>An instance of <code>self.config_cls</code> with the loaded and validated configuration.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the config_file_path does not exist.</p> <code>YAMLError</code> <p>If the file content is not valid YAML.</p> <code>ValidationError</code> <p>If the merged configuration does not conform to <code>self.config_cls</code> schema.</p> Source code in <code>lb_runner/plugin_system/interface.py</code> <pre><code>def load_config_from_file(self, config_file_path: Path) -&gt; BasePluginConfig:\n    \"\"\"\n    Loads and validates plugin configuration from a YAML file.\n\n    The method merges common configuration (from the 'common' section)\n    with plugin-specific configuration (from the 'plugins.&lt;plugin_name&gt;' section).\n    Plugin-specific settings override common settings.\n    Finally, the merged configuration is validated against `self.config_cls`.\n\n    Args:\n        config_file_path: The path to the YAML configuration file.\n\n    Returns:\n        An instance of `self.config_cls` with the loaded and validated configuration.\n\n    Raises:\n        FileNotFoundError: If the config_file_path does not exist.\n        yaml.YAMLError: If the file content is not valid YAML.\n        ValidationError: If the merged configuration does not conform to `self.config_cls` schema.\n    \"\"\"\n    if not config_file_path.exists():\n        raise FileNotFoundError(f\"Configuration file not found: {config_file_path}\")\n\n    with open(config_file_path, 'r') as f:\n        full_data = yaml.safe_load(f) or {}\n\n    # Extract common and plugin-specific data\n    common_data = full_data.get(\"common\", {})\n    plugin_data = full_data.get(\"plugins\", {}).get(self.name, {})\n\n    # Merge data: plugin-specific overrides common\n    merged_data = {**common_data, **plugin_data}\n\n    # Validate and instantiate the config class using Pydantic\n    # Pydantic will handle default values for missing fields\n    return self.config_cls(**merged_data)\n</code></pre>"},{"location":"reference/runner/#local-runner","title":"Local runner","text":""},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner","title":"LocalRunner","text":"<pre><code>LocalRunner(\n    config,\n    registry,\n    progress_callback=None,\n    host_name=None,\n    stop_token=None,\n)\n</code></pre> <p>Local agent for executing benchmarks on a single node.</p> <p>Initialize the local runner.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>BenchmarkConfig</code> <p>Benchmark configuration</p> required Source code in <code>lb_runner/engine/runner.py</code> <pre><code>def __init__(\n    self,\n    config: BenchmarkConfig,\n    registry: PluginRegistry,\n    progress_callback: Optional[Callable[[RunEvent], None]] = None,\n    host_name: str | None = None,\n    stop_token: StopToken | None = None,\n):\n    \"\"\"\n    Initialize the local runner.\n\n    Args:\n        config: Benchmark configuration\n    \"\"\"\n    self.config = config\n    self.system_info: Optional[Dict[str, Any]] = None\n    self.test_results: List[Dict[str, Any]] = []\n    self.plugin_registry = registry\n    self._current_run_id: Optional[str] = None\n    self._output_root: Optional[Path] = None\n    self._data_export_root: Optional[Path] = None\n    self._log_file_handler_attached: bool = False\n    self._host_name = host_name or os.environ.get(\"LB_RUN_HOST\") or platform.node() or \"localhost\"\n    self._progress = RunProgressEmitter(host=self._host_name, callback=progress_callback)\n    self._stop_token = stop_token\n</code></pre>"},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner.config","title":"config  <code>instance-attribute</code>","text":"<pre><code>config = config\n</code></pre>"},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner.plugin_registry","title":"plugin_registry  <code>instance-attribute</code>","text":"<pre><code>plugin_registry = registry\n</code></pre>"},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner.system_info","title":"system_info  <code>instance-attribute</code>","text":"<pre><code>system_info = None\n</code></pre>"},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner.test_results","title":"test_results  <code>instance-attribute</code>","text":"<pre><code>test_results = []\n</code></pre>"},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner.collect_system_info","title":"collect_system_info","text":"<pre><code>collect_system_info()\n</code></pre> <p>Collect detailed information about the system.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary containing system information</p> Source code in <code>lb_runner/engine/runner.py</code> <pre><code>def collect_system_info(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Collect detailed information about the system.\n\n    Returns:\n        Dictionary containing system information\n    \"\"\"\n    logger.info(\"Collecting system information\")\n\n    collected = system_info.collect_system_info()\n    self.system_info = collected.to_dict()\n\n    # Persist JSON/CSV alongside run outputs when available\n    if self._output_root:\n        write_system_info_artifacts(collected, self._output_root, logger)\n\n    return self.system_info\n</code></pre>"},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner.run_all_benchmarks","title":"run_all_benchmarks","text":"<pre><code>run_all_benchmarks()\n</code></pre> <p>Run all configured benchmark tests.</p> Source code in <code>lb_runner/engine/runner.py</code> <pre><code>def run_all_benchmarks(self) -&gt; None:\n    \"\"\"Run all configured benchmark tests.\"\"\"\n    run_id = self._generate_run_id()\n    for test_name, workload in self.config.workloads.items():\n        if not workload.enabled:\n            logger.info(\"Skipping disabled workload '%s'\", test_name)\n            continue\n        try:\n            self.run_benchmark(test_name, run_id=run_id)\n        except Exception as e:\n            logger.error(f\"Failed to run {test_name} benchmark: {e}\", exc_info=True)\n</code></pre>"},{"location":"reference/runner/#lb_runner.engine.runner.LocalRunner.run_benchmark","title":"run_benchmark","text":"<pre><code>run_benchmark(\n    test_type,\n    repetition_override=None,\n    total_repetitions=None,\n    run_id=None,\n    pending_reps=None,\n)\n</code></pre> <p>Run a complete benchmark test.</p> <p>Parameters:</p> Name Type Description Default <code>test_type</code> <code>str</code> <p>Name of the workload to run (plugin id)</p> required <code>repetition_override</code> <code>int | None</code> <p>When set, run only this repetition index.</p> <code>None</code> <code>total_repetitions</code> <code>int | None</code> <p>Total repetitions planned (for display purposes).</p> <code>None</code> Source code in <code>lb_runner/engine/runner.py</code> <pre><code>def run_benchmark(\n    self,\n    test_type: str,\n    repetition_override: int | None = None,\n    total_repetitions: int | None = None,\n    run_id: str | None = None,\n    pending_reps: List[int] | None = None,\n) -&gt; bool:\n    \"\"\"\n    Run a complete benchmark test.\n\n    Args:\n        test_type: Name of the workload to run (plugin id)\n        repetition_override: When set, run only this repetition index.\n        total_repetitions: Total repetitions planned (for display purposes).\n    \"\"\"\n    logger.info(f\"Starting benchmark: {test_type}\")\n\n    self._prepare_run_scope(run_id)\n\n    if self.config.collect_system_info and not self.system_info:\n        self.collect_system_info()\n\n    workload_cfg = self._resolve_workload(test_type)\n    plugin: WorkloadPlugin = self.plugin_registry.get(workload_cfg.plugin)\n\n    total_reps = total_repetitions or self.config.repetitions\n    reps = self._select_repetitions(repetition_override, pending_reps)\n\n    success_overall = True\n    for idx, rep in enumerate(reps):\n        success = self._run_single_repetition(\n            test_type=test_type,\n            workload_cfg=workload_cfg,\n            plugin=plugin,\n            repetition=rep,\n            total_reps=total_reps,\n        )\n        success_overall = success_overall and success\n\n        if idx &lt; len(reps) - 1 and self.config.cooldown_seconds &gt; 0:\n            logger.info(\"Cooldown period: %s seconds\", self.config.cooldown_seconds)\n            time.sleep(self.config.cooldown_seconds)\n\n        if self._stop_token and self._stop_token.should_stop():\n            break\n\n    logger.info(f\"Completed benchmark: {test_type}\")\n    return success_overall\n</code></pre>"},{"location":"reference/runner/#plugin-registry","title":"Plugin registry","text":""},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry","title":"PluginRegistry","text":"<pre><code>PluginRegistry(plugins=None)\n</code></pre> <p>In-memory registry that supports built-in, entry-point, and user directory plugins.</p> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def __init__(self, plugins: Optional[Iterable[Any]] = None):\n    self._workloads: Dict[str, IWorkloadPlugin] = {}\n    self._collectors: Dict[str, CollectorPlugin] = {}\n    self._pending_entrypoints: Dict[str, importlib.metadata.EntryPoint] = {}\n    if plugins:\n        for plugin in plugins:\n            self.register(plugin)\n    self._discover_entrypoint_plugins()\n    self._load_user_plugins()\n</code></pre>"},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry.available","title":"available","text":"<pre><code>available(load_entrypoints=False)\n</code></pre> <p>Return available workload plugins.</p> <p>When load_entrypoints is True, pending entry-point plugins are resolved and registered; otherwise only already-registered plugins are returned.</p> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def available(self, load_entrypoints: bool = False) -&gt; Dict[str, Any]:\n    \"\"\"\n    Return available workload plugins.\n\n    When load_entrypoints is True, pending entry-point plugins are resolved and\n    registered; otherwise only already-registered plugins are returned.\n    \"\"\"\n    if load_entrypoints:\n        self._load_pending_entrypoints()\n    return dict(self._workloads)\n</code></pre>"},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry.available_collectors","title":"available_collectors","text":"<pre><code>available_collectors()\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def available_collectors(self) -&gt; Dict[str, CollectorPlugin]:\n    return dict(self._collectors)\n</code></pre>"},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry.create_collectors","title":"create_collectors","text":"<pre><code>create_collectors(config)\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def create_collectors(self, config: BenchmarkConfig) -&gt; list[BaseCollector]:\n    collectors = []\n    for plugin in self._collectors.values():\n        if plugin.should_run(config):\n            try:\n                collector = plugin.factory(config)\n                collectors.append(collector)\n            except Exception as e:\n                logger.error(f\"Failed to create collector {plugin.name}: {e}\")\n    return collectors\n</code></pre>"},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry.create_generator","title":"create_generator","text":"<pre><code>create_generator(plugin_name, options=None)\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def create_generator(\n    self, plugin_name: str, options: Optional[Dict[str, Any]] = None\n) -&gt; BaseGenerator:\n    plugin = self.get(plugin_name)\n\n    # New style: we need to handle config instantiation here or in the plugin\n    # The interface says `create_generator(config: Any)`.\n    # We need to convert dict -&gt; config_obj.\n\n    if options is None:\n        options = {}\n\n    # If options is already the config object, pass it\n    if isinstance(options, plugin.config_cls):\n        return plugin.create_generator(options)\n\n    # Otherwise instantiate from dict\n    config_obj = plugin.config_cls(**options)\n    return plugin.create_generator(config_obj)\n</code></pre>"},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry.get","title":"get","text":"<pre><code>get(name)\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def get(self, name: str) -&gt; IWorkloadPlugin:\n    if name not in self._workloads and name in self._pending_entrypoints:\n        self._load_entrypoint(name)\n    if name not in self._workloads:\n        raise KeyError(f\"Workload Plugin '{name}' not found\")\n    return self._workloads[name]\n</code></pre>"},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry.get_collector","title":"get_collector","text":"<pre><code>get_collector(name)\n</code></pre> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def get_collector(self, name: str) -&gt; CollectorPlugin:\n    if name not in self._collectors:\n        raise KeyError(f\"Collector Plugin '{name}' not found\")\n    return self._collectors[name]\n</code></pre>"},{"location":"reference/runner/#lb_runner.plugin_system.registry.PluginRegistry.register","title":"register","text":"<pre><code>register(plugin)\n</code></pre> <p>Register a new plugin.</p> Source code in <code>lb_runner/plugin_system/registry.py</code> <pre><code>def register(self, plugin: Any) -&gt; None:\n    \"\"\"Register a new plugin.\"\"\"\n    if isinstance(plugin, IWorkloadPlugin):\n        self._workloads[plugin.name] = plugin\n    elif isinstance(plugin, CollectorPlugin):\n        self._collectors[plugin.name] = plugin\n    else:\n        # Try duck typing for IWorkloadPlugin if strict check fails (e.g. different import paths)\n        if hasattr(plugin, \"name\") and hasattr(plugin, \"create_generator\"):\n            self._workloads[plugin.name] = plugin\n        else:\n            raise TypeError(f\"Unknown plugin type: {type(plugin)}\")\n</code></pre>"},{"location":"reference/runner/#configuration-models","title":"Configuration models","text":""},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig","title":"BenchmarkConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Main configuration for benchmark tests.</p>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.collect_system_info","title":"collect_system_info  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>collect_system_info = Field(\n    default=True,\n    description=\"Collect system information before running benchmarks\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.collectors","title":"collectors  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>collectors = Field(\n    default_factory=MetricCollectorConfig,\n    description=\"Configuration for metric collectors\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.cooldown_seconds","title":"cooldown_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cooldown_seconds = Field(\n    default=5,\n    ge=0,\n    description=\"Cooldown period after test finishes\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.data_export_dir","title":"data_export_dir  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>data_export_dir = Field(\n    default=Path(\"./data_exports\"),\n    description=\"Directory for raw data exports\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.influxdb_bucket","title":"influxdb_bucket  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_bucket = Field(\n    default=\"performance\", description=\"InfluxDB Bucket\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.influxdb_enabled","title":"influxdb_enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_enabled = Field(\n    default=False, description=\"Enable InfluxDB integration\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.influxdb_org","title":"influxdb_org  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_org = Field(\n    default=\"benchmark\", description=\"InfluxDB Organization\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.influxdb_token","title":"influxdb_token  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_token = Field(\n    default=\"\", description=\"InfluxDB API Token\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.influxdb_url","title":"influxdb_url  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>influxdb_url = Field(\n    default=\"http://localhost:8086\",\n    description=\"InfluxDB URL\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.metrics_interval_seconds","title":"metrics_interval_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metrics_interval_seconds = Field(\n    default=1.0,\n    gt=0,\n    description=\"Interval for metric collection in seconds\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.output_dir","title":"output_dir  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>output_dir = Field(\n    default=Path(\"./benchmark_results\"),\n    description=\"Root directory for all benchmark output\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.plugin_settings","title":"plugin_settings  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>plugin_settings = Field(\n    default_factory=dict,\n    description=\"Dictionary of plugin-specific Pydantic config models\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.remote_execution","title":"remote_execution  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>remote_execution = Field(\n    default_factory=RemoteExecutionConfig,\n    description=\"Configuration for remote execution\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.remote_hosts","title":"remote_hosts  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>remote_hosts = Field(\n    default_factory=list,\n    description=\"List of remote hosts for benchmarking\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.repetitions","title":"repetitions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>repetitions = Field(\n    default=3,\n    gt=0,\n    description=\"Number of repetitions for each test\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.report_dir","title":"report_dir  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>report_dir = Field(\n    default=Path(\"./reports\"),\n    description=\"Directory for generated reports\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.test_duration_seconds","title":"test_duration_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>test_duration_seconds = Field(\n    default=3600,\n    gt=0,\n    description=\"Default duration for tests in seconds\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.warmup_seconds","title":"warmup_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>warmup_seconds = Field(\n    default=5,\n    ge=0,\n    description=\"Warmup period before metric collection starts\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.workloads","title":"workloads  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>workloads = Field(\n    default_factory=dict,\n    description=\"Dictionary of workload definitions\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.ensure_output_dirs","title":"ensure_output_dirs","text":"<pre><code>ensure_output_dirs()\n</code></pre> <p>Ensures all configured output directories exist.</p> Source code in <code>lb_runner/models/config.py</code> <pre><code>def ensure_output_dirs(self) -&gt; None:\n    \"\"\"Ensures all configured output directories exist.\"\"\"\n    for path in (self.output_dir, self.report_dir, self.data_export_dir):\n        path.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data)\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Dict[str, Any]) -&gt; \"BenchmarkConfig\":\n    # Use Pydantic's built-in dictionary parsing and validation\n    # Pydantic will handle nested models and Path conversions automatically\n    return cls.model_validate(data)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_str)\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; \"BenchmarkConfig\":\n    # Use Pydantic's built-in JSON parsing and validation\n    return cls.model_validate_json(json_str)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.load","title":"load  <code>classmethod</code>","text":"<pre><code>load(filepath)\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>@classmethod\ndef load(cls, filepath: Path) -&gt; \"BenchmarkConfig\":\n    return cls.model_validate_json(filepath.read_text())\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.BenchmarkConfig.save","title":"save","text":"<pre><code>save(filepath)\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>def save(self, filepath: Path) -&gt; None:\n    filepath.write_text(self.model_dump_json(indent=2))\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.WorkloadConfig","title":"WorkloadConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration wrapper for workload plugins.</p>"},{"location":"reference/runner/#lb_runner.models.config.WorkloadConfig-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.models.config.WorkloadConfig.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled = Field(\n    default=True,\n    description=\"Enable or disable this workload\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.WorkloadConfig.intensity","title":"intensity  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>intensity = Field(\n    default=\"user_defined\",\n    description=\"Pre-defined intensity level (low, medium, high, user_defined)\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.WorkloadConfig.options","title":"options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>options = Field(\n    default_factory=dict,\n    description=\"Plugin-specific options for the workload\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.WorkloadConfig.plugin","title":"plugin  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>plugin = Field(description='Name of the plugin to use')\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig","title":"RemoteExecutionConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for remote execution via Ansible.</p>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.collect_playbook","title":"collect_playbook  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>collect_playbook = Field(\n    default_factory=lambda: ANSIBLE_ROOT\n    / \"playbooks\"\n    / \"collect.yml\",\n    description=\"Path to the Ansible collect playbook\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.enabled","title":"enabled  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enabled = Field(\n    default=False, description=\"Enable remote execution\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.inventory_path","title":"inventory_path  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>inventory_path = Field(\n    default=None,\n    description=\"Path to a custom Ansible inventory file\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.run_collect","title":"run_collect  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_collect = Field(\n    default=True,\n    description=\"Execute collection playbooks after tests\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.run_playbook","title":"run_playbook  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_playbook = Field(\n    default_factory=lambda: ANSIBLE_ROOT\n    / \"playbooks\"\n    / \"run_benchmark.yml\",\n    description=\"Path to the Ansible run playbook\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.run_setup","title":"run_setup  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_setup = Field(\n    default=True,\n    description=\"Execute setup playbooks before tests\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.run_teardown","title":"run_teardown  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>run_teardown = Field(\n    default=True,\n    description=\"Execute teardown playbooks after tests\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.setup_playbook","title":"setup_playbook  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>setup_playbook = Field(\n    default_factory=lambda: ANSIBLE_ROOT\n    / \"playbooks\"\n    / \"setup.yml\",\n    description=\"Path to the Ansible setup playbook\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.teardown_playbook","title":"teardown_playbook  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>teardown_playbook = Field(\n    default_factory=lambda: ANSIBLE_ROOT\n    / \"playbooks\"\n    / \"teardown.yml\",\n    description=\"Path to the Ansible teardown playbook\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.upgrade_pip","title":"upgrade_pip  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>upgrade_pip = Field(\n    default=False,\n    description=\"Upgrade pip inside the benchmark virtual environment during setup\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteExecutionConfig.use_container_fallback","title":"use_container_fallback  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>use_container_fallback = Field(\n    default=False,\n    description=\"Use container-based fallback for remote execution\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig","title":"RemoteHostConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a remote benchmark host.</p>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig-attributes","title":"Attributes","text":""},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.address","title":"address  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>address = Field(\n    description=\"IP address or hostname of the remote host\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.become","title":"become  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>become = Field(\n    default=True,\n    description=\"Use Ansible become (sudo) for escalated privileges\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.become_method","title":"become_method  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>become_method = Field(\n    default=\"sudo\", description=\"Ansible become method\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name = Field(description='Unique name for the remote host')\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.port","title":"port  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>port = Field(\n    default=22, gt=0, description=\"SSH port for connection\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.user","title":"user  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>user = Field(\n    default=\"root\", description=\"SSH user for connection\"\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.vars","title":"vars  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>vars = Field(\n    default_factory=dict,\n    description=\"Additional Ansible variables for this host\",\n)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig-functions","title":"Functions","text":""},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.ansible_host_line","title":"ansible_host_line","text":"<pre><code>ansible_host_line()\n</code></pre> <p>Render an INI-style inventory line for this host (compat helper).</p> Source code in <code>lb_runner/models/config.py</code> <pre><code>def ansible_host_line(self) -&gt; str:\n    \"\"\"Render an INI-style inventory line for this host (compat helper).\"\"\"\n    parts = [\n        self.name,\n        f\"ansible_host={self.address}\",\n        f\"ansible_port={self.port}\",\n        f\"ansible_user={self.user}\",\n    ]\n    if self.become:\n        parts.append(\"ansible_become=true\")\n    if self.become_method:\n        parts.append(f\"ansible_become_method={self.become_method}\")\n    for key, value in self.vars.items():\n        val = str(value)\n        if \" \" in val:\n            val = f'\"{val}\"'\n        parts.append(f\"{key}={val}\")\n    return \" \".join(parts)\n</code></pre>"},{"location":"reference/runner/#lb_runner.models.config.RemoteHostConfig.validate_name_not_empty","title":"validate_name_not_empty","text":"<pre><code>validate_name_not_empty()\n</code></pre> Source code in <code>lb_runner/models/config.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_name_not_empty(self) -&gt; 'RemoteHostConfig':\n    if not self.name or not self.name.strip():\n        raise ValueError(\"RemoteHostConfig: 'name' must be non-empty\")\n    return self\n</code></pre>"}]}